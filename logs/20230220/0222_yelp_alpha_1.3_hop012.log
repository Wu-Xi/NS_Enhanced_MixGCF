Namespace(K=1, Ks='[20, 40, 60]', alpha=1.3, batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, gnn='lightgcn', gpu_id=2, l2=0.001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重,引入alpha超参数来控制模型倾向......
start training ...
epoch: 0 s: 0 batch_loss 0.693148672580719 BPR_loss 0.6931484937667847 reg_loss 1.591595690797476e-07
epoch: 0 s: 256000 batch_loss 0.693117082118988 BPR_loss 0.6931115388870239 reg_loss 5.554364179261029e-06
epoch: 0 s: 512000 batch_loss 0.692854106426239 BPR_loss 0.6927918195724487 reg_loss 6.227724952623248e-05
epoch: 0 s: 768000 batch_loss 0.6922818422317505 BPR_loss 0.69218909740448 reg_loss 9.273499017581344e-05
epoch: 0 s: 1024000 batch_loss 0.6920651793479919 BPR_loss 0.691931426525116 reg_loss 0.00013374151603784412
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 200.7884304523468 | 43.14618444442749 | 418.3254089355469 | [0.04982556 0.08422058 0.1121986 ] | [0.04086833 0.0539258  0.06376897] | [0.02350006 0.02001626 0.01785241] | [0.32139699 0.45531767 0.53729317] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.6926476955413818 BPR_loss 0.6924971342086792 reg_loss 0.00015054369578137994
epoch: 1 s: 256000 batch_loss 0.6911716461181641 BPR_loss 0.6910133361816406 reg_loss 0.00015830785559955984
epoch: 1 s: 512000 batch_loss 0.6925865411758423 BPR_loss 0.692420482635498 reg_loss 0.00016604368283879012
epoch: 1 s: 768000 batch_loss 0.6916771531105042 BPR_loss 0.691474199295044 reg_loss 0.000202970186364837
epoch: 1 s: 1024000 batch_loss 0.690670907497406 BPR_loss 0.6903712153434753 reg_loss 0.0002996858675032854
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 202.90751910209656 | 42.7438485622406 | 417.8904113769531 | [0.05120664 0.08678623 0.1152658 ] | [0.04223318 0.05568986 0.06572122] | [0.02418846 0.0205894  0.01835344] | [0.32793356 0.46453834 0.54512442] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6913383603096008 BPR_loss 0.691006600856781 reg_loss 0.0003317383525427431
epoch: 2 s: 256000 batch_loss 0.6915057301521301 BPR_loss 0.6911303997039795 reg_loss 0.00037531688576564193
epoch: 2 s: 512000 batch_loss 0.6935172080993652 BPR_loss 0.6931306719779968 reg_loss 0.0003865563776344061
epoch: 2 s: 768000 batch_loss 0.6921230554580688 BPR_loss 0.6916353702545166 reg_loss 0.00048766034888103604
epoch: 2 s: 1024000 batch_loss 0.68790602684021 BPR_loss 0.6872968077659607 reg_loss 0.0006092482944950461
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 208.12388563156128 | 45.13316035270691 | 417.3166809082031 | [0.05260976 0.08864116 0.1180295 ] | [0.04321921 0.05687672 0.06722953] | [0.02465738 0.02095491 0.01872711] | [0.33428066 0.47126437 0.5543135 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.6896764039993286 BPR_loss 0.6890081763267517 reg_loss 0.0006682511884719133
epoch: 3 s: 256000 batch_loss 0.6901995539665222 BPR_loss 0.6895270347595215 reg_loss 0.000672541034873575
epoch: 3 s: 512000 batch_loss 0.6884950995445251 BPR_loss 0.6876930594444275 reg_loss 0.0008020420209504664
epoch: 3 s: 768000 batch_loss 0.689418375492096 BPR_loss 0.6886259317398071 reg_loss 0.0007924159872345626
epoch: 3 s: 1024000 batch_loss 0.689672589302063 BPR_loss 0.6887399554252625 reg_loss 0.0009326453437097371
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 218.9662685394287 | 45.34217977523804 | 416.6878356933594 | [0.05434526 0.09066272 0.12075543] | [0.04439371 0.05814683 0.06871716] | [0.0254263  0.02145936 0.01914446] | [0.34185929 0.4779904  0.56182898] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.6876357793807983 BPR_loss 0.6866668462753296 reg_loss 0.0009689617436379194
epoch: 4 s: 256000 batch_loss 0.6869473457336426 BPR_loss 0.6858349442481995 reg_loss 0.0011124098673462868
epoch: 4 s: 512000 batch_loss 0.6888892650604248 BPR_loss 0.6878553628921509 reg_loss 0.0010338941356167197
epoch: 4 s: 768000 batch_loss 0.6881017088890076 BPR_loss 0.6869795322418213 reg_loss 0.001122165354900062
epoch: 4 s: 1024000 batch_loss 0.6898025274276733 BPR_loss 0.6886784434318542 reg_loss 0.0011240859748795629
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 218.25474786758423 | 49.64144730567932 | 416.165771484375 | [0.05432816 0.09103143 0.12128271] | [0.04443645 0.05835384 0.06901602] | [0.02524631 0.02140805 0.01914604] | [0.34100669 0.47900088 0.56328155] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.6882626414299011 BPR_loss 0.686941921710968 reg_loss 0.0013207339216023684
epoch: 5 s: 256000 batch_loss 0.6877092719078064 BPR_loss 0.6864005327224731 reg_loss 0.0013087447732686996
epoch: 5 s: 512000 batch_loss 0.688387393951416 BPR_loss 0.6871830224990845 reg_loss 0.001204360625706613
epoch: 5 s: 768000 batch_loss 0.6893566846847534 BPR_loss 0.6881489753723145 reg_loss 0.0012077080318704247
epoch: 5 s: 1024000 batch_loss 0.688344419002533 BPR_loss 0.6870864629745483 reg_loss 0.0012579287867993116
+-------+-------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |      Loss     |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 240.4831109046936 | 68.88164043426514 | 415.697265625 | [0.05482685 0.09169342 0.12258563] | [0.04494912 0.05895569 0.0698225 ] | [0.0254784  0.02163304 0.01935866] | [0.34293293 0.48174814 0.56684982] |
+-------+-------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.6873809695243835 BPR_loss 0.6859256625175476 reg_loss 0.001455321442335844
epoch: 6 s: 256000 batch_loss 0.6889485120773315 BPR_loss 0.6875988245010376 reg_loss 0.0013496975880116224
epoch: 6 s: 512000 batch_loss 0.6854339241981506 BPR_loss 0.683946967124939 reg_loss 0.0014869734877720475
epoch: 6 s: 768000 batch_loss 0.68683922290802 BPR_loss 0.6854369044303894 reg_loss 0.0014023220865055919
epoch: 6 s: 1024000 batch_loss 0.6901702880859375 BPR_loss 0.6888418793678284 reg_loss 0.0013284224551171064
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 242.15237283706665 | 74.13435864448547 | 415.322021484375 | [0.05523043 0.0922707  0.12265131] | [0.04525668 0.05927431 0.07000269] | [0.02575471 0.02175382 0.01943655] | [0.34457497 0.48395857 0.56688139] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.6864249110221863 BPR_loss 0.6848354339599609 reg_loss 0.001589458086527884
epoch: 7 s: 256000 batch_loss 0.6863418817520142 BPR_loss 0.6847125291824341 reg_loss 0.0016293609514832497
epoch: 7 s: 512000 batch_loss 0.6858576536178589 BPR_loss 0.6841809749603271 reg_loss 0.0016766752814874053
epoch: 7 s: 768000 batch_loss 0.6854044795036316 BPR_loss 0.6837555170059204 reg_loss 0.0016489654080942273
epoch: 7 s: 1024000 batch_loss 0.6885405778884888 BPR_loss 0.6869860887527466 reg_loss 0.0015544878551736474
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 245.00813937187195 | 68.79554629325867 | 415.0462341308594 | [0.0548269  0.09200743 0.1217838 ] | [0.04495064 0.05904266 0.069563  ] | [0.02548156 0.02162119 0.01924866] | [0.34094354 0.47997979 0.56366048] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.6874204277992249 BPR_loss 0.6857821941375732 reg_loss 0.0016382173635065556
epoch: 8 s: 256000 batch_loss 0.6878769397735596 BPR_loss 0.6861158013343811 reg_loss 0.001761118182912469
epoch: 8 s: 512000 batch_loss 0.6841096878051758 BPR_loss 0.6820929050445557 reg_loss 0.002016753423959017
epoch: 8 s: 768000 batch_loss 0.6812795996665955 BPR_loss 0.6793642044067383 reg_loss 0.0019153879256919026
epoch: 8 s: 1024000 batch_loss 0.6880730986595154 BPR_loss 0.6863012313842773 reg_loss 0.0017718637827783823
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 253.00395941734314 | 64.75025868415833 | 414.81689453125 | [0.05538297 0.09268614 0.12308286] | [0.04544838 0.05957607 0.07030009] | [0.02582891 0.02184224 0.0194655 ] | [0.3456486  0.48541114 0.56833396] |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.6853951811790466 BPR_loss 0.6833168268203735 reg_loss 0.0020783711224794388
epoch: 9 s: 256000 batch_loss 0.6876988410949707 BPR_loss 0.6858778595924377 reg_loss 0.0018209906993433833
epoch: 9 s: 512000 batch_loss 0.6850208640098572 BPR_loss 0.6830897927284241 reg_loss 0.0019310942152515054
epoch: 9 s: 768000 batch_loss 0.6851391196250916 BPR_loss 0.683295726776123 reg_loss 0.0018433730583637953
epoch: 9 s: 1024000 batch_loss 0.6844965815544128 BPR_loss 0.682401180267334 reg_loss 0.002095386851578951
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 264.10869002342224 | 43.668914794921875 | 414.5550231933594 | [0.05564116 0.09267453 0.12315368] | [0.04572187 0.05970631 0.07045397] | [0.02601996 0.02187697 0.0195197 ] | [0.34580649 0.48493748 0.56741821] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.6891390681266785 BPR_loss 0.6871341466903687 reg_loss 0.0020049053709954023
epoch: 10 s: 256000 batch_loss 0.6859110593795776 BPR_loss 0.6840038299560547 reg_loss 0.0019072068389505148
epoch: 10 s: 512000 batch_loss 0.6854473948478699 BPR_loss 0.6834017634391785 reg_loss 0.002045650267973542
epoch: 10 s: 768000 batch_loss 0.6848906874656677 BPR_loss 0.6828954219818115 reg_loss 0.0019952382426708937
epoch: 10 s: 1024000 batch_loss 0.6877899169921875 BPR_loss 0.6857553124427795 reg_loss 0.002034593839198351
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 272.1150393486023 | 38.031628131866455 | 414.36553955078125 | [0.05553296 0.09235447 0.12281811] | [0.04549556 0.05945404 0.07023322] | [0.02580997 0.02174829 0.01945602] | [0.34508021 0.48225338 0.5651762 ] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.6895079612731934 BPR_loss 0.6875091791152954 reg_loss 0.0019988082349300385
epoch: 11 s: 256000 batch_loss 0.6849822998046875 BPR_loss 0.6827775239944458 reg_loss 0.002204763237386942
epoch: 11 s: 512000 batch_loss 0.6846850514411926 BPR_loss 0.682637095451355 reg_loss 0.0020479464437812567
epoch: 11 s: 768000 batch_loss 0.6861969232559204 BPR_loss 0.6841708421707153 reg_loss 0.002026103436946869
epoch: 11 s: 1024000 batch_loss 0.6866298317909241 BPR_loss 0.6845194101333618 reg_loss 0.002110403496772051
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 284.7927780151367 | 40.83995580673218 | 414.21392822265625 | [0.05527875 0.0920126  0.12211699] | [0.0452137  0.0591449  0.06979927] | [0.02555892 0.02153278 0.01923551] | [0.34290135 0.48054819 0.56451307] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.6846923232078552 BPR_loss 0.682572603225708 reg_loss 0.002119744662195444
epoch: 12 s: 256000 batch_loss 0.6824003458023071 BPR_loss 0.6802799701690674 reg_loss 0.0021203889045864344
epoch: 12 s: 512000 batch_loss 0.6838288903236389 BPR_loss 0.6816115379333496 reg_loss 0.0022173759061843157
epoch: 12 s: 768000 batch_loss 0.6849339604377747 BPR_loss 0.6828579902648926 reg_loss 0.0020759988110512495
epoch: 12 s: 1024000 batch_loss 0.6808304190635681 BPR_loss 0.6783570051193237 reg_loss 0.0024733964819461107
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 273.650071144104 | 41.79920673370361 | 414.0188293457031 | [0.05561802 0.09204466 0.12257966] | [0.04552491 0.05931964 0.07009275] | [0.02580839 0.02165514 0.01936603] | [0.34384868 0.48102185 0.56467096] |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 13 s: 0 batch_loss 0.6837909817695618 BPR_loss 0.6813297271728516 reg_loss 0.002461235737428069
epoch: 13 s: 256000 batch_loss 0.6870129704475403 BPR_loss 0.6849939823150635 reg_loss 0.0020190083887428045
epoch: 13 s: 512000 batch_loss 0.685795247554779 BPR_loss 0.6836706399917603 reg_loss 0.002124614315107465
epoch: 13 s: 768000 batch_loss 0.685451865196228 BPR_loss 0.68294358253479 reg_loss 0.0025083012878894806
epoch: 13 s: 1024000 batch_loss 0.6891674399375916 BPR_loss 0.6868818402290344 reg_loss 0.0022856160067021847
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   13  | 248.1855010986328 | 42.895925760269165 | 413.8260498046875 | [0.05534975 0.09181719 0.12206059] | [0.04540609 0.05917429 0.06986275] | [0.02571839 0.02153357 0.01925708] | [0.34324871 0.47840091 0.56347101] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 14 s: 0 batch_loss 0.6836255192756653 BPR_loss 0.6812235116958618 reg_loss 0.00240202690474689
epoch: 14 s: 256000 batch_loss 0.6842210292816162 BPR_loss 0.6818399429321289 reg_loss 0.0023810614366084337
epoch: 14 s: 512000 batch_loss 0.6858468651771545 BPR_loss 0.6834361553192139 reg_loss 0.0024106965865939856
epoch: 14 s: 768000 batch_loss 0.6853256225585938 BPR_loss 0.6829571723937988 reg_loss 0.0023684368934482336
epoch: 14 s: 1024000 batch_loss 0.6848386526107788 BPR_loss 0.68244469165802 reg_loss 0.0023939881939440966
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   14  | 244.75102376937866 | 39.830801010131836 | 413.69915771484375 | [0.05546822 0.09206853 0.12219534] | [0.04552846 0.05936182 0.07000558] | [0.0257405  0.02157462 0.01925603] | [0.3438171  0.47966401 0.56375521] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 15 s: 0 batch_loss 0.6855189204216003 BPR_loss 0.6830772161483765 reg_loss 0.0024417052045464516
epoch: 15 s: 256000 batch_loss 0.6878995299339294 BPR_loss 0.6854332685470581 reg_loss 0.0024662744253873825
epoch: 15 s: 512000 batch_loss 0.6866589784622192 BPR_loss 0.6841486692428589 reg_loss 0.0025103145744651556
epoch: 15 s: 768000 batch_loss 0.6845121383666992 BPR_loss 0.682231068611145 reg_loss 0.00228105834685266
epoch: 15 s: 1024000 batch_loss 0.6863883137702942 BPR_loss 0.6840406060218811 reg_loss 0.0023477321956306696
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 236.52396512031555 | 38.20544219017029 | 413.61004638671875 | [0.0552847  0.09194896 0.12182767] | [0.04554892 0.05937364 0.06994689] | [0.02572629 0.02156199 0.01923972] | [0.34309082 0.47840091 0.56081849] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 16 s: 0 batch_loss 0.685947597026825 BPR_loss 0.6834759712219238 reg_loss 0.0024716139305382967
epoch: 16 s: 256000 batch_loss 0.6820052266120911 BPR_loss 0.6794216632843018 reg_loss 0.0025835393462330103
epoch: 16 s: 512000 batch_loss 0.6837378740310669 BPR_loss 0.6809686422348022 reg_loss 0.0027692171279340982
epoch: 16 s: 768000 batch_loss 0.6834992170333862 BPR_loss 0.6809751987457275 reg_loss 0.0025240438990294933
epoch: 16 s: 1024000 batch_loss 0.6845901608467102 BPR_loss 0.6820467114448547 reg_loss 0.002543449169024825
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   16  | 238.672865152359 | 39.04516959190369 | 413.5409851074219 | [0.05496137 0.09110299 0.12144146] | [0.04519308 0.0588644  0.06960702] | [0.02548945 0.02131647 0.01912972] | [0.33955412 0.4746116  0.5591133 ] |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 17 s: 0 batch_loss 0.6825207471847534 BPR_loss 0.6798167824745178 reg_loss 0.002703992649912834
epoch: 17 s: 256000 batch_loss 0.6855045557022095 BPR_loss 0.6829968690872192 reg_loss 0.00250768824480474
epoch: 17 s: 512000 batch_loss 0.6835582256317139 BPR_loss 0.6810727119445801 reg_loss 0.0024855295196175575
epoch: 17 s: 768000 batch_loss 0.6878474950790405 BPR_loss 0.6851234436035156 reg_loss 0.002724062418565154
epoch: 17 s: 1024000 batch_loss 0.6855797171592712 BPR_loss 0.6827940940856934 reg_loss 0.0027856500819325447
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   17  | 244.3979001045227 | 39.169745683670044 | 413.4418640136719 | [0.05497544 0.09142784 0.12123565] | [0.04528941 0.05907988 0.06963163] | [0.02545945 0.02135989 0.01907709] | [0.34002779 0.47448528 0.55709233] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 18 s: 0 batch_loss 0.68647301197052 BPR_loss 0.6837897896766663 reg_loss 0.0026832136791199446
epoch: 18 s: 256000 batch_loss 0.6872995495796204 BPR_loss 0.6846381425857544 reg_loss 0.0026613872032612562
epoch: 18 s: 512000 batch_loss 0.6820615530014038 BPR_loss 0.6793179512023926 reg_loss 0.0027436036616563797
epoch: 18 s: 768000 batch_loss 0.6854270696640015 BPR_loss 0.6828351616859436 reg_loss 0.00259189261123538
epoch: 18 s: 1024000 batch_loss 0.6837002038955688 BPR_loss 0.6810764074325562 reg_loss 0.002623769687488675
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   18  | 247.078138589859 | 47.73049283027649 | 413.3387451171875 | [0.05519546 0.09135169 0.12120015] | [0.0454645  0.05914508 0.06968447] | [0.0255605  0.0213741  0.01906972] | [0.34059619 0.47394847 0.55753442] |
+-------+------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 19 s: 0 batch_loss 0.6837972402572632 BPR_loss 0.681191086769104 reg_loss 0.0026061362586915493
epoch: 19 s: 256000 batch_loss 0.684217095375061 BPR_loss 0.681556224822998 reg_loss 0.002660894300788641
epoch: 19 s: 512000 batch_loss 0.6837918758392334 BPR_loss 0.681310772895813 reg_loss 0.0024811120238155127
epoch: 19 s: 768000 batch_loss 0.6844223141670227 BPR_loss 0.6818258762359619 reg_loss 0.002596435137093067
epoch: 19 s: 1024000 batch_loss 0.6826511025428772 BPR_loss 0.6797645688056946 reg_loss 0.0028865160420536995
+-------+--------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |      Loss     |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   19  | 235.72518396377563 | 49.56320333480835 | 413.197265625 | [0.05514515 0.09111006 0.12070338] | [0.04542976 0.05901283 0.06945233] | [0.02553208 0.02131173 0.01898394] | [0.34005937 0.47252747 0.55415561] |
+-------+--------------------+-------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.055145149148399845
early stopping at 19, recall@20:0.0556
