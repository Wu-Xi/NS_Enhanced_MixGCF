Namespace(K=1, Ks='[20, 40, 60]', alpha=1.5, batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, gnn='lightgcn', gpu_id=2, l2=0.001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重,引入alpha超参数来控制模型倾向......
start training ...
epoch: 0 s: 0 batch_loss 0.6931489109992981 BPR_loss 0.6931487321853638 reg_loss 1.6913692491016263e-07
epoch: 0 s: 256000 batch_loss 0.6931451559066772 BPR_loss 0.6931425333023071 reg_loss 2.6096322471858002e-06
epoch: 0 s: 512000 batch_loss 0.6929810643196106 BPR_loss 0.6929458379745483 reg_loss 3.523001214489341e-05
epoch: 0 s: 768000 batch_loss 0.6922492980957031 BPR_loss 0.6922050714492798 reg_loss 4.422186248120852e-05
epoch: 0 s: 1024000 batch_loss 0.6923509836196899 BPR_loss 0.6922973394393921 reg_loss 5.3663279686588794e-05
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 204.3739631175995 | 36.11480903625488 | 418.46905517578125 | [0.04838728 0.08103157 0.107221  ] | [0.03992542 0.05225844 0.06152206] | [0.02305324 0.01941629 0.01724401] | [0.31482885 0.44274978 0.52235695] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.692861020565033 BPR_loss 0.692786455154419 reg_loss 7.456644379999489e-05
epoch: 1 s: 256000 batch_loss 0.6920721530914307 BPR_loss 0.6919893622398376 reg_loss 8.280915062641725e-05
epoch: 1 s: 512000 batch_loss 0.6927623748779297 BPR_loss 0.6926931142807007 reg_loss 6.923195178387687e-05
epoch: 1 s: 768000 batch_loss 0.6926026940345764 BPR_loss 0.6925241947174072 reg_loss 7.850395195418969e-05
epoch: 1 s: 1024000 batch_loss 0.6917892098426819 BPR_loss 0.6916722059249878 reg_loss 0.00011699929018504918
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 203.4204661846161 | 36.33230376243591 | 418.2647705078125 | [0.04978211 0.08348407 0.11166453] | [0.04095741 0.05378281 0.06371912] | [0.02362006 0.02003205 0.01791714] | [0.31928129 0.44976001 0.53072502] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6925038695335388 BPR_loss 0.6923876404762268 reg_loss 0.00011625160550465807
epoch: 2 s: 256000 batch_loss 0.6924304366111755 BPR_loss 0.6923055648803711 reg_loss 0.00012485584011301398
epoch: 2 s: 512000 batch_loss 0.6942219734191895 BPR_loss 0.6940882802009583 reg_loss 0.00013370493252296
epoch: 2 s: 768000 batch_loss 0.6929445266723633 BPR_loss 0.6928001046180725 reg_loss 0.000144440884469077
epoch: 2 s: 1024000 batch_loss 0.6907738447189331 BPR_loss 0.6905409097671509 reg_loss 0.00023295331629924476
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 215.3030071258545 | 39.05083250999451 | 418.0835876464844 | [0.04866546 0.08313535 0.11124832] | [0.04023112 0.05328292 0.06317349] | [0.02321429 0.01987337 0.01779294] | [0.31388152 0.44524441 0.5265252 ] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.6915103197097778 BPR_loss 0.6912814378738403 reg_loss 0.0002288597752340138
epoch: 3 s: 256000 batch_loss 0.691963791847229 BPR_loss 0.6917459964752197 reg_loss 0.00021777316578663886
epoch: 3 s: 512000 batch_loss 0.69078129529953 BPR_loss 0.6904933452606201 reg_loss 0.0002879546955227852
epoch: 3 s: 768000 batch_loss 0.6919816732406616 BPR_loss 0.6917086839675903 reg_loss 0.00027300723013468087
epoch: 3 s: 1024000 batch_loss 0.6920268535614014 BPR_loss 0.6916379928588867 reg_loss 0.0003888684732373804
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 219.84882760047913 | 38.21792960166931 | 417.842041015625 | [0.04930939 0.08310175 0.11086641] | [0.04041417 0.05326794 0.06307473] | [0.0233848  0.01993337 0.01783767] | [0.31536567 0.44432866 0.52137805] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.6904617547988892 BPR_loss 0.6900691390037537 reg_loss 0.00039263421786017716
epoch: 4 s: 256000 batch_loss 0.6902218461036682 BPR_loss 0.6897655725479126 reg_loss 0.0004562688700389117
epoch: 4 s: 512000 batch_loss 0.6908678412437439 BPR_loss 0.6904385089874268 reg_loss 0.00042932815267704427
epoch: 4 s: 768000 batch_loss 0.6905187368392944 BPR_loss 0.690043568611145 reg_loss 0.0004751711094286293
epoch: 4 s: 1024000 batch_loss 0.6918354630470276 BPR_loss 0.6913344860076904 reg_loss 0.0005009508458897471
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 224.60811257362366 | 37.59047198295593 | 417.58416748046875 | [0.04918851 0.08306877 0.11084798] | [0.04073226 0.05354579 0.06340698] | [0.02332797 0.01983706 0.01782293] | [0.31318681 0.44290767 0.52380952] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.6907750368118286 BPR_loss 0.6901986598968506 reg_loss 0.00057635159464553
epoch: 5 s: 256000 batch_loss 0.689970076084137 BPR_loss 0.6893616318702698 reg_loss 0.0006084168562665582
epoch: 5 s: 512000 batch_loss 0.6904340982437134 BPR_loss 0.6898713707923889 reg_loss 0.0005627204081974924
epoch: 5 s: 768000 batch_loss 0.6912193894386292 BPR_loss 0.6906648874282837 reg_loss 0.0005544901359826326
epoch: 5 s: 1024000 batch_loss 0.6906830072402954 BPR_loss 0.6901137828826904 reg_loss 0.0005692359409295022
+-------+--------------------+-----------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s) |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-----------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 249.40009808540344 | 44.566241979599 | 417.317138671875 | [0.04836797 0.08139646 0.10913062] | [0.03998239 0.05254726 0.06238056] | [0.02283062 0.01939182 0.01745558] | [0.30778704 0.43466591 0.51563092] |
+-------+--------------------+-----------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.6897324919700623 BPR_loss 0.6890054941177368 reg_loss 0.0007269986090250313
epoch: 6 s: 256000 batch_loss 0.6908504962921143 BPR_loss 0.6901720762252808 reg_loss 0.0006784152355976403
epoch: 6 s: 512000 batch_loss 0.6893543004989624 BPR_loss 0.6886051893234253 reg_loss 0.0007491330616176128
epoch: 6 s: 768000 batch_loss 0.6898064613342285 BPR_loss 0.6890851259231567 reg_loss 0.0007213230710476637
epoch: 6 s: 1024000 batch_loss 0.6926804780960083 BPR_loss 0.6919967532157898 reg_loss 0.000683753052726388
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 250.20078706741333 | 58.189505100250244 | 417.0565490722656 | [0.04836004 0.0814561  0.1088496 ] | [0.03997451 0.05257206 0.06228685] | [0.02292693 0.01950786 0.01749611] | [0.30696602 0.43548693 0.51575723] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.6892886161804199 BPR_loss 0.6884633898735046 reg_loss 0.0008252377156168222
epoch: 7 s: 256000 batch_loss 0.6893055438995361 BPR_loss 0.6884438991546631 reg_loss 0.0008616429986432195
epoch: 7 s: 512000 batch_loss 0.6898878216743469 BPR_loss 0.6889947652816772 reg_loss 0.0008930275216698647
epoch: 7 s: 768000 batch_loss 0.688256025314331 BPR_loss 0.6873712539672852 reg_loss 0.0008847453282214701
epoch: 7 s: 1024000 batch_loss 0.690452516078949 BPR_loss 0.6896229386329651 reg_loss 0.0008295740117318928
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 245.88373398780823 | 78.61965894699097 | 416.83575439453125 | [0.04852572 0.0810731  0.10765868] | [0.03980404 0.05219071 0.06164804] | [0.02281009 0.0193105  0.01727717] | [0.306145   0.43204497 0.50966275] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.6902139782905579 BPR_loss 0.6893579959869385 reg_loss 0.0008559542475268245
epoch: 8 s: 256000 batch_loss 0.6904345154762268 BPR_loss 0.6894587874412537 reg_loss 0.0009756991639733315
epoch: 8 s: 512000 batch_loss 0.6885355114936829 BPR_loss 0.6874013543128967 reg_loss 0.0011341297067701817
epoch: 8 s: 768000 batch_loss 0.6860958337783813 BPR_loss 0.6849849224090576 reg_loss 0.00111092918086797
epoch: 8 s: 1024000 batch_loss 0.6900233030319214 BPR_loss 0.6890525221824646 reg_loss 0.0009707954595796764
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+---------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |            precision            |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+---------------------------------+------------------------------------+
|   8   | 244.22507500648499 | 100.70127868652344 | 416.6583557128906 | [0.04911025 0.08211157 0.10933931] | [0.04029009 0.05283784 0.06249121] | [0.0231385 0.0196026 0.017524 ] | [0.3109448  0.43880258 0.51582039] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+---------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.6895163059234619 BPR_loss 0.6883156299591064 reg_loss 0.0012007009936496615
epoch: 9 s: 256000 batch_loss 0.6902647018432617 BPR_loss 0.689233660697937 reg_loss 0.001031042542308569
epoch: 9 s: 512000 batch_loss 0.6887499094009399 BPR_loss 0.6876035928726196 reg_loss 0.0011463287519291043
epoch: 9 s: 768000 batch_loss 0.6889738440513611 BPR_loss 0.687917172908783 reg_loss 0.0010566979181021452
epoch: 9 s: 1024000 batch_loss 0.6896744966506958 BPR_loss 0.6884807348251343 reg_loss 0.0011937706731259823
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 243.03042840957642 | 99.63595175743103 | 416.4626770019531 | [0.04838388 0.08075745 0.1081543 ] | [0.03984238 0.05216306 0.06189111] | [0.02285588 0.01934287 0.01739453] | [0.30665025 0.43210812 0.51199949] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.6913094520568848 BPR_loss 0.6901386976242065 reg_loss 0.0011707410449162126
epoch: 10 s: 256000 batch_loss 0.6897261142730713 BPR_loss 0.6885740756988525 reg_loss 0.0011520367115736008
epoch: 10 s: 512000 batch_loss 0.6886812448501587 BPR_loss 0.687463641166687 reg_loss 0.0012175835436210036
epoch: 10 s: 768000 batch_loss 0.6883292198181152 BPR_loss 0.6871239542961121 reg_loss 0.0012052933452650905
epoch: 10 s: 1024000 batch_loss 0.6913160681724548 BPR_loss 0.6900882124900818 reg_loss 0.0012278725625947118
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 243.0942451953888 | 105.97470879554749 | 416.3341369628906 | [0.04797655 0.07962729 0.10620676] | [0.03936809 0.05144014 0.0608924 ] | [0.02239011 0.01890947 0.0169735 ] | [0.30118732 0.42494    0.5015473 ] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.6924324035644531 BPR_loss 0.6912643313407898 reg_loss 0.0011680948082357645
epoch: 11 s: 256000 batch_loss 0.6878639459609985 BPR_loss 0.686516284942627 reg_loss 0.0013476588064804673
epoch: 11 s: 512000 batch_loss 0.688426673412323 BPR_loss 0.6871756911277771 reg_loss 0.0012509538792073727
epoch: 11 s: 768000 batch_loss 0.6889826655387878 BPR_loss 0.6877776980400085 reg_loss 0.0012049598153680563
epoch: 11 s: 1024000 batch_loss 0.6891608834266663 BPR_loss 0.6878464221954346 reg_loss 0.001314450055360794
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 241.1462688446045 | 107.20082306861877 | 416.2126770019531 | [0.04809067 0.0793197  0.10589443] | [0.03951574 0.05139251 0.06083329] | [0.02243432 0.01879026 0.01686666] | [0.30330302 0.42285588 0.50258936] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.048090673212932124
early stopping at 11, recall@20:0.0498
