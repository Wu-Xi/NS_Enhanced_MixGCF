Namespace(K=1, Ks='[20, 40, 60]', alpha=1.5, batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, gnn='lightgcn', gpu_id=2, l2=0.001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重,引入alpha超参数来控制模型倾向......
start training ...
epoch: 0 s: 0 batch_loss 0.6931483745574951 BPR_loss 0.6931482553482056 reg_loss 1.4879779541843163e-07
epoch: 0 s: 256000 batch_loss 0.6931478977203369 BPR_loss 0.6931477785110474 reg_loss 9.732538330808893e-08
epoch: 0 s: 512000 batch_loss 0.693147599697113 BPR_loss 0.6931475400924683 reg_loss 7.172402405331013e-08
epoch: 0 s: 768000 batch_loss 0.6931474804878235 BPR_loss 0.6931474208831787 reg_loss 5.590651852571682e-08
epoch: 0 s: 1024000 batch_loss 0.6931474804878235 BPR_loss 0.6931474208831787 reg_loss 4.562919286854594e-08
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 197.44911742210388 | 35.75826668739319 | 418.66033935546875 | [0.01141817 0.01760958 0.02211373] | [0.01017108 0.0124779  0.01410239] | [0.00585765 0.00453297 0.00380773] | [0.08731211 0.12435266 0.14847796] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.6931473612785339 BPR_loss 0.6931473016738892 reg_loss 3.85700253957566e-08
epoch: 1 s: 256000 batch_loss 0.6931473612785339 BPR_loss 0.6931473016738892 reg_loss 3.3945799060575155e-08
epoch: 1 s: 512000 batch_loss 0.6931467652320862 BPR_loss 0.6931467056274414 reg_loss 4.926985397446515e-08
epoch: 1 s: 768000 batch_loss 0.693031370639801 BPR_loss 0.6930265426635742 reg_loss 4.849540346185677e-06
epoch: 1 s: 1024000 batch_loss 0.6926390528678894 BPR_loss 0.6926214694976807 reg_loss 1.759541373758111e-05
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 197.6134638786316 | 36.15810036659241 | 418.6180114746094 | [0.03656744 0.06051827 0.07966361] | [0.03038701 0.03934617 0.04612066] | [0.01779399 0.01481859 0.01310471] | [0.2497158  0.35515347 0.42187697] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6932808756828308 BPR_loss 0.693266749382019 reg_loss 1.411645735061029e-05
epoch: 2 s: 256000 batch_loss 0.6928070783615112 BPR_loss 0.6927908658981323 reg_loss 1.6190557289519347e-05
epoch: 2 s: 512000 batch_loss 0.6942384243011475 BPR_loss 0.6942248344421387 reg_loss 1.3588567526312545e-05
epoch: 2 s: 768000 batch_loss 0.6933004260063171 BPR_loss 0.6932884454727173 reg_loss 1.197132223751396e-05
epoch: 2 s: 1024000 batch_loss 0.6926693916320801 BPR_loss 0.6926441192626953 reg_loss 2.529816447349731e-05
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 196.3414876461029 | 37.26506543159485 | 418.53594970703125 | [0.04398482 0.07340559 0.09674741] | [0.03613041 0.04726325 0.05552324] | [0.02116806 0.01779793 0.01572302] | [0.29152457 0.41145636 0.48509536] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.6925339102745056 BPR_loss 0.6925145387649536 reg_loss 1.9387587599339895e-05
epoch: 3 s: 256000 batch_loss 0.6924251317977905 BPR_loss 0.6924055814743042 reg_loss 1.9563020032364875e-05
epoch: 3 s: 512000 batch_loss 0.6920199990272522 BPR_loss 0.691987156867981 reg_loss 3.281324461568147e-05
epoch: 3 s: 768000 batch_loss 0.6930550932884216 BPR_loss 0.6930471658706665 reg_loss 7.900400305516087e-06
epoch: 3 s: 1024000 batch_loss 0.6933166980743408 BPR_loss 0.6932876110076904 reg_loss 2.9071152312099002e-05
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 196.48155093193054 | 36.332122802734375 | 418.51202392578125 | [0.04895524 0.08162864 0.10807435] | [0.04029343 0.05274123 0.06206251] | [0.02319218 0.01958128 0.01734138] | [0.31530251 0.4456865  0.52087281] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.6927704215049744 BPR_loss 0.6927521228790283 reg_loss 1.8270817236043513e-05
epoch: 4 s: 256000 batch_loss 0.6925103664398193 BPR_loss 0.6924890875816345 reg_loss 2.12634931813227e-05
epoch: 4 s: 512000 batch_loss 0.6925060749053955 BPR_loss 0.6924856901168823 reg_loss 2.0358391338959336e-05
epoch: 4 s: 768000 batch_loss 0.692818820476532 BPR_loss 0.6928045749664307 reg_loss 1.4264500350691378e-05
epoch: 4 s: 1024000 batch_loss 0.6931722164154053 BPR_loss 0.6931461691856384 reg_loss 2.607118040032219e-05
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 197.67385292053223 | 35.574000120162964 | 418.51287841796875 | [0.04879744 0.08026103 0.10635971] | [0.04056442 0.05239622 0.06163514] | [0.02338165 0.01934524 0.0172098 ] | [0.31681824 0.43611848 0.51307313] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.6920868158340454 BPR_loss 0.6920517683029175 reg_loss 3.502339677652344e-05
epoch: 5 s: 256000 batch_loss 0.6920912861824036 BPR_loss 0.6920617818832397 reg_loss 2.9516331778722815e-05
epoch: 5 s: 512000 batch_loss 0.6921594142913818 BPR_loss 0.6921335458755493 reg_loss 2.584471985755954e-05
epoch: 5 s: 768000 batch_loss 0.6928728818893433 BPR_loss 0.692851185798645 reg_loss 2.1696534531656653e-05
epoch: 5 s: 1024000 batch_loss 0.6926328539848328 BPR_loss 0.6926085948944092 reg_loss 2.426416176604107e-05
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 197.68112015724182 | 37.1269793510437 | 418.5078430175781 | [0.04817078 0.08036504 0.10660057] | [0.03938367 0.05163642 0.06095788] | [0.02273431 0.01914235 0.01708296] | [0.30889226 0.43264494 0.50729443] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.6917685866355896 BPR_loss 0.6917283535003662 reg_loss 4.0206650737673044e-05
epoch: 6 s: 256000 batch_loss 0.6925162076950073 BPR_loss 0.6924850940704346 reg_loss 3.1142873922362924e-05
epoch: 6 s: 512000 batch_loss 0.6928378939628601 BPR_loss 0.6928000450134277 reg_loss 3.784240107052028e-05
epoch: 6 s: 768000 batch_loss 0.6930809617042542 BPR_loss 0.6930525302886963 reg_loss 2.842961657734122e-05
epoch: 6 s: 1024000 batch_loss 0.6928336024284363 BPR_loss 0.6928160786628723 reg_loss 1.753698779793922e-05
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 196.19487619400024 | 36.33727264404297 | 418.499267578125 | [0.04902005 0.08234492 0.10925234] | [0.04043347 0.05312729 0.0626328 ] | [0.02328218 0.01982048 0.01761136] | [0.31495516 0.44334975 0.52140962] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.6924654245376587 BPR_loss 0.6924382448196411 reg_loss 2.7162670448888093e-05
epoch: 7 s: 256000 batch_loss 0.6926968693733215 BPR_loss 0.6926745772361755 reg_loss 2.2267535314313136e-05
epoch: 7 s: 512000 batch_loss 0.6932892799377441 BPR_loss 0.6932680606842041 reg_loss 2.122760452039074e-05
epoch: 7 s: 768000 batch_loss 0.69191575050354 BPR_loss 0.6918695569038391 reg_loss 4.619002720573917e-05
epoch: 7 s: 1024000 batch_loss 0.6921347975730896 BPR_loss 0.6921038627624512 reg_loss 3.096112050116062e-05
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 196.50794410705566 | 34.512670278549194 | 418.4733581542969 | [0.04640058 0.0781039  0.10411039] | [0.03828589 0.05037343 0.05959152] | [0.02208065 0.01878631 0.01677456] | [0.29926108 0.42171909 0.49766326] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.6931306719779968 BPR_loss 0.6931030750274658 reg_loss 2.7571120881475508e-05
epoch: 8 s: 256000 batch_loss 0.69249427318573 BPR_loss 0.6924598813056946 reg_loss 3.43880383297801e-05
epoch: 8 s: 512000 batch_loss 0.6925496459007263 BPR_loss 0.692513108253479 reg_loss 3.655006003100425e-05
epoch: 8 s: 768000 batch_loss 0.6917136311531067 BPR_loss 0.6916635036468506 reg_loss 5.011102621210739e-05
epoch: 8 s: 1024000 batch_loss 0.6926999092102051 BPR_loss 0.6926583051681519 reg_loss 4.1575047362130135e-05
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 197.81278133392334 | 35.993703842163086 | 418.4956970214844 | [0.04601966 0.07784214 0.10417129] | [0.03784763 0.05000287 0.05937853] | [0.02193539 0.01878    0.01689613] | [0.29752431 0.42260326 0.50101048] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.6930536031723022 BPR_loss 0.693001925945282 reg_loss 5.166775736142881e-05
epoch: 9 s: 256000 batch_loss 0.6928954124450684 BPR_loss 0.6928517818450928 reg_loss 4.363281186670065e-05
epoch: 9 s: 512000 batch_loss 0.6925641298294067 BPR_loss 0.6925053596496582 reg_loss 5.876855720998719e-05
epoch: 9 s: 768000 batch_loss 0.692694365978241 BPR_loss 0.6926568746566772 reg_loss 3.7499939935514703e-05
epoch: 9 s: 1024000 batch_loss 0.6930585503578186 BPR_loss 0.6930031180381775 reg_loss 5.543575753108598e-05
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 196.10235118865967 | 35.00653839111328 | 418.46295166015625 | [0.0448345  0.07602534 0.1022497 ] | [0.0368266  0.04871623 0.05805404] | [0.02148857 0.01841133 0.01662193] | [0.29142983 0.41480359 0.49371605] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.6923590898513794 BPR_loss 0.6922980546951294 reg_loss 6.10458810115233e-05
epoch: 10 s: 256000 batch_loss 0.693303644657135 BPR_loss 0.6932549476623535 reg_loss 4.86876379000023e-05
epoch: 10 s: 512000 batch_loss 0.692645788192749 BPR_loss 0.6925954222679138 reg_loss 5.0374259444652125e-05
epoch: 10 s: 768000 batch_loss 0.6920768618583679 BPR_loss 0.6920192837715149 reg_loss 5.7597088016336784e-05
epoch: 10 s: 1024000 batch_loss 0.6937662959098816 BPR_loss 0.6937036514282227 reg_loss 6.26731853117235e-05
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 196.86163783073425 | 36.91589403152466 | 418.4668273925781 | [0.04425393 0.07524773 0.10136767] | [0.03623944 0.04811636 0.05739727] | [0.02113806 0.01819187 0.01641405] | [0.28647215 0.40975117 0.4894215 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.6937533617019653 BPR_loss 0.693703293800354 reg_loss 5.006810897612013e-05
epoch: 11 s: 256000 batch_loss 0.692006528377533 BPR_loss 0.6919437050819397 reg_loss 6.283109541982412e-05
epoch: 11 s: 512000 batch_loss 0.6928516030311584 BPR_loss 0.6928013563156128 reg_loss 5.023396079195663e-05
epoch: 11 s: 768000 batch_loss 0.6922053694725037 BPR_loss 0.6921423673629761 reg_loss 6.30241192993708e-05
epoch: 11 s: 1024000 batch_loss 0.6928054094314575 BPR_loss 0.6927366256713867 reg_loss 6.876281986478716e-05
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 197.05184698104858 | 35.48963022232056 | 418.4508056640625 | [0.04294862 0.07346753 0.09900409] | [0.0353969  0.04704539 0.05606784] | [0.02060755 0.01776478 0.01598091] | [0.27974612 0.40119363 0.48020083] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.6925888061523438 BPR_loss 0.6925379633903503 reg_loss 5.0818205636460334e-05
epoch: 12 s: 256000 batch_loss 0.6921707391738892 BPR_loss 0.6920961737632751 reg_loss 7.459368498530239e-05
epoch: 12 s: 512000 batch_loss 0.6921676397323608 BPR_loss 0.6920969486236572 reg_loss 7.069726416375488e-05
epoch: 12 s: 768000 batch_loss 0.6922889351844788 BPR_loss 0.6922167539596558 reg_loss 7.218591053970158e-05
epoch: 12 s: 1024000 batch_loss 0.6930457353591919 BPR_loss 0.692957878112793 reg_loss 8.783739758655429e-05
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 196.8014075756073 | 36.25859498977661 | 418.4317932128906 | [0.04307731 0.07320521 0.09879896] | [0.03554023 0.04700943 0.05607407] | [0.02068176 0.01774662 0.01602985] | [0.28031451 0.39989895 0.47881142] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 13 s: 0 batch_loss 0.6931692957878113 BPR_loss 0.6930919885635376 reg_loss 7.727879710728303e-05
epoch: 13 s: 256000 batch_loss 0.6925057172775269 BPR_loss 0.6924326419830322 reg_loss 7.306993938982487e-05
epoch: 13 s: 512000 batch_loss 0.6924553513526917 BPR_loss 0.6923705339431763 reg_loss 8.47981937113218e-05
epoch: 13 s: 768000 batch_loss 0.6928932070732117 BPR_loss 0.6928023099899292 reg_loss 9.087798389373347e-05
epoch: 13 s: 1024000 batch_loss 0.6929389238357544 BPR_loss 0.692855954170227 reg_loss 8.297881140606478e-05
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   13  | 196.64578890800476 | 35.47998118400574 | 418.40435791015625 | [0.04161738 0.0711981  0.09639092] | [0.03441018 0.04575882 0.05468389] | [0.0199539  0.01723822 0.01559619] | [0.27096754 0.39074144 0.46804345] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 14 s: 0 batch_loss 0.6929994821548462 BPR_loss 0.6929042339324951 reg_loss 9.52557529672049e-05
epoch: 14 s: 256000 batch_loss 0.6925835013389587 BPR_loss 0.6924778819084167 reg_loss 0.00010560928785707802
epoch: 14 s: 512000 batch_loss 0.693247377872467 BPR_loss 0.6931594610214233 reg_loss 8.789842831902206e-05
epoch: 14 s: 768000 batch_loss 0.6935479044914246 BPR_loss 0.6934361457824707 reg_loss 0.00011173105303896591
epoch: 14 s: 1024000 batch_loss 0.6929087042808533 BPR_loss 0.6927991509437561 reg_loss 0.0001095756670110859
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   14  | 195.13032293319702 | 38.63349962234497 | 418.3998107910156 | [0.04133033 0.070183   0.09489829] | [0.03387654 0.0449499  0.05372803] | [0.0196697  0.01695323 0.01535567] | [0.26812555 0.38559429 0.465012  ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 15 s: 0 batch_loss 0.692455530166626 BPR_loss 0.6923395395278931 reg_loss 0.00011597750562941656
epoch: 15 s: 256000 batch_loss 0.6930108070373535 BPR_loss 0.6929088830947876 reg_loss 0.00010192870104219764
epoch: 15 s: 512000 batch_loss 0.6925458908081055 BPR_loss 0.6924029588699341 reg_loss 0.00014293118147179484
epoch: 15 s: 768000 batch_loss 0.6925826072692871 BPR_loss 0.6924844980239868 reg_loss 9.810342453420162e-05
epoch: 15 s: 1024000 batch_loss 0.6942997574806213 BPR_loss 0.6941885948181152 reg_loss 0.00011118829570477828
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 193.89313650131226 | 38.84076547622681 | 418.3651123046875 | [0.04092006 0.06960979 0.09421155] | [0.03352734 0.04449505 0.05325919] | [0.01959391 0.01687429 0.01533514] | [0.26563092 0.38426803 0.46163319] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 16 s: 0 batch_loss 0.6928002238273621 BPR_loss 0.6926853656768799 reg_loss 0.00011485828144941479
epoch: 16 s: 256000 batch_loss 0.6925984621047974 BPR_loss 0.6924698352813721 reg_loss 0.00012862721632700413
epoch: 16 s: 512000 batch_loss 0.6932504177093506 BPR_loss 0.6931179761886597 reg_loss 0.00013246994058135897
epoch: 16 s: 768000 batch_loss 0.6927021145820618 BPR_loss 0.6925745606422424 reg_loss 0.00012755404168274254
epoch: 16 s: 1024000 batch_loss 0.6923048496246338 BPR_loss 0.6921778321266174 reg_loss 0.0001270073262276128
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   16  | 194.60129046440125 | 38.06396818161011 | 418.3694763183594 | [0.0404563  0.06905755 0.09331337] | [0.03315465 0.04409108 0.05270989] | [0.01927498 0.01660667 0.01504358] | [0.26351522 0.38009979 0.45557029] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.040456296124558255
early stopping at 16, recall@20:0.0490
