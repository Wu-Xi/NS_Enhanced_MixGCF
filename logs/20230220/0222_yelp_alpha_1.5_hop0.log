Namespace(K=1, Ks='[20, 40, 60]', alpha=1.5, batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, gnn='lightgcn', gpu_id=3, l2=0.001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重,引入alpha超参数来控制模型倾向......
start training ...
epoch: 0 s: 0 batch_loss 0.6931489109992981 BPR_loss 0.6931487321853638 reg_loss 1.5227153937757976e-07
epoch: 0 s: 256000 batch_loss 0.6931430697441101 BPR_loss 0.6931416988372803 reg_loss 1.3694055951418704e-06
epoch: 0 s: 512000 batch_loss 0.6929607391357422 BPR_loss 0.6929454803466797 reg_loss 1.5236223589454312e-05
epoch: 0 s: 768000 batch_loss 0.6922024488449097 BPR_loss 0.6921834945678711 reg_loss 1.8958069631480612e-05
epoch: 0 s: 1024000 batch_loss 0.6922903656959534 BPR_loss 0.6922674179077148 reg_loss 2.2968966732150875e-05
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 210.76084852218628 | 51.41621780395508 | 418.44903564453125 | [0.04794509 0.0798603  0.10579799] | [0.0395677  0.05165104 0.06082611] | [0.02276904 0.01914235 0.01702297] | [0.31012378 0.43529746 0.51386257] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.6928319931030273 BPR_loss 0.6927996873855591 reg_loss 3.230180300306529e-05
epoch: 1 s: 256000 batch_loss 0.6919533014297485 BPR_loss 0.6919175386428833 reg_loss 3.578758332878351e-05
epoch: 1 s: 512000 batch_loss 0.6927292943000793 BPR_loss 0.6926933526992798 reg_loss 3.595802263589576e-05
epoch: 1 s: 768000 batch_loss 0.6925259232521057 BPR_loss 0.6924840211868286 reg_loss 4.1924849938368425e-05
epoch: 1 s: 1024000 batch_loss 0.6916362047195435 BPR_loss 0.6915691494941711 reg_loss 6.702597602270544e-05
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 231.41577553749084 | 47.53970265388489 | 418.21575927734375 | [0.04930157 0.08353951 0.11091516] | [0.04082145 0.05378078 0.06345591] | [0.02349059 0.01997995 0.01781662] | [0.31656562 0.44884426 0.5277883 ] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6923648118972778 BPR_loss 0.6922903060913086 reg_loss 7.452690624631941e-05
epoch: 2 s: 256000 batch_loss 0.6923491954803467 BPR_loss 0.6922658681869507 reg_loss 8.33050871733576e-05
epoch: 2 s: 512000 batch_loss 0.6941741704940796 BPR_loss 0.6940833330154419 reg_loss 9.0845933300443e-05
epoch: 2 s: 768000 batch_loss 0.6928622722625732 BPR_loss 0.6927513480186462 reg_loss 0.00011092840577475727
epoch: 2 s: 1024000 batch_loss 0.6904338598251343 BPR_loss 0.6902773976325989 reg_loss 0.0001564790727570653
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 242.16461777687073 | 49.73741960525513 | 417.9950866699219 | [0.0493681  0.08376045 0.11208915] | [0.04057195 0.05363843 0.06364472] | [0.02347954 0.02005652 0.01798714] | [0.3175761  0.44966528 0.53164077] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.6913098692893982 BPR_loss 0.6911391019821167 reg_loss 0.00017075732466764748
epoch: 3 s: 256000 batch_loss 0.6918078660964966 BPR_loss 0.6916298866271973 reg_loss 0.00017795218445826322
epoch: 3 s: 512000 batch_loss 0.6904805302619934 BPR_loss 0.6902579069137573 reg_loss 0.0002226338256150484
epoch: 3 s: 768000 batch_loss 0.6916680932044983 BPR_loss 0.6914454698562622 reg_loss 0.00022264293511398137
epoch: 3 s: 1024000 batch_loss 0.6917232871055603 BPR_loss 0.6914242506027222 reg_loss 0.00029904217808507383
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 254.24356746673584 | 45.894927978515625 | 417.6977844238281 | [0.04995839 0.08468417 0.11301272] | [0.04109141 0.05426781 0.0642888 ] | [0.02373216 0.02026257 0.01816502] | [0.31956549 0.45124416 0.53097764] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.6900476813316345 BPR_loss 0.6897399425506592 reg_loss 0.00030775758204981685
epoch: 4 s: 256000 batch_loss 0.6896851062774658 BPR_loss 0.6893210411071777 reg_loss 0.0003640448267105967
epoch: 4 s: 512000 batch_loss 0.6906076669692993 BPR_loss 0.6902651786804199 reg_loss 0.00034247589064761996
epoch: 4 s: 768000 batch_loss 0.690132200717926 BPR_loss 0.689733624458313 reg_loss 0.0003985569637734443
epoch: 4 s: 1024000 batch_loss 0.6915866732597351 BPR_loss 0.6911983489990234 reg_loss 0.0003883138997480273
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 248.18748450279236 | 46.62657618522644 | 417.3902587890625 | [0.0500979  0.08426088 0.11235186] | [0.04129907 0.05423058 0.06417801] | [0.02370058 0.02012599 0.0180424 ] | [0.31792346 0.44922319 0.52943034] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.6904188394546509 BPR_loss 0.689963698387146 reg_loss 0.0004551564925350249
epoch: 5 s: 256000 batch_loss 0.6894879341125488 BPR_loss 0.6890066862106323 reg_loss 0.00048125439207069576
epoch: 5 s: 512000 batch_loss 0.6901018619537354 BPR_loss 0.6896657943725586 reg_loss 0.0004360698803793639
epoch: 5 s: 768000 batch_loss 0.6909164786338806 BPR_loss 0.6904780864715576 reg_loss 0.000438409362686798
epoch: 5 s: 1024000 batch_loss 0.6903474926948547 BPR_loss 0.6898950338363647 reg_loss 0.0004524537653196603
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 225.5222306251526 | 95.51604890823364 | 417.08111572265625 | [0.04941581 0.08336162 0.11159688] | [0.04070736 0.0536101  0.06362018] | [0.02326639 0.01979996 0.01781872] | [0.31268157 0.44369711 0.52560945] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.6894438862800598 BPR_loss 0.6888754963874817 reg_loss 0.00056839530589059
epoch: 6 s: 256000 batch_loss 0.6905676126480103 BPR_loss 0.6900564432144165 reg_loss 0.0005111513310112059
epoch: 6 s: 512000 batch_loss 0.6887565851211548 BPR_loss 0.6881818771362305 reg_loss 0.0005747221875935793
epoch: 6 s: 768000 batch_loss 0.6893641352653503 BPR_loss 0.6888071894645691 reg_loss 0.0005569675122387707
epoch: 6 s: 1024000 batch_loss 0.6923917531967163 BPR_loss 0.6918575763702393 reg_loss 0.0005341804935596883
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 203.78334140777588 | 107.93809914588928 | 416.7903137207031 | [0.04979327 0.08370823 0.11178993] | [0.04097847 0.05389378 0.06385352] | [0.02344796 0.01998784 0.01794503] | [0.31571302 0.44477075 0.52816724] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.6887679100036621 BPR_loss 0.6881309747695923 reg_loss 0.0006369228358380497
epoch: 7 s: 256000 batch_loss 0.6888483166694641 BPR_loss 0.6881701946258545 reg_loss 0.0006781008560210466
epoch: 7 s: 512000 batch_loss 0.6892836689949036 BPR_loss 0.6885927319526672 reg_loss 0.0006909308722242713
epoch: 7 s: 768000 batch_loss 0.6876491904258728 BPR_loss 0.6869788765907288 reg_loss 0.0006703224498778582
epoch: 7 s: 1024000 batch_loss 0.6901153326034546 BPR_loss 0.6894763708114624 reg_loss 0.0006389791960828006
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |      Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 214.29399609565735 | 56.08154106140137 | 416.5439453125 | [0.04970321 0.08317587 0.11092385] | [0.04065312 0.05338801 0.06323419] | [0.02323639 0.01970049 0.01767083] | [0.31296577 0.44129721 0.52248326] |
+-------+--------------------+-------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.6898229718208313 BPR_loss 0.6891550421714783 reg_loss 0.0006679203943349421
epoch: 8 s: 256000 batch_loss 0.6899375915527344 BPR_loss 0.6891942024230957 reg_loss 0.0007433650898747146
epoch: 8 s: 512000 batch_loss 0.6877637505531311 BPR_loss 0.6868941187858582 reg_loss 0.0008696187869645655
epoch: 8 s: 768000 batch_loss 0.6852300763130188 BPR_loss 0.6843985319137573 reg_loss 0.0008315164013765752
epoch: 8 s: 1024000 batch_loss 0.68961101770401 BPR_loss 0.6888595819473267 reg_loss 0.0007514556054957211
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 221.54179692268372 | 56.010931730270386 | 416.3480529785156 | [0.0500265  0.08348929 0.11162331] | [0.04106184 0.05374968 0.0637109 ] | [0.02354427 0.01988679 0.0178382 ] | [0.316313   0.44451813 0.52478843] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.6888502836227417 BPR_loss 0.6879286766052246 reg_loss 0.0009216300095431507
epoch: 9 s: 256000 batch_loss 0.6897994875907898 BPR_loss 0.6890079975128174 reg_loss 0.0007914622547104955
epoch: 9 s: 512000 batch_loss 0.6881546974182129 BPR_loss 0.6872959136962891 reg_loss 0.00085879594553262
epoch: 9 s: 768000 batch_loss 0.688498854637146 BPR_loss 0.6876853704452515 reg_loss 0.0008134903036989272
epoch: 9 s: 1024000 batch_loss 0.6890549659729004 BPR_loss 0.6881344318389893 reg_loss 0.0009205479873344302
+-------+------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 219.965802192688 | 56.353652238845825 | 416.13232421875 | [0.04985967 0.08318654 0.11096102] | [0.04099176 0.05362032 0.06346356] | [0.02347954 0.01980627 0.01774504] | [0.31555513 0.44240243 0.52134647] |
+-------+------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.6910131573677063 BPR_loss 0.6901297569274902 reg_loss 0.0008833865285851061
epoch: 10 s: 256000 batch_loss 0.6892480850219727 BPR_loss 0.6883644461631775 reg_loss 0.0008836666238494217
epoch: 10 s: 512000 batch_loss 0.6880713701248169 BPR_loss 0.68714439868927 reg_loss 0.0009269940201193094
epoch: 10 s: 768000 batch_loss 0.6877431869506836 BPR_loss 0.6868572235107422 reg_loss 0.000885963614564389
epoch: 10 s: 1024000 batch_loss 0.6908754110336304 BPR_loss 0.6899528503417969 reg_loss 0.0009225765825249255
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 212.9953474998474 | 60.76095652580261 | 415.98724365234375 | [0.04945354 0.08227561 0.109726  ] | [0.04061793 0.05310418 0.06286386] | [0.02307692 0.01946286 0.01747137] | [0.31059745 0.43801314 0.51714665] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.6919929385185242 BPR_loss 0.6911146640777588 reg_loss 0.0008782905642874539
epoch: 11 s: 256000 batch_loss 0.687262237071991 BPR_loss 0.686247706413269 reg_loss 0.001014541368931532
epoch: 11 s: 512000 batch_loss 0.6877778172492981 BPR_loss 0.686839759349823 reg_loss 0.0009380732080899179
epoch: 11 s: 768000 batch_loss 0.6884443759918213 BPR_loss 0.687543511390686 reg_loss 0.0009008648921735585
epoch: 11 s: 1024000 batch_loss 0.6885976195335388 BPR_loss 0.6876127123832703 reg_loss 0.0009848856134340167
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 218.78199195861816 | 50.44900059700012 | 415.8533630371094 | [0.04914984 0.08162601 0.10889466] | [0.04032827 0.05269899 0.06235558] | [0.02286062 0.01927182 0.01725033] | [0.3088291  0.4342554  0.51373626] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.6879125833511353 BPR_loss 0.6869417428970337 reg_loss 0.0009708580328151584
epoch: 12 s: 256000 batch_loss 0.6857959032058716 BPR_loss 0.6848032474517822 reg_loss 0.0009926615748554468
epoch: 12 s: 512000 batch_loss 0.6867027282714844 BPR_loss 0.6856861114501953 reg_loss 0.0010166011052206159
epoch: 12 s: 768000 batch_loss 0.6876952052116394 BPR_loss 0.6867228746414185 reg_loss 0.0009723523398861289
epoch: 12 s: 1024000 batch_loss 0.6852176189422607 BPR_loss 0.6840568780899048 reg_loss 0.0011607592459768057
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 224.0866298675537 | 38.91467022895813 | 415.68951416015625 | [0.04899465 0.081072   0.10813636] | [0.04041854 0.05259859 0.0622107 ] | [0.02293167 0.01924182 0.01727454] | [0.30952381 0.43286598 0.5105785 ] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 13 s: 0 batch_loss 0.68752121925354 BPR_loss 0.6863781213760376 reg_loss 0.0011430971790105104
epoch: 13 s: 256000 batch_loss 0.6892361044883728 BPR_loss 0.6883004307746887 reg_loss 0.0009356532827951014
epoch: 13 s: 512000 batch_loss 0.6880326271057129 BPR_loss 0.6870309114456177 reg_loss 0.0010017434833571315
epoch: 13 s: 768000 batch_loss 0.6891087889671326 BPR_loss 0.6879140138626099 reg_loss 0.001194748212583363
epoch: 13 s: 1024000 batch_loss 0.6913788318634033 BPR_loss 0.6903203129768372 reg_loss 0.0010585016570985317
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   13  | 241.88986468315125 | 38.711711406707764 | 415.5265197753906 | [0.04887861 0.08074285 0.10758374] | [0.04025392 0.05231584 0.06184607] | [0.0228622  0.0191163  0.01714665] | [0.30747126 0.43188708 0.50899962] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 14 s: 0 batch_loss 0.6865711212158203 BPR_loss 0.6854246258735657 reg_loss 0.001146515365689993
epoch: 14 s: 256000 batch_loss 0.6870608925819397 BPR_loss 0.6859488487243652 reg_loss 0.0011120158014819026
epoch: 14 s: 512000 batch_loss 0.6887814998626709 BPR_loss 0.6876477003097534 reg_loss 0.00113381864503026
epoch: 14 s: 768000 batch_loss 0.6881710886955261 BPR_loss 0.6870459318161011 reg_loss 0.0011251616524532437
epoch: 14 s: 1024000 batch_loss 0.6882162094116211 BPR_loss 0.6871126890182495 reg_loss 0.0011035171337425709
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   14  | 227.75745391845703 | 38.73599815368652 | 415.45037841796875 | [0.04887229 0.08052876 0.10763966] | [0.04021584 0.05222591 0.06184962] | [0.02275167 0.01899946 0.01710244] | [0.30652394 0.42853985 0.50792598] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.04887228868263899
early stopping at 14, recall@20:0.0501
