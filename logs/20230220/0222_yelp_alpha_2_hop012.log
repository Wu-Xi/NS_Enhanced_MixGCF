Namespace(K=1, Ks='[20, 40, 60]', alpha=2.0, batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, gnn='lightgcn', gpu_id=2, l2=0.001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重,引入alpha超参数来控制模型倾向......
start training ...
epoch: 0 s: 0 batch_loss 0.6931496262550354 BPR_loss 0.6931494474411011 reg_loss 2.002109056320478e-07
epoch: 0 s: 256000 batch_loss 0.6931482553482056 BPR_loss 0.693148136138916 reg_loss 1.108305767161255e-07
epoch: 0 s: 512000 batch_loss 0.6931478381156921 BPR_loss 0.6931477785110474 reg_loss 7.454075046098296e-08
epoch: 0 s: 768000 batch_loss 0.6931005716323853 BPR_loss 0.6930983066558838 reg_loss 2.248909368063323e-06
epoch: 0 s: 1024000 batch_loss 0.6928136944770813 BPR_loss 0.6927826404571533 reg_loss 3.102517803199589e-05
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 204.46081638336182 | 37.673381328582764 | 418.6325378417969 | [0.03770697 0.06254943 0.08207433] | [0.03159487 0.04083057 0.04774769] | [0.01822502 0.01513594 0.01337891] | [0.25378931 0.35862701 0.4239611 ] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.6931306719779968 BPR_loss 0.6930692195892334 reg_loss 6.147406384116039e-05
epoch: 1 s: 256000 batch_loss 0.6925902366638184 BPR_loss 0.6925376653671265 reg_loss 5.2545998187270015e-05
epoch: 1 s: 512000 batch_loss 0.6929943561553955 BPR_loss 0.6929426193237305 reg_loss 5.1760856877081096e-05
epoch: 1 s: 768000 batch_loss 0.6928564310073853 BPR_loss 0.6928213834762573 reg_loss 3.507493602228351e-05
epoch: 1 s: 1024000 batch_loss 0.692442774772644 BPR_loss 0.6923904418945312 reg_loss 5.234451964497566e-05
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 203.35470151901245 | 37.39335799217224 | 418.52618408203125 | [0.04523116 0.07585814 0.09979099] | [0.03738863 0.04895185 0.05742806] | [0.02153909 0.01816739 0.01608827] | [0.29484022 0.41587723 0.48749526] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6933360695838928 BPR_loss 0.6932899951934814 reg_loss 4.606813672580756e-05
epoch: 2 s: 256000 batch_loss 0.6927255988121033 BPR_loss 0.6926941871643066 reg_loss 3.141396518913098e-05
epoch: 2 s: 512000 batch_loss 0.6944178342819214 BPR_loss 0.6943740844726562 reg_loss 4.3754116632044315e-05
epoch: 2 s: 768000 batch_loss 0.6933364868164062 BPR_loss 0.6933099031448364 reg_loss 2.6606281608110294e-05
epoch: 2 s: 1024000 batch_loss 0.6925821900367737 BPR_loss 0.6925289034843445 reg_loss 5.3287822083802894e-05
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 213.19480395317078 | 38.85075616836548 | 418.5192565917969 | [0.0474468  0.07872736 0.10414352] | [0.03954996 0.0514039  0.06042969] | [0.02265694 0.01902157 0.01690666] | [0.30816597 0.42812934 0.5023999 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.6924465298652649 BPR_loss 0.692398190498352 reg_loss 4.834635183215141e-05
epoch: 3 s: 256000 batch_loss 0.6923671960830688 BPR_loss 0.6923089027404785 reg_loss 5.826602136949077e-05
epoch: 3 s: 512000 batch_loss 0.6918657422065735 BPR_loss 0.691809356212616 reg_loss 5.637880531139672e-05
epoch: 3 s: 768000 batch_loss 0.6930645108222961 BPR_loss 0.6930347681045532 reg_loss 2.9760689358226955e-05
epoch: 3 s: 1024000 batch_loss 0.6933140754699707 BPR_loss 0.6932560801506042 reg_loss 5.797380435978994e-05
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 219.86796307563782 | 39.31442666053772 | 418.49444580078125 | [0.04872588 0.08200716 0.10909306] | [0.04013809 0.05279996 0.0623995 ] | [0.02326165 0.01978811 0.01764768] | [0.31378679 0.44136036 0.51784135] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.6927102208137512 BPR_loss 0.6926592588424683 reg_loss 5.094272273709066e-05
epoch: 4 s: 256000 batch_loss 0.6924186944961548 BPR_loss 0.6923649311065674 reg_loss 5.375078399083577e-05
epoch: 4 s: 512000 batch_loss 0.6924173831939697 BPR_loss 0.6923629641532898 reg_loss 5.443329791887663e-05
epoch: 4 s: 768000 batch_loss 0.6927425265312195 BPR_loss 0.6926997900009155 reg_loss 4.2753632442327216e-05
epoch: 4 s: 1024000 batch_loss 0.693103551864624 BPR_loss 0.6930407285690308 reg_loss 6.279536319198087e-05
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 217.92892694473267 | 43.455002546310425 | 418.4892883300781 | [0.04488163 0.07510137 0.10059348] | [0.03709575 0.04863391 0.05767662] | [0.02148225 0.0182416  0.01635668] | [0.29070355 0.4106985  0.48496905] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.6919111609458923 BPR_loss 0.6918329000473022 reg_loss 7.825040665920824e-05
epoch: 5 s: 256000 batch_loss 0.6919441819190979 BPR_loss 0.6918830871582031 reg_loss 6.111952825449407e-05
epoch: 5 s: 512000 batch_loss 0.6920409202575684 BPR_loss 0.6919655203819275 reg_loss 7.541933155152947e-05
epoch: 5 s: 768000 batch_loss 0.6927879452705383 BPR_loss 0.692731499671936 reg_loss 5.6466247770003974e-05
epoch: 5 s: 1024000 batch_loss 0.6925481557846069 BPR_loss 0.6924746036529541 reg_loss 7.356734568020329e-05
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 243.9614884853363 | 63.25489664077759 | 418.4727478027344 | [0.04459852 0.07488365 0.10040852] | [0.03676415 0.04832276 0.05741346] | [0.02142699 0.01820134 0.01637457] | [0.2876721  0.40757231 0.48449539] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.6915408372879028 BPR_loss 0.691450834274292 reg_loss 8.998627890832722e-05
epoch: 6 s: 256000 batch_loss 0.6925034523010254 BPR_loss 0.6924254298210144 reg_loss 7.801417086739093e-05
epoch: 6 s: 512000 batch_loss 0.6927148103713989 BPR_loss 0.69260174036026 reg_loss 0.00011309130786685273
epoch: 6 s: 768000 batch_loss 0.6929529905319214 BPR_loss 0.6928625106811523 reg_loss 9.050425433088094e-05
epoch: 6 s: 1024000 batch_loss 0.6930006146430969 BPR_loss 0.6929222345352173 reg_loss 7.83987416070886e-05
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 245.14087343215942 | 69.23946809768677 | 418.44708251953125 | [0.0431415  0.07276576 0.09768057] | [0.03549297 0.04685952 0.05571268] | [0.02052071 0.01760531 0.01584565] | [0.27958823 0.39693066 0.47439055] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.6922851800918579 BPR_loss 0.6921948194503784 reg_loss 9.038198186317459e-05
epoch: 7 s: 256000 batch_loss 0.6924813985824585 BPR_loss 0.6923770904541016 reg_loss 0.00010432642011437565
epoch: 7 s: 512000 batch_loss 0.693293035030365 BPR_loss 0.6931755542755127 reg_loss 0.00011749397526727989
epoch: 7 s: 768000 batch_loss 0.6915980577468872 BPR_loss 0.6914664506912231 reg_loss 0.00013160830712877214
epoch: 7 s: 1024000 batch_loss 0.6919869780540466 BPR_loss 0.6918680667877197 reg_loss 0.0001188891546917148
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 240.58649682998657 | 79.97602605819702 | 418.3965759277344 | [0.04088436 0.07020038 0.09470481] | [0.03385164 0.04507454 0.05378656] | [0.01957497 0.01696823 0.01536041] | [0.26591512 0.38316281 0.45983327] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.6928999423980713 BPR_loss 0.6927813291549683 reg_loss 0.00011863942927448079
epoch: 8 s: 256000 batch_loss 0.6924213767051697 BPR_loss 0.6922906041145325 reg_loss 0.00013078897609375417
epoch: 8 s: 512000 batch_loss 0.6924278140068054 BPR_loss 0.6922680735588074 reg_loss 0.00015971710672602057
epoch: 8 s: 768000 batch_loss 0.6911523938179016 BPR_loss 0.6909949779510498 reg_loss 0.00015740227536298335
epoch: 8 s: 1024000 batch_loss 0.6924651265144348 BPR_loss 0.6923035383224487 reg_loss 0.00016159737424459308
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 243.41403102874756 | 101.65368390083313 | 418.3919982910156 | [0.04123294 0.07043095 0.09447614] | [0.03407538 0.04522219 0.05377431] | [0.01983548 0.0170977  0.01536883] | [0.26916761 0.38663635 0.46100164] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.6929172277450562 BPR_loss 0.692740797996521 reg_loss 0.00017644243780523539
epoch: 9 s: 256000 batch_loss 0.6925704479217529 BPR_loss 0.6924130916595459 reg_loss 0.0001573502813698724
epoch: 9 s: 512000 batch_loss 0.6922702789306641 BPR_loss 0.692070484161377 reg_loss 0.00019981033983640373
epoch: 9 s: 768000 batch_loss 0.692367672920227 BPR_loss 0.6922001838684082 reg_loss 0.0001674739905865863
epoch: 9 s: 1024000 batch_loss 0.6931281685829163 BPR_loss 0.6929289698600769 reg_loss 0.0001991863246075809
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 245.45211338996887 | 101.06574726104736 | 418.3306579589844 | [0.03970494 0.06813912 0.09166598] | [0.03273448 0.04367693 0.05205139] | [0.01900657 0.01651115 0.01488622] | [0.25761021 0.3730264  0.4466654 ] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.6924988627433777 BPR_loss 0.6922878623008728 reg_loss 0.0002110223867930472
epoch: 10 s: 256000 batch_loss 0.6931812763214111 BPR_loss 0.6929703950881958 reg_loss 0.0002108878834405914
epoch: 10 s: 512000 batch_loss 0.6922780275344849 BPR_loss 0.6920654773712158 reg_loss 0.0002125507453456521
epoch: 10 s: 768000 batch_loss 0.6917033195495605 BPR_loss 0.691500723361969 reg_loss 0.00020257470896467566
epoch: 10 s: 1024000 batch_loss 0.693718671798706 BPR_loss 0.693484902381897 reg_loss 0.00023375044111162424
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 243.21063542366028 | 103.6805100440979 | 418.3086853027344 | [0.04011472 0.0681678  0.0912339 ] | [0.03291447 0.04374811 0.05197491] | [0.01896394 0.01641641 0.01474675] | [0.25963117 0.3742895  0.44704433] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.6940820813179016 BPR_loss 0.6938768029212952 reg_loss 0.00020526116713881493
epoch: 11 s: 256000 batch_loss 0.6914889216423035 BPR_loss 0.691228985786438 reg_loss 0.0002599417348392308
epoch: 11 s: 512000 batch_loss 0.6924636960029602 BPR_loss 0.692257285118103 reg_loss 0.00020641657465603203
epoch: 11 s: 768000 batch_loss 0.6917608380317688 BPR_loss 0.6915496587753296 reg_loss 0.00021115504205226898
epoch: 11 s: 1024000 batch_loss 0.6923540830612183 BPR_loss 0.6920764446258545 reg_loss 0.0002776101464405656
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 243.00150561332703 | 104.28621625900269 | 418.2678527832031 | [0.03929753 0.06692313 0.0899629 ] | [0.0322799  0.04289978 0.05110359] | [0.01864974 0.01609906 0.01452781] | [0.25378931 0.36743716 0.44101301] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.6923320889472961 BPR_loss 0.6920895576477051 reg_loss 0.00024254340678453445
epoch: 12 s: 256000 batch_loss 0.6913828253746033 BPR_loss 0.6910898089408875 reg_loss 0.0002930350601673126
epoch: 12 s: 512000 batch_loss 0.691730797290802 BPR_loss 0.691470742225647 reg_loss 0.00026006458210758865
epoch: 12 s: 768000 batch_loss 0.69198077917099 BPR_loss 0.6916968822479248 reg_loss 0.00028390687657520175
epoch: 12 s: 1024000 batch_loss 0.6926265954971313 BPR_loss 0.6922997236251831 reg_loss 0.00032687507336959243
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 239.08443784713745 | 59.79134249687195 | 418.2182312011719 | [0.03884977 0.06595363 0.08878587] | [0.03206736 0.04245377 0.05057009] | [0.01835607 0.01585354 0.01432834] | [0.25025262 0.36124795 0.43602375] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 13 s: 0 batch_loss 0.6929841041564941 BPR_loss 0.6926894783973694 reg_loss 0.00029460855876095593
epoch: 13 s: 256000 batch_loss 0.6922650337219238 BPR_loss 0.6919775009155273 reg_loss 0.00028756153187714517
epoch: 13 s: 512000 batch_loss 0.692049503326416 BPR_loss 0.6917253732681274 reg_loss 0.00032412874861620367
epoch: 13 s: 768000 batch_loss 0.6930476427078247 BPR_loss 0.692683219909668 reg_loss 0.0003644476819317788
epoch: 13 s: 1024000 batch_loss 0.6930835843086243 BPR_loss 0.692772626876831 reg_loss 0.00031096587190404534
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   13  | 238.6997697353363 | 54.30493927001953 | 418.1553955078125 | [0.0379842  0.06428896 0.08627175] | [0.03133546 0.04139769 0.04924544] | [0.01796924 0.01538619 0.01391468] | [0.24390552 0.35303777 0.42430845] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.03798419662361649
early stopping at 13, recall@20:0.0487
