Namespace(K=1, Ks='[20, 40, 60]', alpha=1.3, batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, gnn='lightgcn', gpu_id=2, l2=0.001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重,引入alpha超参数来控制模型倾向......
start training ...
epoch: 0 s: 0 batch_loss 0.6931483149528503 BPR_loss 0.6931481957435608 reg_loss 1.414522756704173e-07
epoch: 0 s: 256000 batch_loss 0.6931436061859131 BPR_loss 0.6931430101394653 reg_loss 5.81200254146097e-07
epoch: 0 s: 512000 batch_loss 0.6929560303688049 BPR_loss 0.6929429769515991 reg_loss 1.3053717339062132e-05
epoch: 0 s: 768000 batch_loss 0.6922916173934937 BPR_loss 0.6922711133956909 reg_loss 2.048777423624415e-05
epoch: 0 s: 1024000 batch_loss 0.6923172473907471 BPR_loss 0.6922863125801086 reg_loss 3.091640610364266e-05
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 199.34125900268555 | 34.68676781654358 | 418.4585876464844 | [0.04818494 0.08081604 0.10663022] | [0.03972765 0.05208251 0.06121036] | [0.02289851 0.01933103 0.01712981] | [0.31356574 0.44063408 0.51894657] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.692796528339386 BPR_loss 0.6927512884140015 reg_loss 4.525561962509528e-05
epoch: 1 s: 256000 batch_loss 0.6919170618057251 BPR_loss 0.6918696761131287 reg_loss 4.737803101306781e-05
epoch: 1 s: 512000 batch_loss 0.6927807927131653 BPR_loss 0.6927372217178345 reg_loss 4.356806311989203e-05
epoch: 1 s: 768000 batch_loss 0.6924658417701721 BPR_loss 0.692418098449707 reg_loss 4.772873944602907e-05
epoch: 1 s: 1024000 batch_loss 0.6917136907577515 BPR_loss 0.6916400194168091 reg_loss 7.367712532868609e-05
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 199.67743062973022 | 33.51106119155884 | 418.2145080566406 | [0.04973424 0.08371868 0.11168684] | [0.04089983 0.05383287 0.06368118] | [0.02349691 0.01997205 0.0178403 ] | [0.32019704 0.45099154 0.5320197 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6924150586128235 BPR_loss 0.6923373341560364 reg_loss 7.771422679070383e-05
epoch: 2 s: 256000 batch_loss 0.6924097537994385 BPR_loss 0.6923277974128723 reg_loss 8.195824921131134e-05
epoch: 2 s: 512000 batch_loss 0.6942843794822693 BPR_loss 0.6942065358161926 reg_loss 7.781805470585823e-05
epoch: 2 s: 768000 batch_loss 0.6928220391273499 BPR_loss 0.6927295923233032 reg_loss 9.243763634003699e-05
epoch: 2 s: 1024000 batch_loss 0.6905915141105652 BPR_loss 0.6904414892196655 reg_loss 0.00015001962310634553
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 197.3337118625641 | 33.29582691192627 | 418.0415344238281 | [0.05019528 0.0852727  0.11373969] | [0.04135545 0.05463949 0.06467661] | [0.02380163 0.02031151 0.01816871] | [0.32177593 0.45667551 0.53877731] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.6914469599723816 BPR_loss 0.6912934184074402 reg_loss 0.000153543587657623
epoch: 3 s: 256000 batch_loss 0.6918048858642578 BPR_loss 0.6916491389274597 reg_loss 0.00015574241115245968
epoch: 3 s: 512000 batch_loss 0.690646231174469 BPR_loss 0.6904408931732178 reg_loss 0.00020535034127533436
epoch: 3 s: 768000 batch_loss 0.6919594407081604 BPR_loss 0.6917579770088196 reg_loss 0.00020146519818808883
epoch: 3 s: 1024000 batch_loss 0.6917815804481506 BPR_loss 0.6915050745010376 reg_loss 0.00027648257673718035
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 196.32826733589172 | 34.682504415512085 | 417.79583740234375 | [0.05045754 0.08554081 0.11402139] | [0.04147639 0.05476393 0.06479447] | [0.02394531 0.0204394  0.01825713] | [0.32351269 0.45727548 0.53798787] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.6903553009033203 BPR_loss 0.690059244632721 reg_loss 0.00029604119481518865
epoch: 4 s: 256000 batch_loss 0.6900354027748108 BPR_loss 0.6896876096725464 reg_loss 0.0003477870486676693
epoch: 4 s: 512000 batch_loss 0.690882682800293 BPR_loss 0.6905664801597595 reg_loss 0.00031619222136214375
epoch: 4 s: 768000 batch_loss 0.6904288530349731 BPR_loss 0.6900670528411865 reg_loss 0.0003617769689299166
epoch: 4 s: 1024000 batch_loss 0.6917473077774048 BPR_loss 0.691379725933075 reg_loss 0.00036759013892151415
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 198.90673828125  | 34.666218757629395 | 417.5392761230469 | [0.05047312 0.08542492 0.11359294] | [0.04152824 0.05480756 0.06476109] | [0.02380163 0.02034704 0.01817818] | [0.32086017 0.45522294 0.53530378] |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.690782904624939 BPR_loss 0.6903434991836548 reg_loss 0.00043942476622760296
epoch: 5 s: 256000 batch_loss 0.690180778503418 BPR_loss 0.6897096633911133 reg_loss 0.00047111581079661846
epoch: 5 s: 512000 batch_loss 0.690430760383606 BPR_loss 0.6900085210800171 reg_loss 0.0004222200077492744
epoch: 5 s: 768000 batch_loss 0.6910941004753113 BPR_loss 0.6906752586364746 reg_loss 0.00041884093661792576
epoch: 5 s: 1024000 batch_loss 0.6906078457832336 BPR_loss 0.6901652812957764 reg_loss 0.0004425763327162713
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 197.30236268043518 | 35.37678337097168 | 417.2753601074219 | [0.05030649 0.08499407 0.11365042] | [0.04139796 0.05460185 0.06469557] | [0.023699   0.02021915 0.01808608] | [0.31836554 0.45320197 0.53410383] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.6896965503692627 BPR_loss 0.6891337037086487 reg_loss 0.0005628488725051284
epoch: 6 s: 256000 batch_loss 0.6909404993057251 BPR_loss 0.6904318928718567 reg_loss 0.00050858233589679
epoch: 6 s: 512000 batch_loss 0.6893509030342102 BPR_loss 0.6887859106063843 reg_loss 0.0005649842205457389
epoch: 6 s: 768000 batch_loss 0.6898386478424072 BPR_loss 0.6892820596694946 reg_loss 0.0005566119798459113
epoch: 6 s: 1024000 batch_loss 0.6925035715103149 BPR_loss 0.6919962763786316 reg_loss 0.0005072939675301313
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 196.74392366409302 | 34.327205657958984 | 417.0238952636719 | [0.05074603 0.0853966  0.11405314] | [0.04173583 0.05488208 0.06502053] | [0.02392952 0.02035099 0.01825976] | [0.32051282 0.45389668 0.53561955] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.689289927482605 BPR_loss 0.6886415481567383 reg_loss 0.0006483810138888657
epoch: 7 s: 256000 batch_loss 0.6892057061195374 BPR_loss 0.6885300874710083 reg_loss 0.0006755925714969635
epoch: 7 s: 512000 batch_loss 0.6895840167999268 BPR_loss 0.6888951063156128 reg_loss 0.0006888810312375426
epoch: 7 s: 768000 batch_loss 0.6883570551872253 BPR_loss 0.6876779794692993 reg_loss 0.0006790923071093857
epoch: 7 s: 1024000 batch_loss 0.690376877784729 BPR_loss 0.6897552609443665 reg_loss 0.000621626153588295
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 197.4657337665558 | 34.86630892753601 | 416.8209533691406 | [0.05054174 0.08480487 0.11366788] | [0.04137019 0.05439762 0.0645986 ] | [0.02370058 0.02013468 0.01811345] | [0.31918656 0.45070734 0.53318808] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.6903552412986755 BPR_loss 0.6896867752075195 reg_loss 0.00066843640524894
epoch: 8 s: 256000 batch_loss 0.6903795003890991 BPR_loss 0.6896421909332275 reg_loss 0.0007372890831902623
epoch: 8 s: 512000 batch_loss 0.6887178421020508 BPR_loss 0.6878516674041748 reg_loss 0.000866156886331737
epoch: 8 s: 768000 batch_loss 0.6861997842788696 BPR_loss 0.6853592395782471 reg_loss 0.0008405217668041587
epoch: 8 s: 1024000 batch_loss 0.6901038885116577 BPR_loss 0.6893582344055176 reg_loss 0.0007456838502548635
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 197.90814781188965 | 35.494370460510254 | 416.6609191894531 | [0.05090482 0.08541323 0.11429522] | [0.04171457 0.05485598 0.06508236] | [0.02388373 0.02029967 0.01822765] | [0.32158646 0.45500189 0.53656688] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.6894919276237488 BPR_loss 0.6885760426521301 reg_loss 0.0009158983011730015
epoch: 9 s: 256000 batch_loss 0.6903015375137329 BPR_loss 0.6895124912261963 reg_loss 0.0007890250999480486
epoch: 9 s: 512000 batch_loss 0.6886635422706604 BPR_loss 0.6878145933151245 reg_loss 0.0008489446481689811
epoch: 9 s: 768000 batch_loss 0.6892092823982239 BPR_loss 0.6884233951568604 reg_loss 0.0007858597673475742
epoch: 9 s: 1024000 batch_loss 0.6894655823707581 BPR_loss 0.6885532140731812 reg_loss 0.0009123903000727296
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 198.77088332176208 | 34.28153133392334 | 416.4787902832031 | [0.05100637 0.0853464  0.11419182] | [0.04175061 0.05483549 0.06503814] | [0.02393741 0.02033125 0.01823976] | [0.32174435 0.45342301 0.53580902] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.6910983324050903 BPR_loss 0.6902226805686951 reg_loss 0.0008756387396715581
epoch: 10 s: 256000 batch_loss 0.6896189451217651 BPR_loss 0.6887688636779785 reg_loss 0.0008500874391756952
epoch: 10 s: 512000 batch_loss 0.6887854337692261 BPR_loss 0.6878635883331299 reg_loss 0.0009218159248121083
epoch: 10 s: 768000 batch_loss 0.6883141994476318 BPR_loss 0.6874169707298279 reg_loss 0.0008972492069005966
epoch: 10 s: 1024000 batch_loss 0.6909234523773193 BPR_loss 0.6900084614753723 reg_loss 0.000914975069463253
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 198.37508487701416 | 33.29695796966553 | 416.3608703613281 | [0.05103443 0.0849619  0.11338479] | [0.04178304 0.05467849 0.06476014] | [0.02386478 0.02015284 0.01807977] | [0.31953391 0.45137047 0.53148288] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.6923367381095886 BPR_loss 0.6914730072021484 reg_loss 0.0008637020364403725
epoch: 11 s: 256000 batch_loss 0.6882045865058899 BPR_loss 0.6872017979621887 reg_loss 0.0010028027463704348
epoch: 11 s: 512000 batch_loss 0.68864506483078 BPR_loss 0.6877263188362122 reg_loss 0.000918747391551733
epoch: 11 s: 768000 batch_loss 0.6889301538467407 BPR_loss 0.6880166530609131 reg_loss 0.000913508702069521
epoch: 11 s: 1024000 batch_loss 0.6892716884613037 BPR_loss 0.6883140802383423 reg_loss 0.0009576023439876735
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 197.49867057800293 | 35.80144476890564 | 416.25067138671875 | [0.05079601 0.08467057 0.11276296] | [0.0415643  0.05443046 0.06437431] | [0.02375426 0.02004547 0.01793188] | [0.31966022 0.44988632 0.52936718] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.6886208057403564 BPR_loss 0.6876790523529053 reg_loss 0.0009417558321729302
epoch: 12 s: 256000 batch_loss 0.6866470575332642 BPR_loss 0.6856748461723328 reg_loss 0.0009722391841933131
epoch: 12 s: 512000 batch_loss 0.6875565648078918 BPR_loss 0.6865417957305908 reg_loss 0.0010147398570552468
epoch: 12 s: 768000 batch_loss 0.6882196664810181 BPR_loss 0.6872803568840027 reg_loss 0.0009393256041221321
epoch: 12 s: 1024000 batch_loss 0.686524510383606 BPR_loss 0.685387134552002 reg_loss 0.0011373875895515084
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 196.15174174308777 | 34.51009798049927 | 416.12042236328125 | [0.05080026 0.08448971 0.11251055] | [0.04170864 0.05446321 0.06440751] | [0.02388215 0.02008336 0.01799398] | [0.31915498 0.44852848 0.5289251 ] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 13 s: 0 batch_loss 0.6885181069374084 BPR_loss 0.6873912811279297 reg_loss 0.0011268537491559982
epoch: 13 s: 256000 batch_loss 0.6897624135017395 BPR_loss 0.6888576745986938 reg_loss 0.0009047681232914329
epoch: 13 s: 512000 batch_loss 0.6887310147285461 BPR_loss 0.6877619028091431 reg_loss 0.0009691044688224792
epoch: 13 s: 768000 batch_loss 0.6896927952766418 BPR_loss 0.6885359287261963 reg_loss 0.0011568828485906124
epoch: 13 s: 1024000 batch_loss 0.6915135383605957 BPR_loss 0.69047611951828 reg_loss 0.0010374065022915602
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   13  | 198.56118297576904 | 36.06732130050659 | 415.9905090332031 | [0.05022579 0.08363595 0.1117275 ] | [0.04123526 0.05391266 0.06386531] | [0.02353638 0.01982838 0.01779241] | [0.31599722 0.44546545 0.52620942] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 14 s: 0 batch_loss 0.6876267790794373 BPR_loss 0.6865067481994629 reg_loss 0.0011200456647202373
epoch: 14 s: 256000 batch_loss 0.6879485249519348 BPR_loss 0.6868472099304199 reg_loss 0.001101324101909995
epoch: 14 s: 512000 batch_loss 0.6895172595977783 BPR_loss 0.6884225606918335 reg_loss 0.0010946691036224365
epoch: 14 s: 768000 batch_loss 0.6893385052680969 BPR_loss 0.6882549524307251 reg_loss 0.001083575189113617
epoch: 14 s: 1024000 batch_loss 0.6887682676315308 BPR_loss 0.6876904964447021 reg_loss 0.0010777957504615188
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   14  | 194.22996640205383 | 36.95943832397461 | 415.9246520996094 | [0.05069592 0.08337597 0.11114402] | [0.04141679 0.05381635 0.06365218] | [0.02363585 0.01972338 0.01766189] | [0.31716559 0.44284451 0.52191487] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 15 s: 0 batch_loss 0.6889371275901794 BPR_loss 0.6878013610839844 reg_loss 0.001135768136009574
epoch: 15 s: 256000 batch_loss 0.6905800700187683 BPR_loss 0.6894485950469971 reg_loss 0.0011314760195091367
epoch: 15 s: 512000 batch_loss 0.6894598603248596 BPR_loss 0.6882486343383789 reg_loss 0.0012112336698919535
epoch: 15 s: 768000 batch_loss 0.6884049773216248 BPR_loss 0.6873592138290405 reg_loss 0.0010457740863785148
epoch: 15 s: 1024000 batch_loss 0.6903095841407776 BPR_loss 0.6892209053039551 reg_loss 0.0010886635864153504
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 193.6562042236328 | 37.15642261505127 | 415.8505554199219 | [0.050168   0.08335344 0.11115741] | [0.04127225 0.05386207 0.06370667] | [0.02350322 0.01977469 0.01771504] | [0.3144815  0.44464444 0.52320955] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 16 s: 0 batch_loss 0.6890895366668701 BPR_loss 0.6879414916038513 reg_loss 0.0011480171233415604
epoch: 16 s: 256000 batch_loss 0.6868284344673157 BPR_loss 0.6856133341789246 reg_loss 0.0012151211267337203
epoch: 16 s: 512000 batch_loss 0.6880725622177124 BPR_loss 0.6867647171020508 reg_loss 0.001307823695242405
epoch: 16 s: 768000 batch_loss 0.6881245374679565 BPR_loss 0.6869411468505859 reg_loss 0.0011833985336124897
epoch: 16 s: 1024000 batch_loss 0.687994122505188 BPR_loss 0.6868376135826111 reg_loss 0.001156480167992413
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   16  | 195.17397379875183 | 37.12829661369324 | 415.8250427246094 | [0.04938279 0.08186412 0.10950925] | [0.04068361 0.05301321 0.06281599] | [0.02308955 0.01933261 0.01738085] | [0.3099659  0.43545535 0.51616774] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 17 s: 0 batch_loss 0.6869100332260132 BPR_loss 0.6856386661529541 reg_loss 0.0012713494943454862
epoch: 17 s: 256000 batch_loss 0.6890444159507751 BPR_loss 0.6879153251647949 reg_loss 0.0011291096452623606
epoch: 17 s: 512000 batch_loss 0.6875697374343872 BPR_loss 0.6864269375801086 reg_loss 0.001142791355960071
epoch: 17 s: 768000 batch_loss 0.6907864212989807 BPR_loss 0.6895512342453003 reg_loss 0.001235215226188302
epoch: 17 s: 1024000 batch_loss 0.6893446445465088 BPR_loss 0.6880582571029663 reg_loss 0.0012863903539255261
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   17  | 193.18611550331116 | 36.530049562454224 | 415.7541198730469 | [0.04977816 0.0821386  0.10969141] | [0.04093073 0.05318587 0.06293942] | [0.02329323 0.01943444 0.01741664] | [0.3123658  0.43769736 0.51613616] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 18 s: 0 batch_loss 0.6903603672981262 BPR_loss 0.6891359090805054 reg_loss 0.001224462641403079
epoch: 18 s: 256000 batch_loss 0.6904540657997131 BPR_loss 0.689222514629364 reg_loss 0.0012315681669861078
epoch: 18 s: 512000 batch_loss 0.6866879463195801 BPR_loss 0.6853803396224976 reg_loss 0.0013076213654130697
epoch: 18 s: 768000 batch_loss 0.6889013051986694 BPR_loss 0.6876736879348755 reg_loss 0.0012276292545720935
epoch: 18 s: 1024000 batch_loss 0.6877763271331787 BPR_loss 0.6865341663360596 reg_loss 0.0012421829160302877
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   18  | 193.56632018089294 | 36.355074882507324 | 415.68804931640625 | [0.04947135 0.08183621 0.10893807] | [0.04070167 0.05297406 0.06257429] | [0.0231085  0.0193405  0.01730559] | [0.30990274 0.433687   0.51177845] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 19 s: 0 batch_loss 0.687601625919342 BPR_loss 0.6863570213317871 reg_loss 0.0012446099426597357
epoch: 19 s: 256000 batch_loss 0.687973141670227 BPR_loss 0.6867296695709229 reg_loss 0.0012434624368324876
epoch: 19 s: 512000 batch_loss 0.6879252195358276 BPR_loss 0.6867687106132507 reg_loss 0.0011564973974600434
epoch: 19 s: 768000 batch_loss 0.6884309649467468 BPR_loss 0.6872286796569824 reg_loss 0.0012023000745102763
epoch: 19 s: 1024000 batch_loss 0.6871717572212219 BPR_loss 0.6858248114585876 reg_loss 0.0013469456462189555
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   19  | 193.05676221847534 | 37.44648480415344 | 415.5936279296875 | [0.04947819 0.08169527 0.10842644] | [0.0407272  0.05293291 0.06240903] | [0.02308008 0.01929471 0.01721822] | [0.30987116 0.4334028  0.51073639] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 20 s: 0 batch_loss 0.6884357333183289 BPR_loss 0.6873088479042053 reg_loss 0.0011268872767686844
epoch: 20 s: 256000 batch_loss 0.6878788471221924 BPR_loss 0.6866228580474854 reg_loss 0.0012559746392071247
epoch: 20 s: 512000 batch_loss 0.6863601207733154 BPR_loss 0.6849727034568787 reg_loss 0.001387435127981007
epoch: 20 s: 768000 batch_loss 0.687308669090271 BPR_loss 0.6858698129653931 reg_loss 0.0014388813870027661
epoch: 20 s: 1024000 batch_loss 0.687339186668396 BPR_loss 0.6859844326972961 reg_loss 0.0013547423295676708
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 192.58806133270264 | 35.82239508628845 | 415.5390930175781 | [0.04893012 0.08096101 0.1074347 ] | [0.04031682 0.05251574 0.06188327] | [0.02274378 0.01912498 0.01705191] | [0.30683971 0.42932929 0.50644183] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.048930119469303424
early stopping at 20, recall@20:0.0510
