Namespace(K=1, Ks='[20, 40, 60]', alpha=3.0, batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, gnn='lightgcn', gpu_id=2, l2=0.001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重,引入alpha超参数来控制模型倾向......
start training ...
epoch: 0 s: 0 batch_loss 0.6931492686271667 BPR_loss 0.6931490302085876 reg_loss 2.3686683903179073e-07
epoch: 0 s: 256000 batch_loss 0.6931300163269043 BPR_loss 0.6931222677230835 reg_loss 7.744870345050003e-06
epoch: 0 s: 512000 batch_loss 0.6913687586784363 BPR_loss 0.6906116604804993 reg_loss 0.0007571037276647985
epoch: 0 s: 768000 batch_loss 0.6823603510856628 BPR_loss 0.6776212453842163 reg_loss 0.004739083349704742
epoch: 0 s: 1024000 batch_loss 0.6681442260742188 BPR_loss 0.6566372513771057 reg_loss 0.011506983079016209
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 196.0682668685913 | 35.06187438964844 | 412.4351806640625 | [0.0004351  0.00070152 0.00088839] | [0.00040244 0.00048964 0.00055181] | [0.00024788 0.00019894 0.00016999] | [0.00483138 0.00770494 0.00975748] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.6579840183258057 BPR_loss 0.6403079628944397 reg_loss 0.01767602749168873
epoch: 1 s: 256000 batch_loss 0.6454454064369202 BPR_loss 0.621286153793335 reg_loss 0.024159230291843414
epoch: 1 s: 512000 batch_loss 0.6338346004486084 BPR_loss 0.6034397482872009 reg_loss 0.030394837260246277
epoch: 1 s: 768000 batch_loss 0.6236057877540588 BPR_loss 0.5869084000587463 reg_loss 0.036697402596473694
epoch: 1 s: 1024000 batch_loss 0.6164942383766174 BPR_loss 0.5748246312141418 reg_loss 0.04166962578892708
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 197.84769916534424 | 35.91434144973755 | 381.861572265625 | [0.00050077 0.00086517 0.0012089 ] | [0.00044281 0.00056401 0.00067681] | [0.0002842  0.00023841 0.0002142 ] | [0.00549451 0.00922066 0.01244158] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6098737120628357 BPR_loss 0.5640053749084473 reg_loss 0.04586835578083992
epoch: 2 s: 256000 batch_loss 0.6057335138320923 BPR_loss 0.556540846824646 reg_loss 0.04919266328215599
epoch: 2 s: 512000 batch_loss 0.5994542241096497 BPR_loss 0.546055257320404 reg_loss 0.053398989140987396
epoch: 2 s: 768000 batch_loss 0.5931749939918518 BPR_loss 0.5364863872528076 reg_loss 0.05668862909078598
epoch: 2 s: 1024000 batch_loss 0.587079644203186 BPR_loss 0.5270980000495911 reg_loss 0.05998161807656288
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 196.13391780853271 | 37.85907030105591 | 360.8708190917969 | [0.00056828 0.00096912 0.00124373] | [0.00048068 0.00061227 0.00070549] | [0.00031736 0.00025894 0.00022157] | [0.00609448 0.0100101  0.0126942 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.583615243434906 BPR_loss 0.5211502313613892 reg_loss 0.062465038150548935
epoch: 3 s: 256000 batch_loss 0.5798800587654114 BPR_loss 0.5136129856109619 reg_loss 0.06626708060503006
epoch: 3 s: 512000 batch_loss 0.5759398937225342 BPR_loss 0.509579062461853 reg_loss 0.06636084616184235
epoch: 3 s: 768000 batch_loss 0.5696163773536682 BPR_loss 0.4992191791534424 reg_loss 0.07039719820022583
epoch: 3 s: 1024000 batch_loss 0.5721125602722168 BPR_loss 0.5012089014053345 reg_loss 0.07090366631746292
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 196.89833617210388 | 37.142894983291626 | 347.0186767578125 | [0.00058959 0.00101448 0.0011971 ] | [0.0004911  0.00064522 0.00070173] | [0.0003142  0.00027709 0.00021789] | [0.00615764 0.01064166 0.01250474] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.5649397969245911 BPR_loss 0.49057427048683167 reg_loss 0.07436553388834
epoch: 4 s: 256000 batch_loss 0.5583544969558716 BPR_loss 0.48177385330200195 reg_loss 0.07658064365386963
epoch: 4 s: 512000 batch_loss 0.5634790062904358 BPR_loss 0.48847806453704834 reg_loss 0.07500091940164566
epoch: 4 s: 768000 batch_loss 0.5524845719337463 BPR_loss 0.4731673300266266 reg_loss 0.07931726425886154
epoch: 4 s: 1024000 batch_loss 0.5584994554519653 BPR_loss 0.47733074426651 reg_loss 0.08116870373487473
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 197.65863060951233 | 37.54371452331543 | 336.70916748046875 | [0.00063422 0.00099834 0.00114152] | [0.00052036 0.00063892 0.00068288] | [0.00033788 0.00026683 0.00020473] | [0.00666288 0.01035746 0.01181003] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.5514791011810303 BPR_loss 0.4703969657421112 reg_loss 0.08108212053775787
epoch: 5 s: 256000 batch_loss 0.5450737476348877 BPR_loss 0.45931297540664673 reg_loss 0.08576080203056335
epoch: 5 s: 512000 batch_loss 0.5439879298210144 BPR_loss 0.4582931399345398 reg_loss 0.08569476753473282
epoch: 5 s: 768000 batch_loss 0.5416977405548096 BPR_loss 0.4553540349006653 reg_loss 0.0863436907529831
epoch: 5 s: 1024000 batch_loss 0.5427824854850769 BPR_loss 0.45398855209350586 reg_loss 0.08879394829273224
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 198.01024413108826 | 35.64105200767517 | 328.5511779785156 | [0.00045592 0.00090035 0.00111474] | [0.00041358 0.00057239 0.00063917] | [0.00024473 0.00024394 0.00019631] | [0.0047998  0.00947329 0.01133636] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.5391748547554016 BPR_loss 0.44976940751075745 reg_loss 0.08940546214580536
epoch: 6 s: 256000 batch_loss 0.5367839336395264 BPR_loss 0.44706666469573975 reg_loss 0.08971727639436722
epoch: 6 s: 512000 batch_loss 0.5345140099525452 BPR_loss 0.4409879446029663 reg_loss 0.09352605789899826
epoch: 6 s: 768000 batch_loss 0.528950572013855 BPR_loss 0.4356582462787628 reg_loss 0.09329234063625336
epoch: 6 s: 1024000 batch_loss 0.5307105779647827 BPR_loss 0.4367256164550781 reg_loss 0.09398497641086578
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 196.14541172981262 | 35.58305764198303 | 321.7859802246094 | [0.0003115  0.0006491  0.00082012] | [0.00032383 0.00044817 0.00050012] | [0.00016578 0.00018157 0.00014841] | [0.00331565 0.0071997  0.008747  ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.5276415348052979 BPR_loss 0.43191736936569214 reg_loss 0.09572415798902512
epoch: 7 s: 256000 batch_loss 0.5198720097541809 BPR_loss 0.42185676097869873 reg_loss 0.09801526367664337
epoch: 7 s: 512000 batch_loss 0.5181610584259033 BPR_loss 0.419189989566803 reg_loss 0.09897105395793915
epoch: 7 s: 768000 batch_loss 0.5230520963668823 BPR_loss 0.425870418548584 reg_loss 0.09718167781829834
epoch: 7 s: 1024000 batch_loss 0.5231951475143433 BPR_loss 0.4258359670639038 reg_loss 0.09735917299985886
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 196.79427886009216 | 35.824629068374634 | 316.1770935058594 | [0.00028332 0.00052303 0.00067644] | [0.00030173 0.0003828  0.00043003] | [0.00015789 0.0001492  0.00012631] | [0.00315776 0.00593659 0.00745232] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.5213760137557983 BPR_loss 0.4213491380214691 reg_loss 0.10002684593200684
epoch: 8 s: 256000 batch_loss 0.5152827501296997 BPR_loss 0.41457241773605347 reg_loss 0.10071030259132385
epoch: 8 s: 512000 batch_loss 0.5133417248725891 BPR_loss 0.40999674797058105 reg_loss 0.10334498435258865
epoch: 8 s: 768000 batch_loss 0.507956326007843 BPR_loss 0.4056944251060486 reg_loss 0.10226191580295563
epoch: 8 s: 1024000 batch_loss 0.5121753811836243 BPR_loss 0.4088430404663086 reg_loss 0.10333234816789627
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 196.97732591629028 | 38.2100944519043 | 311.3753356933594 | [0.00024894 0.00042319 0.00055189] | [0.0002765  0.00033657 0.00037199] | [0.00013894 0.00012789 0.00010263] | [0.00277883 0.005084   0.00609448] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.5092371702194214 BPR_loss 0.4037412405014038 reg_loss 0.10549592971801758
epoch: 9 s: 256000 batch_loss 0.5134087800979614 BPR_loss 0.4089505076408386 reg_loss 0.10445830225944519
epoch: 9 s: 512000 batch_loss 0.5065091252326965 BPR_loss 0.4020545780658722 reg_loss 0.10445452481508255
epoch: 9 s: 768000 batch_loss 0.5111764073371887 BPR_loss 0.40389418601989746 reg_loss 0.10728222131729126
epoch: 9 s: 1024000 batch_loss 0.5023502111434937 BPR_loss 0.3959069848060608 reg_loss 0.10644324123859406
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |                   precision                    |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
|   9   | 196.4706244468689 | 37.36700177192688 | 307.2904968261719 | [0.00020869 0.00035149 0.00048362] | [0.0002375  0.00028291 0.00032282] | [1.16837186e-04 1.05785020e-04 9.21013852e-05] | [0.00233674 0.00419982 0.00546293] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.5049508213996887 BPR_loss 0.39733606576919556 reg_loss 0.10761474072933197
epoch: 10 s: 256000 batch_loss 0.508101224899292 BPR_loss 0.40035444498062134 reg_loss 0.10774680972099304
epoch: 10 s: 512000 batch_loss 0.5072859525680542 BPR_loss 0.3993351459503174 reg_loss 0.10795082896947861
epoch: 10 s: 768000 batch_loss 0.5071706175804138 BPR_loss 0.3987712860107422 reg_loss 0.10839931666851044
epoch: 10 s: 1024000 batch_loss 0.5015273690223694 BPR_loss 0.39423805475234985 reg_loss 0.10728932172060013
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |                   precision                    |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
|   10  | 198.1962013244629 | 35.92883491516113 | 303.51422119140625 | [0.00011189 0.00030018 0.00043484] | [0.00017124 0.00023686 0.00028055] | [7.26285209e-05 8.92067702e-05 8.31543935e-05] | [0.00145257 0.00353669 0.00492611] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.49908018112182617 BPR_loss 0.38758453726768494 reg_loss 0.11149565875530243
epoch: 11 s: 256000 batch_loss 0.5027418732643127 BPR_loss 0.3930067718029022 reg_loss 0.10973508656024933
epoch: 11 s: 512000 batch_loss 0.4981308579444885 BPR_loss 0.38707733154296875 reg_loss 0.11105352640151978
epoch: 11 s: 768000 batch_loss 0.49486595392227173 BPR_loss 0.38357555866241455 reg_loss 0.11129038780927658
epoch: 11 s: 1024000 batch_loss 0.4957070052623749 BPR_loss 0.3851796090602875 reg_loss 0.1105273962020874
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |                   precision                    |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
|   11  | 197.06491136550903 | 35.09413003921509 | 300.1960144042969 | [0.00010232 0.00021393 0.00038464] | [0.00016441 0.00019873 0.0002558 ] | [6.15763547e-05 6.55235569e-05 7.15759336e-05] | [0.00123153 0.00262094 0.0042314 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.4939393401145935 BPR_loss 0.38164687156677246 reg_loss 0.11229247599840164
epoch: 12 s: 256000 batch_loss 0.49560096859931946 BPR_loss 0.382667601108551 reg_loss 0.11293336004018784
epoch: 12 s: 512000 batch_loss 0.49317511916160583 BPR_loss 0.37865564227104187 reg_loss 0.11451947689056396
epoch: 12 s: 768000 batch_loss 0.4948647618293762 BPR_loss 0.38319534063339233 reg_loss 0.11166942119598389
epoch: 12 s: 1024000 batch_loss 0.48603829741477966 BPR_loss 0.37108904123306274 reg_loss 0.11494926363229752
+-------+--------------------+-------------------+-------------------+------------------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |                     recall                     |                ndcg                |                   precision                    |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
|   12  | 195.68393540382385 | 37.91162085533142 | 297.1866455078125 | [8.80056548e-05 1.82399762e-04 3.37425197e-04] | [0.00014927 0.00017276 0.00022335] | [6.31552356e-05 5.68397120e-05 6.21026483e-05] | [0.00123153 0.00224201 0.00369458] |
+-------+--------------------+-------------------+-------------------+------------------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
epoch: 13 s: 0 batch_loss 0.48666197061538696 BPR_loss 0.36999326944351196 reg_loss 0.1166686862707138
epoch: 13 s: 256000 batch_loss 0.49020323157310486 BPR_loss 0.3742868900299072 reg_loss 0.11591634899377823
epoch: 13 s: 512000 batch_loss 0.48937517404556274 BPR_loss 0.372274249792099 reg_loss 0.11710093915462494
epoch: 13 s: 768000 batch_loss 0.4860636591911316 BPR_loss 0.3696381449699402 reg_loss 0.11642549932003021
epoch: 13 s: 1024000 batch_loss 0.48844626545906067 BPR_loss 0.3718319535255432 reg_loss 0.11661431938409805
+-------+--------------------+-------------------+------------------+------------------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |                     recall                     |                ndcg                |                   precision                    |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
|   13  | 198.22751879692078 | 36.80255150794983 | 294.490478515625 | [8.13904819e-05 2.00963198e-04 3.14320532e-04] | [0.00013779 0.00017196 0.0002095 ] | [5.36819502e-05 5.52608311e-05 5.63134184e-05] | [0.00104206 0.00217886 0.00334723] |
+-------+--------------------+-------------------+------------------+------------------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
epoch: 14 s: 0 batch_loss 0.4855441153049469 BPR_loss 0.3688783049583435 reg_loss 0.1166658103466034
epoch: 14 s: 256000 batch_loss 0.48570042848587036 BPR_loss 0.3697825074195862 reg_loss 0.11591791361570358
epoch: 14 s: 512000 batch_loss 0.48603060841560364 BPR_loss 0.36816322803497314 reg_loss 0.1178673803806305
epoch: 14 s: 768000 batch_loss 0.48222148418426514 BPR_loss 0.36644306778907776 reg_loss 0.11577841639518738
epoch: 14 s: 1024000 batch_loss 0.48002511262893677 BPR_loss 0.3627282977104187 reg_loss 0.11729682236909866
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |                   precision                    |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
|   14  | 196.7354724407196 | 37.920743227005005 | 292.0444641113281 | [0.00010566 0.00020968 0.0003378 ] | [0.00015611 0.00018222 0.00022684] | [6.15763547e-05 5.28925098e-05 5.89448865e-05] | [0.00119995 0.00208412 0.00350512] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.00010566071506740325
early stopping at 14, recall@20:0.0006
