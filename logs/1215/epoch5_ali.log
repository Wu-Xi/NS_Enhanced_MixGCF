Namespace(K=1, Ks='[20, 40, 60]', batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='ali', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, eps=0.01, gnn='lightgcn', gpu_id=1, l2=0.0001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=32, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上自适应权重......
start training ...
epoch: 0 s: 0 batch_loss 0.6931495666503906 BPR_loss 0.6931495666503906 reg_loss 2.6514008766298502e-08
epoch: 0 s: 256000 batch_loss 0.6931414008140564 BPR_loss 0.6931412220001221 reg_loss 1.6718033180040948e-07
epoch: 0 s: 512000 batch_loss 0.6929386854171753 BPR_loss 0.692935585975647 reg_loss 3.11961093757418e-06
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 43.25102257728577 | 139.55761122703552 | 248.08351135253906 | [0.03423962 0.05360507 0.06885699] | [0.01510611 0.01930285 0.02213842] | [0.00213033 0.00169358 0.00144872] | [0.0410209  0.06411671 0.081573  ] |
|   0   | 43.25102257728577 | 153.94811487197876 | 248.08351135253906 | [0.00794545 0.01366793 0.01944456] | [0.00336035 0.00456528 0.00563202] | [0.00044035 0.00038974 0.00037755] | [0.00865929 0.01523503 0.02192898] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.691925048828125 BPR_loss 0.6919100880622864 reg_loss 1.4944380382075906e-05
epoch: 1 s: 256000 batch_loss 0.6899517774581909 BPR_loss 0.6899087429046631 reg_loss 4.3041967728640884e-05
epoch: 1 s: 512000 batch_loss 0.6867825388908386 BPR_loss 0.6866897344589233 reg_loss 9.28090448724106e-05
using time 45.5382s, training loss at epoch 1: 246.5645
epoch: 2 s: 0 batch_loss 0.683255136013031 BPR_loss 0.6831173896789551 reg_loss 0.00013775922707282007
epoch: 2 s: 256000 batch_loss 0.6805760860443115 BPR_loss 0.6803717613220215 reg_loss 0.0002043450513156131
epoch: 2 s: 512000 batch_loss 0.6750569343566895 BPR_loss 0.6747540235519409 reg_loss 0.0003029360086657107
using time 46.5849s, training loss at epoch 2: 242.4766
epoch: 3 s: 0 batch_loss 0.6722594499588013 BPR_loss 0.6718853116035461 reg_loss 0.00037416350096464157
epoch: 3 s: 256000 batch_loss 0.665059506893158 BPR_loss 0.6645877361297607 reg_loss 0.0004717705596704036
epoch: 3 s: 512000 batch_loss 0.6600909233093262 BPR_loss 0.6595311164855957 reg_loss 0.0005597806884907186
using time 44.2799s, training loss at epoch 3: 237.0181
epoch: 4 s: 0 batch_loss 0.6547279357910156 BPR_loss 0.6540478467941284 reg_loss 0.0006800942355766892
epoch: 4 s: 256000 batch_loss 0.6425710916519165 BPR_loss 0.6417887210845947 reg_loss 0.0007823651540093124
epoch: 4 s: 512000 batch_loss 0.6414898037910461 BPR_loss 0.6405770778656006 reg_loss 0.0009126966469921172
using time 43.4896s, training loss at epoch 4: 230.4092
epoch: 5 s: 0 batch_loss 0.6391271948814392 BPR_loss 0.6380934715270996 reg_loss 0.0010337384883314371
epoch: 5 s: 256000 batch_loss 0.6304798722267151 BPR_loss 0.6293841600418091 reg_loss 0.0010957227787002921
epoch: 5 s: 512000 batch_loss 0.6171362400054932 BPR_loss 0.6158530116081238 reg_loss 0.0012832345673814416
+-------+-------------------+--------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |      Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 44.50455141067505 | 135.29834604263306 | 223.0986328125 | [0.05999976 0.08715333 0.10627082] | [0.0272826  0.03311962 0.03669102] | [0.00357744 0.00264051 0.00216687] | [0.06937014 0.10087695 0.12313165] |
|   5   | 44.50455141067505 | 123.54270243644714 | 223.0986328125 | [0.01470232 0.02452872 0.03240597] | [0.0060102  0.00806788 0.00950862] | [0.00079204 0.00067568 0.00060413] | [0.01564878 0.02661327 0.03550899] |
+-------+-------------------+--------------------+----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.6124406456947327 BPR_loss 0.6110171675682068 reg_loss 0.0014234811533242464
epoch: 6 s: 256000 batch_loss 0.6091153621673584 BPR_loss 0.6076130867004395 reg_loss 0.0015022787265479565
epoch: 6 s: 512000 batch_loss 0.5993977785110474 BPR_loss 0.5977019667625427 reg_loss 0.0016958328196778893
using time 43.6457s, training loss at epoch 6: 214.9720
epoch: 7 s: 0 batch_loss 0.5796542167663574 BPR_loss 0.577768087387085 reg_loss 0.0018861552234739065
epoch: 7 s: 256000 batch_loss 0.5829753279685974 BPR_loss 0.580992579460144 reg_loss 0.0019827778451144695
epoch: 7 s: 512000 batch_loss 0.5682902932167053 BPR_loss 0.5660886168479919 reg_loss 0.0022016840521246195
using time 45.1979s, training loss at epoch 7: 206.5039
epoch: 8 s: 0 batch_loss 0.5632432699203491 BPR_loss 0.560961127281189 reg_loss 0.0022821566089987755
epoch: 8 s: 256000 batch_loss 0.5492984652519226 BPR_loss 0.5467265248298645 reg_loss 0.0025719371624290943
epoch: 8 s: 512000 batch_loss 0.5451639294624329 BPR_loss 0.5424193143844604 reg_loss 0.002744642086327076
using time 43.7947s, training loss at epoch 8: 197.8256
epoch: 9 s: 0 batch_loss 0.538342297077179 BPR_loss 0.5355451703071594 reg_loss 0.0027971272356808186
epoch: 9 s: 256000 batch_loss 0.5365104675292969 BPR_loss 0.5333907604217529 reg_loss 0.003119679866358638
epoch: 9 s: 512000 batch_loss 0.5244899392127991 BPR_loss 0.5212287902832031 reg_loss 0.003261128207668662
using time 42.7505s, training loss at epoch 9: 188.8450
epoch: 10 s: 0 batch_loss 0.5145841240882874 BPR_loss 0.511236310005188 reg_loss 0.003347839927300811
epoch: 10 s: 256000 batch_loss 0.5064039826393127 BPR_loss 0.502816915512085 reg_loss 0.00358703825622797
epoch: 10 s: 512000 batch_loss 0.4978248178958893 BPR_loss 0.4939672350883484 reg_loss 0.003857590025290847
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 46.34578561782837 | 151.64519476890564 | 179.96961975097656 | [0.06526894 0.09283051 0.11196237] | [0.03013107 0.03605461 0.03962558] | [0.003867   0.00279907 0.00227028] | [0.07516133 0.10742651 0.12929513] |
|   10  | 46.34578561782837 | 143.4357190132141  | 179.96961975097656 | [0.01605749 0.02614594 0.03449294] | [0.00665449 0.00875785 0.01028224] | [0.00086002 0.00071336 0.00063935] | [0.01702304 0.0281353  0.03756299] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.491769403219223 BPR_loss 0.48791491985321045 reg_loss 0.0038544905837625265
epoch: 11 s: 256000 batch_loss 0.4818408191204071 BPR_loss 0.47766435146331787 reg_loss 0.0041764783672988415
epoch: 11 s: 512000 batch_loss 0.4715527892112732 BPR_loss 0.46722888946533203 reg_loss 0.004323901142925024
using time 48.8438s, training loss at epoch 11: 171.2482
epoch: 12 s: 0 batch_loss 0.4671753942966461 BPR_loss 0.46248167753219604 reg_loss 0.004693704657256603
epoch: 12 s: 256000 batch_loss 0.4544109106063843 BPR_loss 0.4496424198150635 reg_loss 0.004768498241901398
epoch: 12 s: 512000 batch_loss 0.45218604803085327 BPR_loss 0.44724488258361816 reg_loss 0.0049411519430577755
using time 46.4443s, training loss at epoch 12: 162.5252
epoch: 13 s: 0 batch_loss 0.43986865878105164 BPR_loss 0.43461874127388 reg_loss 0.005249909125268459
epoch: 13 s: 256000 batch_loss 0.43755441904067993 BPR_loss 0.4321590065956116 reg_loss 0.005395407322794199
epoch: 13 s: 512000 batch_loss 0.42395442724227905 BPR_loss 0.41832613945007324 reg_loss 0.005628288257867098
using time 47.2131s, training loss at epoch 13: 154.1126
epoch: 14 s: 0 batch_loss 0.41392049193382263 BPR_loss 0.4081020653247833 reg_loss 0.005818431731313467
epoch: 14 s: 256000 batch_loss 0.40899714827537537 BPR_loss 0.4030032455921173 reg_loss 0.005993897095322609
epoch: 14 s: 512000 batch_loss 0.4082877039909363 BPR_loss 0.4020223915576935 reg_loss 0.006265315692871809
using time 44.9639s, training loss at epoch 14: 146.0361
epoch: 15 s: 0 batch_loss 0.3937023878097534 BPR_loss 0.38722729682922363 reg_loss 0.006475084461271763
epoch: 15 s: 256000 batch_loss 0.3873896598815918 BPR_loss 0.3808774948120117 reg_loss 0.006512160412967205
epoch: 15 s: 512000 batch_loss 0.3834320604801178 BPR_loss 0.3764497637748718 reg_loss 0.006982305087149143
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 44.70414996147156 | 134.23852443695068 | 138.06134033203125 | [0.06706417 0.09522204 0.11444794] | [0.03133672 0.03739784 0.04098808] | [0.00396765 0.00286043 0.00231579] | [0.07731234 0.10992223 0.13203905] |
|   15  | 44.70414996147156 | 120.72013473510742 | 138.06134033203125 | [0.01638688 0.0267029  0.03448673] | [0.00678816 0.00893879 0.01036623] | [0.00087479 0.00072739 0.00063886] | [0.01734813 0.02865249 0.03742999] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 16 s: 0 batch_loss 0.3749951124191284 BPR_loss 0.36785292625427246 reg_loss 0.00714217871427536
epoch: 16 s: 256000 batch_loss 0.3732937276363373 BPR_loss 0.36576056480407715 reg_loss 0.007533169351518154
epoch: 16 s: 512000 batch_loss 0.3585425019264221 BPR_loss 0.3510715961456299 reg_loss 0.007470907177776098
using time 44.2347s, training loss at epoch 16: 130.5287
epoch: 17 s: 0 batch_loss 0.3602440357208252 BPR_loss 0.3524390459060669 reg_loss 0.0078049818985164165
epoch: 17 s: 256000 batch_loss 0.35050463676452637 BPR_loss 0.34261518716812134 reg_loss 0.007889438420534134
epoch: 17 s: 512000 batch_loss 0.3380914330482483 BPR_loss 0.32979997992515564 reg_loss 0.0082914549857378
using time 43.4478s, training loss at epoch 17: 123.5089
epoch: 18 s: 0 batch_loss 0.33028528094291687 BPR_loss 0.3218764066696167 reg_loss 0.008408869616687298
epoch: 18 s: 256000 batch_loss 0.32854947447776794 BPR_loss 0.31970909237861633 reg_loss 0.008840395137667656
epoch: 18 s: 512000 batch_loss 0.3261377811431885 BPR_loss 0.31733936071395874 reg_loss 0.00879841111600399
using time 43.5035s, training loss at epoch 18: 116.6732
epoch: 19 s: 0 batch_loss 0.312457799911499 BPR_loss 0.3031623363494873 reg_loss 0.009295451454818249
epoch: 19 s: 256000 batch_loss 0.3107662498950958 BPR_loss 0.30126088857650757 reg_loss 0.009505356661975384
epoch: 19 s: 512000 batch_loss 0.3015543818473816 BPR_loss 0.29217809438705444 reg_loss 0.009376291185617447
using time 44.5942s, training loss at epoch 19: 110.2632
epoch: 20 s: 0 batch_loss 0.2965553104877472 BPR_loss 0.2868390381336212 reg_loss 0.0097162751480937
epoch: 20 s: 256000 batch_loss 0.2943529188632965 BPR_loss 0.2846143841743469 reg_loss 0.009738548658788204
epoch: 20 s: 512000 batch_loss 0.28400254249572754 BPR_loss 0.2736867368221283 reg_loss 0.010315807536244392
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 45.092042446136475 | 165.70003652572632 | 104.19477844238281 | [0.06894419 0.09655746 0.11591232] | [0.03222247 0.03816069 0.04176504] | [0.00407038 0.00289939 0.00233923] | [0.07935304 0.11141139 0.13363852] |
|   20  | 45.092042446136475 | 145.7613706588745  | 104.19477844238281 | [0.0162066  0.02661117 0.03442367] | [0.00673138 0.00890045 0.01033184] | [0.00086297 0.00072222 0.00063516] | [0.01712648 0.02850472 0.03726745] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 21 s: 0 batch_loss 0.2811494767665863 BPR_loss 0.2708461880683899 reg_loss 0.01030330266803503
epoch: 21 s: 256000 batch_loss 0.2860228419303894 BPR_loss 0.2751516103744507 reg_loss 0.010871241800487041
epoch: 21 s: 512000 batch_loss 0.2717856466770172 BPR_loss 0.2610028386116028 reg_loss 0.010782795026898384
using time 48.1596s, training loss at epoch 21: 98.5479
epoch: 22 s: 0 batch_loss 0.2654382288455963 BPR_loss 0.25437822937965393 reg_loss 0.011060011573135853
epoch: 22 s: 256000 batch_loss 0.25566238164901733 BPR_loss 0.24408137798309326 reg_loss 0.011581012047827244
epoch: 22 s: 512000 batch_loss 0.2506595551967621 BPR_loss 0.2389339804649353 reg_loss 0.01172557007521391
using time 43.5327s, training loss at epoch 22: 93.1957
epoch: 23 s: 0 batch_loss 0.2516365051269531 BPR_loss 0.2396179735660553 reg_loss 0.012018545530736446
epoch: 23 s: 256000 batch_loss 0.24692140519618988 BPR_loss 0.23480096459388733 reg_loss 0.012120445258915424
epoch: 23 s: 512000 batch_loss 0.23715655505657196 BPR_loss 0.22493329644203186 reg_loss 0.01222325675189495
using time 44.5348s, training loss at epoch 23: 88.3194
epoch: 24 s: 0 batch_loss 0.24460291862487793 BPR_loss 0.23210564255714417 reg_loss 0.012497269548475742
epoch: 24 s: 256000 batch_loss 0.2376713901758194 BPR_loss 0.22492477297782898 reg_loss 0.012746619991958141
epoch: 24 s: 512000 batch_loss 0.22842353582382202 BPR_loss 0.21550758183002472 reg_loss 0.012915960513055325
using time 45.1953s, training loss at epoch 24: 83.5630
epoch: 25 s: 0 batch_loss 0.21903978288173676 BPR_loss 0.20615547895431519 reg_loss 0.012884309515357018
epoch: 25 s: 256000 batch_loss 0.22398033738136292 BPR_loss 0.21010105311870575 reg_loss 0.013879281468689442
epoch: 25 s: 512000 batch_loss 0.22955907881259918 BPR_loss 0.21558597683906555 reg_loss 0.013973098248243332
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 43.93352484703064 | 130.7522189617157  | 79.27873229980469 | [0.06990963 0.09748391 0.1161488 ] | [0.03280491 0.0387214  0.04219583] | [0.00412346 0.00292145 0.002339  ] | [0.08038718 0.11229386 0.13367989] |
|   25  | 43.93352484703064 | 117.64176177978516 | 79.27873229980469 | [0.01611905 0.02595819 0.03403587] | [0.0066498  0.00869671 0.01018167] | [0.00085706 0.00070338 0.0006295 ] | [0.01702304 0.02778065 0.03692758] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 26 s: 0 batch_loss 0.2107599675655365 BPR_loss 0.19706323742866516 reg_loss 0.013696728274226189
epoch: 26 s: 256000 batch_loss 0.21064896881580353 BPR_loss 0.19631357491016388 reg_loss 0.0143353920429945
epoch: 26 s: 512000 batch_loss 0.2098834067583084 BPR_loss 0.1954822987318039 reg_loss 0.014401101507246494
using time 42.4690s, training loss at epoch 26: 75.2920
epoch: 27 s: 0 batch_loss 0.19753338396549225 BPR_loss 0.18281450867652893 reg_loss 0.014718880876898766
epoch: 27 s: 256000 batch_loss 0.2003178894519806 BPR_loss 0.18528543412685394 reg_loss 0.015032458119094372
epoch: 27 s: 512000 batch_loss 0.19957312941551208 BPR_loss 0.18405885994434357 reg_loss 0.015514272265136242
using time 43.2596s, training loss at epoch 27: 71.5483
epoch: 28 s: 0 batch_loss 0.19778023660182953 BPR_loss 0.18232116103172302 reg_loss 0.015459070913493633
epoch: 28 s: 256000 batch_loss 0.19033709168434143 BPR_loss 0.17498654127120972 reg_loss 0.015350555069744587
epoch: 28 s: 512000 batch_loss 0.19227635860443115 BPR_loss 0.17680881917476654 reg_loss 0.015467544086277485
using time 44.3576s, training loss at epoch 28: 67.9946
epoch: 29 s: 0 batch_loss 0.19034869968891144 BPR_loss 0.17410185933113098 reg_loss 0.016246842220425606
epoch: 29 s: 256000 batch_loss 0.17997926473617554 BPR_loss 0.1635293960571289 reg_loss 0.016449863091111183
epoch: 29 s: 512000 batch_loss 0.17904438078403473 BPR_loss 0.16259276866912842 reg_loss 0.016451610252261162
using time 46.1868s, training loss at epoch 29: 64.8831
epoch: 30 s: 0 batch_loss 0.16982398927211761 BPR_loss 0.15374569594860077 reg_loss 0.016078297048807144
epoch: 30 s: 256000 batch_loss 0.1776277869939804 BPR_loss 0.16134321689605713 reg_loss 0.01628457009792328
epoch: 30 s: 512000 batch_loss 0.17025059461593628 BPR_loss 0.152725487947464 reg_loss 0.017525099217891693
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 48.10657596588135 | 153.7682991027832  | 61.81135940551758 | [0.06963757 0.09688689 0.11636092] | [0.03295624 0.03880681 0.0424288 ] | [0.0041083  0.00290042 0.00233946] | [0.08004247 0.11153549 0.13381777] |
|   30  | 48.10657596588135 | 149.08748936653137 | 61.81135940551758 | [0.01570529 0.02565169 0.03376509] | [0.00647563 0.00854583 0.01003511] | [0.00083342 0.00069452 0.00062383] | [0.01655018 0.02749989 0.03661726] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 31 s: 0 batch_loss 0.1708168089389801 BPR_loss 0.15319259464740753 reg_loss 0.01762421429157257
epoch: 31 s: 256000 batch_loss 0.17068734765052795 BPR_loss 0.1534622311592102 reg_loss 0.017225109040737152
epoch: 31 s: 512000 batch_loss 0.16651633381843567 BPR_loss 0.14902490377426147 reg_loss 0.017491424456238747
using time 47.2295s, training loss at epoch 31: 59.0134
epoch: 32 s: 0 batch_loss 0.1568882018327713 BPR_loss 0.13884615898132324 reg_loss 0.018042046576738358
epoch: 32 s: 256000 batch_loss 0.15660293400287628 BPR_loss 0.13825231790542603 reg_loss 0.01835061050951481
epoch: 32 s: 512000 batch_loss 0.16070063412189484 BPR_loss 0.14219507575035095 reg_loss 0.018505554646253586
using time 44.7525s, training loss at epoch 32: 56.4109
epoch: 33 s: 0 batch_loss 0.15581390261650085 BPR_loss 0.13710758090019226 reg_loss 0.018706323578953743
epoch: 33 s: 256000 batch_loss 0.15873485803604126 BPR_loss 0.14017996191978455 reg_loss 0.01855490356683731
epoch: 33 s: 512000 batch_loss 0.14317378401756287 BPR_loss 0.12446919828653336 reg_loss 0.01870458573102951
using time 44.1515s, training loss at epoch 33: 54.0546
epoch: 34 s: 0 batch_loss 0.15082435309886932 BPR_loss 0.13160130381584167 reg_loss 0.019223053008317947
epoch: 34 s: 256000 batch_loss 0.14201943576335907 BPR_loss 0.12226362526416779 reg_loss 0.019755816087126732
epoch: 34 s: 512000 batch_loss 0.14534127712249756 BPR_loss 0.12588560581207275 reg_loss 0.019455669447779655
using time 42.1083s, training loss at epoch 34: 51.8244
epoch: 35 s: 0 batch_loss 0.14290156960487366 BPR_loss 0.12332787364721298 reg_loss 0.019573699682950974
epoch: 35 s: 256000 batch_loss 0.14690695703029633 BPR_loss 0.12708768248558044 reg_loss 0.019819268956780434
epoch: 35 s: 512000 batch_loss 0.1428024023771286 BPR_loss 0.12233196943998337 reg_loss 0.020470429211854935
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 44.00121879577637 | 129.66874742507935 | 49.81232833862305 | [0.0693793  0.09671746 0.11547518] | [0.03281294 0.03867716 0.04216033] | [0.00408761 0.00289318 0.00231923] | [0.07971154 0.1111632  0.13271469] |
|   35  | 44.00121879577637 | 118.8603081703186  | 49.81232833862305 | [0.01552809 0.02498919 0.03295028] | [0.00634298 0.00831511 0.00977174] | [0.00082234 0.00067826 0.00060782] | [0.0163433  0.02680537 0.03565676] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 36 s: 0 batch_loss 0.13739360868930817 BPR_loss 0.11703607439994812 reg_loss 0.020357539877295494
epoch: 36 s: 256000 batch_loss 0.12802614271640778 BPR_loss 0.107549287378788 reg_loss 0.02047685906291008
epoch: 36 s: 512000 batch_loss 0.13523109257221222 BPR_loss 0.11441376805305481 reg_loss 0.02081732638180256
using time 43.6389s, training loss at epoch 36: 47.7498
epoch: 37 s: 0 batch_loss 0.12804706394672394 BPR_loss 0.10682797431945801 reg_loss 0.021219095215201378
epoch: 37 s: 256000 batch_loss 0.12817148864269257 BPR_loss 0.1071683019399643 reg_loss 0.021003182977437973
epoch: 37 s: 512000 batch_loss 0.12627875804901123 BPR_loss 0.10498671233654022 reg_loss 0.02129204012453556
using time 45.0366s, training loss at epoch 37: 46.0082
epoch: 38 s: 0 batch_loss 0.12540873885154724 BPR_loss 0.10373955219984055 reg_loss 0.0216691792011261
epoch: 38 s: 256000 batch_loss 0.1216142550110817 BPR_loss 0.09960982203483582 reg_loss 0.02200443111360073
epoch: 38 s: 512000 batch_loss 0.11955956369638443 BPR_loss 0.09793036431074142 reg_loss 0.021629201248288155
using time 46.3946s, training loss at epoch 38: 44.3106
epoch: 39 s: 0 batch_loss 0.11781895905733109 BPR_loss 0.09572616219520569 reg_loss 0.022092796862125397
epoch: 39 s: 256000 batch_loss 0.12446382641792297 BPR_loss 0.10209394246339798 reg_loss 0.022369887679815292
epoch: 39 s: 512000 batch_loss 0.11892452836036682 BPR_loss 0.09687577933073044 reg_loss 0.022048745304346085
using time 49.0233s, training loss at epoch 39: 42.7581
epoch: 40 s: 0 batch_loss 0.12234817445278168 BPR_loss 0.10028813779354095 reg_loss 0.022060032933950424
epoch: 40 s: 256000 batch_loss 0.11900246888399124 BPR_loss 0.09625567495822906 reg_loss 0.022746795788407326
epoch: 40 s: 512000 batch_loss 0.11800970882177353 BPR_loss 0.09523159265518188 reg_loss 0.022778116166591644
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 49.49118232727051 | 155.6799716949463  | 41.41875076293945 | [0.06892491 0.09579845 0.11411627] | [0.03253632 0.03829865 0.04170094] | [0.00406417 0.00286422 0.00229005] | [0.07920137 0.11011527 0.13106006] |
|   40  | 49.49118232727051 | 152.60787153244019 | 41.41875076293945 | [0.01530398 0.02470558 0.03233642] | [0.00618338 0.00813892 0.00953125] | [0.00081125 0.00067198 0.000596  ] | [0.0161512  0.02653939 0.0349918 ] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 41 s: 0 batch_loss 0.11093875765800476 BPR_loss 0.08818040788173676 reg_loss 0.022758346050977707
epoch: 41 s: 256000 batch_loss 0.11097218096256256 BPR_loss 0.08804493397474289 reg_loss 0.02292724885046482
epoch: 41 s: 512000 batch_loss 0.1089201420545578 BPR_loss 0.08560404181480408 reg_loss 0.02331610396504402
using time 47.4127s, training loss at epoch 41: 40.0743
epoch: 42 s: 0 batch_loss 0.10943251848220825 BPR_loss 0.08571524918079376 reg_loss 0.02371726930141449
epoch: 42 s: 256000 batch_loss 0.11168407648801804 BPR_loss 0.08821273595094681 reg_loss 0.023471340537071228
epoch: 42 s: 512000 batch_loss 0.10923181474208832 BPR_loss 0.08530060946941376 reg_loss 0.02393120713531971
using time 44.6556s, training loss at epoch 42: 38.7485
epoch: 43 s: 0 batch_loss 0.111642986536026 BPR_loss 0.08736354112625122 reg_loss 0.02427944727241993
epoch: 43 s: 256000 batch_loss 0.11091677099466324 BPR_loss 0.087058886885643 reg_loss 0.023857882246375084
epoch: 43 s: 512000 batch_loss 0.10593988001346588 BPR_loss 0.0814729556441307 reg_loss 0.024466928094625473
using time 43.0549s, training loss at epoch 43: 37.6750
epoch: 44 s: 0 batch_loss 0.10090910643339157 BPR_loss 0.07657851278781891 reg_loss 0.024330593645572662
epoch: 44 s: 256000 batch_loss 0.10471440851688385 BPR_loss 0.07955624163150787 reg_loss 0.025158168748021126
epoch: 44 s: 512000 batch_loss 0.09965510666370392 BPR_loss 0.0748751163482666 reg_loss 0.02477998659014702
using time 42.7571s, training loss at epoch 44: 36.6864
epoch: 45 s: 0 batch_loss 0.09606804698705673 BPR_loss 0.07100339978933334 reg_loss 0.02506464719772339
epoch: 45 s: 256000 batch_loss 0.09998975694179535 BPR_loss 0.07524703443050385 reg_loss 0.024742726236581802
epoch: 45 s: 512000 batch_loss 0.10390234738588333 BPR_loss 0.07863499224185944 reg_loss 0.025267355144023895
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 42.27402710914612 | 128.5649175643921  | 35.658287048339844 | [0.06874303 0.09498322 0.11281306] | [0.03248018 0.03811128 0.0414287 ] | [0.00404556 0.00284044 0.00226592] | [0.07891181 0.10924659 0.12968121] |
|   45  | 42.27402710914612 | 112.67761635780334 | 35.658287048339844 | [0.01514061 0.02419085 0.03181006] | [0.00611045 0.00799644 0.00939035] | [0.00080387 0.00065905 0.00058911] | [0.01600343 0.02605175 0.03448938] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 46 s: 0 batch_loss 0.09955297410488129 BPR_loss 0.07465119659900665 reg_loss 0.024901773780584335
epoch: 46 s: 256000 batch_loss 0.09731369465589523 BPR_loss 0.07226288318634033 reg_loss 0.0250508114695549
epoch: 46 s: 512000 batch_loss 0.09184937924146652 BPR_loss 0.06655070185661316 reg_loss 0.025298677384853363
using time 49.1983s, training loss at epoch 46: 34.6884
epoch: 47 s: 0 batch_loss 0.09569324553012848 BPR_loss 0.07005979120731354 reg_loss 0.025633452460169792
epoch: 47 s: 256000 batch_loss 0.09170830994844437 BPR_loss 0.06583254039287567 reg_loss 0.025875767692923546
epoch: 47 s: 512000 batch_loss 0.10040606558322906 BPR_loss 0.07429085671901703 reg_loss 0.026115207001566887
using time 48.4152s, training loss at epoch 47: 33.8156
epoch: 48 s: 0 batch_loss 0.09301365911960602 BPR_loss 0.06688708066940308 reg_loss 0.02612658031284809
epoch: 48 s: 256000 batch_loss 0.08944953233003616 BPR_loss 0.06335680186748505 reg_loss 0.026092732325196266
epoch: 48 s: 512000 batch_loss 0.09288646280765533 BPR_loss 0.066127248108387 reg_loss 0.02675921656191349
using time 48.7736s, training loss at epoch 48: 32.9984
epoch: 49 s: 0 batch_loss 0.08972933888435364 BPR_loss 0.06334947049617767 reg_loss 0.026379864662885666
epoch: 49 s: 256000 batch_loss 0.09259942173957825 BPR_loss 0.06548132002353668 reg_loss 0.027118105441331863
epoch: 49 s: 512000 batch_loss 0.09004710614681244 BPR_loss 0.0637957826256752 reg_loss 0.026251323521137238
using time 49.6444s, training loss at epoch 49: 32.2076
epoch: 50 s: 0 batch_loss 0.09007143974304199 BPR_loss 0.06294572353363037 reg_loss 0.02712571993470192
epoch: 50 s: 256000 batch_loss 0.08651573210954666 BPR_loss 0.05903308093547821 reg_loss 0.0274826530367136
epoch: 50 s: 512000 batch_loss 0.08716881275177002 BPR_loss 0.05987575650215149 reg_loss 0.02729305438697338
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 49.337061166763306 | 158.34189987182617 | 31.513917922973633 | [0.06797421 0.09383194 0.11141329] | [0.03215305 0.03770154 0.04097918] | [0.0039973  0.00280424 0.00223857] | [0.07797419 0.10778501 0.12798522] |
|   50  | 49.337061166763306 | 147.7621808052063  | 31.513917922973633 | [0.01490171 0.0238905  0.03092297] | [0.00604878 0.00792229 0.00921446] | [0.00079131 0.00065092 0.00057384] | [0.01575222 0.02572666 0.03355844] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 51 s: 0 batch_loss 0.08493982255458832 BPR_loss 0.056951507925987244 reg_loss 0.027988310903310776
epoch: 51 s: 256000 batch_loss 0.08480168879032135 BPR_loss 0.05725782737135887 reg_loss 0.027543865144252777
epoch: 51 s: 512000 batch_loss 0.08638806641101837 BPR_loss 0.058437786996364594 reg_loss 0.02795027755200863
using time 49.2475s, training loss at epoch 51: 30.8717
epoch: 52 s: 0 batch_loss 0.08256536722183228 BPR_loss 0.05464643985033035 reg_loss 0.027918925508856773
epoch: 52 s: 256000 batch_loss 0.08552423864603043 BPR_loss 0.05711503326892853 reg_loss 0.02840920351445675
epoch: 52 s: 512000 batch_loss 0.08412154018878937 BPR_loss 0.05619616061449051 reg_loss 0.02792537771165371
using time 42.3102s, training loss at epoch 52: 30.2951
epoch: 53 s: 0 batch_loss 0.08455735445022583 BPR_loss 0.05657735466957092 reg_loss 0.027979997918009758
epoch: 53 s: 256000 batch_loss 0.08476251363754272 BPR_loss 0.05635886266827583 reg_loss 0.02840365469455719
epoch: 53 s: 512000 batch_loss 0.08128160238265991 BPR_loss 0.05336235836148262 reg_loss 0.02791924588382244
using time 42.3088s, training loss at epoch 53: 29.7253
epoch: 54 s: 0 batch_loss 0.0816938579082489 BPR_loss 0.052524134516716 reg_loss 0.0291697196662426
epoch: 54 s: 256000 batch_loss 0.08074863255023956 BPR_loss 0.05219613015651703 reg_loss 0.028552502393722534
epoch: 54 s: 512000 batch_loss 0.08306732028722763 BPR_loss 0.054418183863162994 reg_loss 0.028649138286709785
using time 42.7361s, training loss at epoch 54: 29.1474
epoch: 55 s: 0 batch_loss 0.07805582880973816 BPR_loss 0.04933999478816986 reg_loss 0.02871583215892315
epoch: 55 s: 256000 batch_loss 0.07795260846614838 BPR_loss 0.049483396112918854 reg_loss 0.02846921607851982
epoch: 55 s: 512000 batch_loss 0.07894733548164368 BPR_loss 0.049833692610263824 reg_loss 0.02911364659667015
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   55  | 42.35705304145813 | 129.4554088115692  | 28.570314407348633 | [0.06708658 0.09281344 0.10988311] | [0.03156264 0.03707923 0.04026278] | [0.00394283 0.00277184 0.00220663] | [0.07694005 0.10666814 0.12624786] |
|   55  | 42.35705304145813 | 116.04516673088074 | 28.570314407348633 | [0.01471023 0.02359769 0.03073911] | [0.0060051  0.0078586  0.00917152] | [0.00078022 0.00064206 0.00057064] | [0.01554534 0.02538679 0.03339589] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 56 s: 0 batch_loss 0.08011876046657562 BPR_loss 0.050142839550971985 reg_loss 0.029975920915603638
epoch: 56 s: 256000 batch_loss 0.08013760298490524 BPR_loss 0.050638824701309204 reg_loss 0.02949877642095089
epoch: 56 s: 512000 batch_loss 0.07935687899589539 BPR_loss 0.05006270110607147 reg_loss 0.029294176027178764
using time 48.6030s, training loss at epoch 56: 28.1193
epoch: 57 s: 0 batch_loss 0.08093274384737015 BPR_loss 0.05075446143746376 reg_loss 0.030178282409906387
epoch: 57 s: 256000 batch_loss 0.0755763053894043 BPR_loss 0.04604011029005051 reg_loss 0.02953619323670864
epoch: 57 s: 512000 batch_loss 0.08075273036956787 BPR_loss 0.05069465935230255 reg_loss 0.03005806729197502
using time 49.5473s, training loss at epoch 57: 27.7195
epoch: 58 s: 0 batch_loss 0.07451038807630539 BPR_loss 0.04482368379831314 reg_loss 0.029686706140637398
epoch: 58 s: 256000 batch_loss 0.07607568800449371 BPR_loss 0.045865900814533234 reg_loss 0.03020978346467018
epoch: 58 s: 512000 batch_loss 0.07447703182697296 BPR_loss 0.04462110996246338 reg_loss 0.029855920001864433
using time 53.0022s, training loss at epoch 58: 27.2555
epoch: 59 s: 0 batch_loss 0.07818683236837387 BPR_loss 0.048289138823747635 reg_loss 0.029897691681981087
epoch: 59 s: 256000 batch_loss 0.07429586350917816 BPR_loss 0.04372325539588928 reg_loss 0.03057260625064373
epoch: 59 s: 512000 batch_loss 0.08053965866565704 BPR_loss 0.049648672342300415 reg_loss 0.03089098446071148
using time 52.5999s, training loss at epoch 59: 26.8818
epoch: 60 s: 0 batch_loss 0.07672621309757233 BPR_loss 0.04705062136054039 reg_loss 0.029675593599677086
epoch: 60 s: 256000 batch_loss 0.07101938873529434 BPR_loss 0.04133190959692001 reg_loss 0.02968747727572918
epoch: 60 s: 512000 batch_loss 0.07401145994663239 BPR_loss 0.042917992919683456 reg_loss 0.031093468889594078
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   60  | 44.5144362449646 | 166.50051999092102 | 26.46868133544922 | [0.06627627 0.09142528 0.1088051 ] | [0.03136544 0.03675169 0.03999329] | [0.00389526 0.00272668 0.00218227] | [0.07593348 0.10498594 0.12482764] |
|   60  | 44.5144362449646 | 149.60372352600098 | 26.46868133544922 | [0.01470418 0.02358844 0.03048787] | [0.00601921 0.00786892 0.00913734] | [0.00078022 0.00064169 0.0005662 ] | [0.01553057 0.02537201 0.03315946] |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 61 s: 0 batch_loss 0.07418344169855118 BPR_loss 0.04353194311261177 reg_loss 0.030651496723294258
epoch: 61 s: 256000 batch_loss 0.07224060595035553 BPR_loss 0.04204428941011429 reg_loss 0.030196312814950943
epoch: 61 s: 512000 batch_loss 0.07748421281576157 BPR_loss 0.04695946350693703 reg_loss 0.03052474930882454
using time 43.8005s, training loss at epoch 61: 26.1437
epoch: 62 s: 0 batch_loss 0.07396704703569412 BPR_loss 0.04321417212486267 reg_loss 0.030752873048186302
epoch: 62 s: 256000 batch_loss 0.0703016147017479 BPR_loss 0.03944651782512665 reg_loss 0.030855095013976097
epoch: 62 s: 512000 batch_loss 0.07551560550928116 BPR_loss 0.04470876604318619 reg_loss 0.03080684132874012
using time 41.7237s, training loss at epoch 62: 25.7080
epoch: 63 s: 0 batch_loss 0.0688321590423584 BPR_loss 0.037975214421749115 reg_loss 0.030856944620609283
epoch: 63 s: 256000 batch_loss 0.0747346580028534 BPR_loss 0.04370667785406113 reg_loss 0.031027983874082565
epoch: 63 s: 512000 batch_loss 0.06843659281730652 BPR_loss 0.037804510444402695 reg_loss 0.030632086098194122
using time 42.2901s, training loss at epoch 63: 25.3648
epoch: 64 s: 0 batch_loss 0.07146317511796951 BPR_loss 0.039950646460056305 reg_loss 0.03151252865791321
epoch: 64 s: 256000 batch_loss 0.07013368606567383 BPR_loss 0.03890982270240784 reg_loss 0.03122386336326599
epoch: 64 s: 512000 batch_loss 0.06709381937980652 BPR_loss 0.03609463572502136 reg_loss 0.030999181792140007
using time 42.7974s, training loss at epoch 64: 25.1231
epoch: 65 s: 0 batch_loss 0.06959115713834763 BPR_loss 0.039223186671733856 reg_loss 0.03036797046661377
epoch: 65 s: 256000 batch_loss 0.06938308477401733 BPR_loss 0.03812382370233536 reg_loss 0.03125925734639168
epoch: 65 s: 512000 batch_loss 0.06887808442115784 BPR_loss 0.03729342669248581 reg_loss 0.03158465400338173
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   65  | 42.38135480880737 | 121.01026940345764 | 24.79403305053711 | [0.06538184 0.09065613 0.10802664] | [0.03100223 0.03641749 0.03964653] | [0.00384424 0.00270669 0.00216641] | [0.07494071 0.10407589 0.12394518] |
|   65  | 42.38135480880737 | 122.16238236427307 | 24.79403305053711 | [0.01441062 0.02340483 0.03037855] | [0.00592284 0.00779654 0.00907449] | [0.00076545 0.00063873 0.00056374] | [0.01523503 0.02525379 0.03304124] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.01441061569547082
early stopping at 65, recall@20:0.0164
