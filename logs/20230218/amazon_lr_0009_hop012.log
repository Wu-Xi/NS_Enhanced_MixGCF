Namespace(K=1, Ks='[20, 40, 60]', batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='amazon', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, eps=0.01, gnn='lightgcn', gpu_id=3, l2=0.001, lr=0.009, mess_dropout=False, mess_dropout_rate=0.1, n_negs=16, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重......
start training ...
epoch: 0 s: 0 batch_loss 0.693147599697113 BPR_loss 0.6931474208831787 reg_loss 1.6988676065921027e-07
epoch: 0 s: 256000 batch_loss 0.6639620661735535 BPR_loss 0.6490541696548462 reg_loss 0.014907908625900745
epoch: 0 s: 512000 batch_loss 0.6548986434936523 BPR_loss 0.6352887153625488 reg_loss 0.01960994116961956
epoch: 0 s: 768000 batch_loss 0.6366370320320129 BPR_loss 0.6125841736793518 reg_loss 0.02405283786356449
epoch: 0 s: 1024000 batch_loss 0.6300949454307556 BPR_loss 0.6041463613510132 reg_loss 0.025948572903871536
epoch: 0 s: 1280000 batch_loss 0.6185861229896545 BPR_loss 0.5891100764274597 reg_loss 0.02947603538632393
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 90.22875165939331 | 1142.5737981796265 | 431.9616394042969 | [0.04481151 0.0667102  0.08263668] | [0.02092872 0.0255495  0.02845888] | [0.00253898 0.00190807 0.00158275] | [0.05003469 0.07472343 0.09265764] |
|   0   | 90.22875165939331 | 1207.2660875320435 | 431.9616394042969 | [0.05663982 0.08222199 0.10173167] | [0.02511752 0.03049689 0.03406742] | [0.00324278 0.00236748 0.00196122] | [0.06376056 0.09246975 0.11438768] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.587855875492096 BPR_loss 0.5569318532943726 reg_loss 0.03092399798333645
epoch: 1 s: 256000 batch_loss 0.5866279602050781 BPR_loss 0.55329430103302 reg_loss 0.033333636820316315
epoch: 1 s: 512000 batch_loss 0.5817036628723145 BPR_loss 0.5450796484947205 reg_loss 0.0366239957511425
epoch: 1 s: 768000 batch_loss 0.5744258761405945 BPR_loss 0.5366464853286743 reg_loss 0.03777939826250076
epoch: 1 s: 1024000 batch_loss 0.561297595500946 BPR_loss 0.5208024978637695 reg_loss 0.04049510881304741
epoch: 1 s: 1280000 batch_loss 0.5591894388198853 BPR_loss 0.5169715881347656 reg_loss 0.042217858135700226
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 116.98501563072205 | 1292.169596195221  | 384.0893859863281 | [0.04754501 0.06869139 0.08461998] | [0.02207027 0.02651753 0.02942698] | [0.00267845 0.0019537  0.00161245] | [0.05292636 0.07668772 0.09455621] |
|   1   | 116.98501563072205 | 1194.4302299022675 | 384.0893859863281 | [0.06035524 0.08799558 0.10818246] | [0.02734399 0.03315333 0.03684322] | [0.00344368 0.00252761 0.00207939] | [0.06763677 0.09877253 0.12139953] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.5339285135269165 BPR_loss 0.4911623001098633 reg_loss 0.04276623949408531
epoch: 2 s: 256000 batch_loss 0.532754123210907 BPR_loss 0.48822006583213806 reg_loss 0.04453406110405922
epoch: 2 s: 512000 batch_loss 0.5353243350982666 BPR_loss 0.4887654781341553 reg_loss 0.04655883088707924
epoch: 2 s: 768000 batch_loss 0.5239685773849487 BPR_loss 0.47716864943504333 reg_loss 0.046799905598163605
epoch: 2 s: 1024000 batch_loss 0.5268019437789917 BPR_loss 0.4786183536052704 reg_loss 0.048183560371398926
epoch: 2 s: 1280000 batch_loss 0.5268718600273132 BPR_loss 0.47685712575912476 reg_loss 0.050014711916446686
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 133.88940811157227 | 1252.816376209259  | 352.996337890625 | [0.0471399  0.06775999 0.08364427] | [0.02220709 0.02655399 0.02945487] | [0.00264851 0.0019245  0.00159005] | [0.05237139 0.075607   0.09335135] |
|   2   | 133.88940811157227 | 1148.0600047111511 | 352.996337890625 | [0.06138502 0.08890723 0.10897805] | [0.02759972 0.03339963 0.03706979] | [0.00349923 0.00255578 0.00209765] | [0.06882642 0.10002521 0.12260494] |
+-------+--------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.5049831867218018 BPR_loss 0.45351701974868774 reg_loss 0.051466189324855804
epoch: 3 s: 256000 batch_loss 0.49450454115867615 BPR_loss 0.4424249231815338 reg_loss 0.052079614251852036
epoch: 3 s: 512000 batch_loss 0.5028010010719299 BPR_loss 0.4496068060398102 reg_loss 0.05319419875741005
epoch: 3 s: 768000 batch_loss 0.5076447129249573 BPR_loss 0.4548530578613281 reg_loss 0.05279165133833885
epoch: 3 s: 1024000 batch_loss 0.5037106275558472 BPR_loss 0.4502667188644409 reg_loss 0.053443893790245056
epoch: 3 s: 1280000 batch_loss 0.5067260265350342 BPR_loss 0.4539736807346344 reg_loss 0.05275234207510948
+-------+-------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |      Loss     |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 150.4666850566864 | 1253.6848986148834 | 337.111328125 | [0.04653735 0.06722348 0.08224418] | [0.02193804 0.02629615 0.02903499] | [0.00261784 0.0019119  0.00156437] | [0.05180912 0.07503012 0.09181058] |
|   3   | 150.4666850566864 | 1142.4613065719604 | 337.111328125 | [0.06080125 0.08746141 0.1070502 ] | [0.0273738  0.03298881 0.03657729] | [0.00346653 0.00251008 0.00206127] | [0.06823554 0.09818952 0.12051714] |
+-------+-------------------+--------------------+---------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.48708534240722656 BPR_loss 0.43286558985710144 reg_loss 0.05421975255012512
epoch: 4 s: 256000 batch_loss 0.48648011684417725 BPR_loss 0.4291341006755829 reg_loss 0.057346001267433167
epoch: 4 s: 512000 batch_loss 0.48748043179512024 BPR_loss 0.4319992661476135 reg_loss 0.05548117309808731
epoch: 4 s: 768000 batch_loss 0.49706441164016724 BPR_loss 0.44064685702323914 reg_loss 0.056417547166347504
epoch: 4 s: 1024000 batch_loss 0.4919326901435852 BPR_loss 0.4348319172859192 reg_loss 0.05710076540708542
epoch: 4 s: 1280000 batch_loss 0.5034785866737366 BPR_loss 0.4476472735404968 reg_loss 0.05583130568265915
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 147.683531999588 | 1262.644903421402  | 328.8157958984375 | [0.04508129 0.06564039 0.08084061] | [0.02114449 0.02547271 0.02824304] | [0.00252948 0.00186407 0.00153577] | [0.05004199 0.0733068  0.09028442] |
|   4   | 147.683531999588 | 1122.1385173797607 | 328.8157958984375 | [0.0596115  0.08659333 0.1062792 ] | [0.02655078 0.03225113 0.0358575 ] | [0.00339563 0.00249275 0.00205011] | [0.06679377 0.0976144  0.11982384] |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.47210368514060974 BPR_loss 0.41558095812797546 reg_loss 0.05652273818850517
epoch: 5 s: 256000 batch_loss 0.4803634285926819 BPR_loss 0.42100077867507935 reg_loss 0.059362638741731644
epoch: 5 s: 512000 batch_loss 0.4837837219238281 BPR_loss 0.42427173256874084 reg_loss 0.059512004256248474
epoch: 5 s: 768000 batch_loss 0.4896223545074463 BPR_loss 0.43129992485046387 reg_loss 0.05832241475582123
epoch: 5 s: 1024000 batch_loss 0.4810449182987213 BPR_loss 0.42290931940078735 reg_loss 0.05813559144735336
epoch: 5 s: 1280000 batch_loss 0.48395219445228577 BPR_loss 0.4263508915901184 reg_loss 0.057601314038038254
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 112.62386703491211 | 942.4675669670105 | 323.7196350097656 | [0.04468349 0.06553505 0.08061043] | [0.02074901 0.02513745 0.02788586] | [0.00250685 0.00185476 0.00152884] | [0.04962576 0.0729563  0.08990471] |
|   5   | 112.62386703491211 | 887.9735853672028 | 323.7196350097656 | [0.05956442 0.0862043  0.10559606] | [0.02680545 0.03241902 0.03596921] | [0.00340075 0.00248133 0.00203711] | [0.06688831 0.09721259 0.11905962] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.46461430191993713 BPR_loss 0.4050644040107727 reg_loss 0.05954988673329353
epoch: 6 s: 256000 batch_loss 0.4703594446182251 BPR_loss 0.41113191843032837 reg_loss 0.05922752246260643
epoch: 6 s: 512000 batch_loss 0.4778014123439789 BPR_loss 0.4170377254486084 reg_loss 0.06076369062066078
epoch: 6 s: 768000 batch_loss 0.4807920455932617 BPR_loss 0.4225136935710907 reg_loss 0.05827833712100983
epoch: 6 s: 1024000 batch_loss 0.48298850655555725 BPR_loss 0.42489394545555115 reg_loss 0.058094561100006104
epoch: 6 s: 1280000 batch_loss 0.4900190234184265 BPR_loss 0.43044841289520264 reg_loss 0.05957059934735298
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 99.27300643920898 | 921.1514391899109 | 320.62060546875 | [0.04429934 0.06477476 0.07959409] | [0.02031053 0.02461875 0.0273278 ] | [0.00248603 0.00183468 0.00151253] | [0.04918033 0.07216766 0.0888824 ] |
|   6   | 99.27300643920898 | 846.7555875778198 | 320.62060546875 | [0.05945608 0.08502062 0.10415135] | [0.02652243 0.03191129 0.03541372] | [0.00339917 0.00245001 0.00200954] | [0.06689619 0.09599143 0.11757847] |
+-------+-------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.46115022897720337 BPR_loss 0.4010520577430725 reg_loss 0.060098156332969666
epoch: 7 s: 256000 batch_loss 0.47044724225997925 BPR_loss 0.40970492362976074 reg_loss 0.0607423298060894
epoch: 7 s: 512000 batch_loss 0.47662174701690674 BPR_loss 0.4180314540863037 reg_loss 0.058590278029441833
epoch: 7 s: 768000 batch_loss 0.46846145391464233 BPR_loss 0.4090196490287781 reg_loss 0.05944179743528366
epoch: 7 s: 1024000 batch_loss 0.4800989329814911 BPR_loss 0.42030757665634155 reg_loss 0.059791356325149536
epoch: 7 s: 1280000 batch_loss 0.49511513113975525 BPR_loss 0.4365893006324768 reg_loss 0.05852581933140755
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 107.99988913536072 | 874.2137525081635 | 318.3393249511719 | [0.04409405 0.06428754 0.07978057] | [0.02042605 0.02466843 0.02749699] | [0.00247727 0.00182172 0.00151533] | [0.04901968 0.0716419  0.08908686] |
|   7   | 107.99988913536072 | 810.2478430271149 | 318.3393249511719 | [0.05856548 0.084333   0.1038788 ] | [0.02621372 0.0316587  0.03523708] | [0.00334166 0.0024315  0.00200796] | [0.06574593 0.09516419 0.11739726] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.46463388204574585 BPR_loss 0.4041232466697693 reg_loss 0.06051063910126686
epoch: 8 s: 256000 batch_loss 0.47237783670425415 BPR_loss 0.4117606580257416 reg_loss 0.06061718240380287
epoch: 8 s: 512000 batch_loss 0.4724133312702179 BPR_loss 0.41323989629745483 reg_loss 0.05917343124747276
epoch: 8 s: 768000 batch_loss 0.47452133893966675 BPR_loss 0.4140579104423523 reg_loss 0.06046343594789505
epoch: 8 s: 1024000 batch_loss 0.4950680732727051 BPR_loss 0.4351332485675812 reg_loss 0.0599348247051239
epoch: 8 s: 1280000 batch_loss 0.48554831743240356 BPR_loss 0.4243306815624237 reg_loss 0.061217643320560455
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 106.9262011051178 | 851.4662556648254 | 316.4773254394531 | [0.04284164 0.06374492 0.07857093] | [0.01982829 0.02422933 0.02694073] | [0.00240242 0.0018093  0.00149561] | [0.04754463 0.07125488 0.08800613] |
|   8   | 106.9262011051178 | 815.6432800292969 | 316.4773254394531 | [0.05771374 0.08344899 0.10181172] | [0.02562311 0.03105826 0.0344251 ] | [0.00329557 0.0024051  0.00196752] | [0.06482415 0.09411635 0.11508887] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.46767458319664 BPR_loss 0.407753586769104 reg_loss 0.059920988976955414
epoch: 9 s: 256000 batch_loss 0.4633818566799164 BPR_loss 0.40173614025115967 reg_loss 0.06164572387933731
epoch: 9 s: 512000 batch_loss 0.46769896149635315 BPR_loss 0.40733712911605835 reg_loss 0.0603618361055851
epoch: 9 s: 768000 batch_loss 0.47030770778656006 BPR_loss 0.40936750173568726 reg_loss 0.0609402097761631
epoch: 9 s: 1024000 batch_loss 0.4741531014442444 BPR_loss 0.4136773347854614 reg_loss 0.06047576293349266
epoch: 9 s: 1280000 batch_loss 0.4787978529930115 BPR_loss 0.418366402387619 reg_loss 0.06043146178126335
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 112.5344979763031 | 842.6210017204285 | 315.2185363769531 | [0.04403294 0.06425258 0.07891843] | [0.02029643 0.02455844 0.02723793] | [0.00247289 0.00182756 0.00150304] | [0.04893936 0.07193399 0.08829822] |
|   9   | 112.5344979763031 | 810.9197854995728 | 315.2185363769531 | [0.0573592  0.08325252 0.10219539] | [0.02577858 0.03124797 0.03472022] | [0.00327272 0.00240136 0.0019754 ] | [0.06439871 0.09395878 0.1155537 ] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.4587777853012085 BPR_loss 0.398734450340271 reg_loss 0.0600433275103569
epoch: 10 s: 256000 batch_loss 0.4576486349105835 BPR_loss 0.39700767397880554 reg_loss 0.06064097210764885
epoch: 10 s: 512000 batch_loss 0.4660011827945709 BPR_loss 0.40420764684677124 reg_loss 0.061793532222509384
epoch: 10 s: 768000 batch_loss 0.47439971566200256 BPR_loss 0.41299349069595337 reg_loss 0.06140622869133949
epoch: 10 s: 1024000 batch_loss 0.47962629795074463 BPR_loss 0.4191104471683502 reg_loss 0.060515858232975006
epoch: 10 s: 1280000 batch_loss 0.47757816314697266 BPR_loss 0.4167584180831909 reg_loss 0.060819756239652634
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 117.35548377037048 | 826.6085851192474 | 314.0628356933594 | [0.04393608 0.06413507 0.0787344 ] | [0.02023606 0.02448107 0.02714621] | [0.00246997 0.00181734 0.00149573] | [0.04888094 0.07153237 0.08801344] |
|   10  | 117.35548377037048 | 778.6084790229797 | 314.0628356933594 | [0.0575529  0.08320114 0.10148259] | [0.02556875 0.03099214 0.03434571] | [0.00329202 0.00240688 0.00196765] | [0.06483203 0.09417938 0.11492342] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.45240938663482666 BPR_loss 0.39032915234565735 reg_loss 0.06208024173974991
epoch: 11 s: 256000 batch_loss 0.4607532024383545 BPR_loss 0.3991052806377411 reg_loss 0.061647929251194
epoch: 11 s: 512000 batch_loss 0.4535050690174103 BPR_loss 0.3911678194999695 reg_loss 0.06233726069331169
epoch: 11 s: 768000 batch_loss 0.4709619879722595 BPR_loss 0.40918827056884766 reg_loss 0.061773717403411865
epoch: 11 s: 1024000 batch_loss 0.4753570258617401 BPR_loss 0.4128352701663971 reg_loss 0.06252175569534302
epoch: 11 s: 1280000 batch_loss 0.4683709442615509 BPR_loss 0.40570008754730225 reg_loss 0.06267084926366806
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 120.03700947761536 |  814.793872833252 | 313.2886657714844 | [0.04385026 0.06406107 0.07903431] | [0.02024386 0.02450119 0.02723216] | [0.00246559 0.00182044 0.00150389] | [0.0487714  0.0716346  0.08840045] |
|   11  | 120.03700947761536 | 753.5260999202728 | 313.2886657714844 | [0.05602825 0.08208368 0.10046915] | [0.02484431 0.03034105 0.03371253] | [0.00320418 0.00236551 0.00194257] | [0.06307513 0.09261156 0.11360771] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.45689862966537476 BPR_loss 0.39541977643966675 reg_loss 0.06147885322570801
epoch: 12 s: 256000 batch_loss 0.4603557586669922 BPR_loss 0.39720654487609863 reg_loss 0.06314921379089355
epoch: 12 s: 512000 batch_loss 0.47088682651519775 BPR_loss 0.40783464908599854 reg_loss 0.06305216997861862
epoch: 12 s: 768000 batch_loss 0.4686571955680847 BPR_loss 0.4066809415817261 reg_loss 0.06197625771164894
epoch: 12 s: 1024000 batch_loss 0.4830840528011322 BPR_loss 0.42043012380599976 reg_loss 0.06265393644571304
epoch: 12 s: 1280000 batch_loss 0.4753958284854889 BPR_loss 0.41237491369247437 reg_loss 0.06302090734243393
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 137.18251276016235 | 836.0559198856354 | 312.589111328125 | [0.04290444 0.06345036 0.07836087] | [0.01971331 0.02405564 0.02678233] | [0.00240644 0.0018031  0.00149208] | [0.04766877 0.07102121 0.08775786] |
|   12  | 137.18251276016235 |  732.106116771698 | 312.589111328125 | [0.05667231 0.08233992 0.10081969] | [0.02547542 0.03089248 0.03428474] | [0.00324357 0.00237654 0.00195321] | [0.06376056 0.0931079  0.11412769] |
+-------+--------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.056672311823470364
early stopping at 12, recall@20:0.0614
