Namespace(K=1, Ks='[20, 40, 60]', batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='amazon', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, eps=0.01, gnn='lightgcn', gpu_id=3, l2=0.001, lr=0.009, mess_dropout=False, mess_dropout_rate=0.1, n_negs=16, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重......
start training ...
epoch: 0 s: 0 batch_loss 0.6931475400924683 BPR_loss 0.6931474208831787 reg_loss 1.1949748568440555e-07
epoch: 0 s: 256000 batch_loss 0.6586028933525085 BPR_loss 0.6477090120315552 reg_loss 0.010893910191953182
epoch: 0 s: 512000 batch_loss 0.6490767598152161 BPR_loss 0.6364309787750244 reg_loss 0.012645754031836987
epoch: 0 s: 768000 batch_loss 0.628903865814209 BPR_loss 0.6144893169403076 reg_loss 0.014414572156965733
epoch: 0 s: 1024000 batch_loss 0.6209802627563477 BPR_loss 0.6058416366577148 reg_loss 0.015138629823923111
epoch: 0 s: 1280000 batch_loss 0.6074541807174683 BPR_loss 0.5905158519744873 reg_loss 0.016938315704464912
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 131.43726682662964 | 1332.9371807575226 | 427.55792236328125 | [0.04387669 0.06569764 0.08185584] | [0.02037529 0.02497186 0.02792433] | [0.00249297 0.00188068 0.00156778] | [0.04913651 0.07367921 0.09182519] |
|   0   | 131.43726682662964 | 1166.3397302627563 | 427.55792236328125 | [0.05634198 0.08095944 0.10059185] | [0.02473128 0.02991772 0.03350971] | [0.00323136 0.0023338  0.00194205] | [0.06353208 0.09124858 0.11330045] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.5765368938446045 BPR_loss 0.5588905811309814 reg_loss 0.017646342515945435
epoch: 1 s: 256000 batch_loss 0.5754169225692749 BPR_loss 0.5561935305595398 reg_loss 0.019223369657993317
epoch: 1 s: 512000 batch_loss 0.570355236530304 BPR_loss 0.5497621297836304 reg_loss 0.02059309370815754
epoch: 1 s: 768000 batch_loss 0.5606098175048828 BPR_loss 0.5392633676528931 reg_loss 0.021346453577280045
epoch: 1 s: 1024000 batch_loss 0.5457487106323242 BPR_loss 0.5232876539230347 reg_loss 0.02246106043457985
epoch: 1 s: 1280000 batch_loss 0.5420507192611694 BPR_loss 0.518742561340332 reg_loss 0.02330818586051464
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 137.10098099708557 | 1326.2945351600647 | 375.0986633300781 | [0.04728958 0.06860557 0.08540476] | [0.02180117 0.02628067 0.0293442 ] | [0.00266968 0.00195261 0.00162669] | [0.05270729 0.07668042 0.09543978] |
|   1   | 137.10098099708557 | 1148.7243492603302 | 375.0986633300781 | [0.06106524 0.08863765 0.1084397 ] | [0.02742434 0.0332172  0.03683517] | [0.00349017 0.00254416 0.00208399] | [0.06856643 0.09952887 0.12174619] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.5156205296516418 BPR_loss 0.4919627606868744 reg_loss 0.023657778277993202
epoch: 2 s: 256000 batch_loss 0.5172380208969116 BPR_loss 0.49216508865356445 reg_loss 0.02507290244102478
epoch: 2 s: 512000 batch_loss 0.5150046944618225 BPR_loss 0.4887579083442688 reg_loss 0.026246797293424606
epoch: 2 s: 768000 batch_loss 0.5044996738433838 BPR_loss 0.4778534173965454 reg_loss 0.026646241545677185
epoch: 2 s: 1024000 batch_loss 0.5028541088104248 BPR_loss 0.4763582944869995 reg_loss 0.026495834812521935
epoch: 2 s: 1280000 batch_loss 0.5029572248458862 BPR_loss 0.4756578207015991 reg_loss 0.02729940600693226
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 113.63680815696716 | 1287.4217052459717 | 339.0281066894531 | [0.04743444 0.06855001 0.08449044] | [0.02221309 0.02665784 0.02956523] | [0.00266713 0.00194932 0.00160782] | [0.0527292  0.07651247 0.09435905] |
|   2   | 113.63680815696716 | 1161.1433243751526 | 339.0281066894531 | [0.0627559  0.09048562 0.11073733] | [0.02804485 0.03390019 0.03759892] | [0.00357604 0.00260069 0.00212877] | [0.07043363 0.10171908 0.12435396] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.47867870330810547 BPR_loss 0.4511340260505676 reg_loss 0.02754468098282814
epoch: 3 s: 256000 batch_loss 0.4666547179222107 BPR_loss 0.4378603994846344 reg_loss 0.028794316574931145
epoch: 3 s: 512000 batch_loss 0.47372254729270935 BPR_loss 0.44463005661964417 reg_loss 0.029092488810420036
epoch: 3 s: 768000 batch_loss 0.48158401250839233 BPR_loss 0.4523894190788269 reg_loss 0.029194585978984833
epoch: 3 s: 1024000 batch_loss 0.4776792526245117 BPR_loss 0.448604941368103 reg_loss 0.029074296355247498
epoch: 3 s: 1280000 batch_loss 0.47622665762901306 BPR_loss 0.44754451513290405 reg_loss 0.02868213877081871
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 110.75559854507446 | 1277.8870024681091 | 319.5420227050781 | [0.04691578 0.06841095 0.08389579] | [0.02203415 0.02654676 0.02936748] | [0.00264084 0.00194275 0.00159431] | [0.05225455 0.07631531 0.0935339 ] |
|   3   | 110.75559854507446 | 1161.5161526203156 | 319.5420227050781 | [0.0624723  0.09033081 0.11014976] | [0.02807666 0.03394428 0.03756776] | [0.00355477 0.00259143 0.00211708] | [0.06999244 0.10149849 0.12374732] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.4598087966442108 BPR_loss 0.4303422272205353 reg_loss 0.029466576874256134
epoch: 4 s: 256000 batch_loss 0.455527663230896 BPR_loss 0.4252999424934387 reg_loss 0.030227722600102425
epoch: 4 s: 512000 batch_loss 0.45853540301322937 BPR_loss 0.4283699691295624 reg_loss 0.03016544133424759
epoch: 4 s: 768000 batch_loss 0.4675338864326477 BPR_loss 0.4372742176055908 reg_loss 0.030259666964411736
epoch: 4 s: 1024000 batch_loss 0.4587361514568329 BPR_loss 0.4285425543785095 reg_loss 0.03019360639154911
epoch: 4 s: 1280000 batch_loss 0.47449570894241333 BPR_loss 0.44451504945755005 reg_loss 0.029980668798089027
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 117.0295341014862 | 1316.4661395549774 | 309.2510986328125 | [0.04592321 0.06658907 0.08217646] | [0.02142374 0.02577028 0.02861607] | [0.00257585 0.00188671 0.00156036] | [0.05095476 0.07419037 0.09170105] |
|   4   | 117.0295341014862 | 1020.1319155693054 | 309.2510986328125 | [0.06185718 0.09021884 0.10984471] | [0.02749393 0.0334747  0.03706765] | [0.00352365 0.00259301 0.00211393] | [0.06931489 0.10153    0.12357399] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.44381746649742126 BPR_loss 0.413536936044693 reg_loss 0.030280541628599167
epoch: 5 s: 256000 batch_loss 0.4474552869796753 BPR_loss 0.4163281321525574 reg_loss 0.031127141788601875
epoch: 5 s: 512000 batch_loss 0.44962066411972046 BPR_loss 0.4183705449104309 reg_loss 0.031250134110450745
epoch: 5 s: 768000 batch_loss 0.4567948579788208 BPR_loss 0.42580538988113403 reg_loss 0.030989475548267365
epoch: 5 s: 1024000 batch_loss 0.4457838833332062 BPR_loss 0.4151056706905365 reg_loss 0.03067820519208908
epoch: 5 s: 1280000 batch_loss 0.44900450110435486 BPR_loss 0.41825249791145325 reg_loss 0.03075200505554676
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 131.78676891326904 | 959.8870613574982 | 302.9529724121094 | [0.04593733 0.06695168 0.08238077] | [0.02123639 0.02565788 0.02847457] | [0.00257111 0.00189218 0.00156109] | [0.05087444 0.07446055 0.09184709] |
|   5   | 131.78676891326904 | 788.9224510192871 | 302.9529724121094 | [0.06182728 0.0889758  0.10872275] | [0.02776794 0.03348746 0.03710334] | [0.00352208 0.0025542  0.002092  ] | [0.06933852 0.10011975 0.12243161] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.43420445919036865 BPR_loss 0.40306544303894043 reg_loss 0.031139003112912178
epoch: 6 s: 256000 batch_loss 0.43858063220977783 BPR_loss 0.40730005502700806 reg_loss 0.03128057345747948
epoch: 6 s: 512000 batch_loss 0.4417386054992676 BPR_loss 0.41041940450668335 reg_loss 0.03131920099258423
epoch: 6 s: 768000 batch_loss 0.4517197012901306 BPR_loss 0.420938104391098 reg_loss 0.030781587585806847
epoch: 6 s: 1024000 batch_loss 0.45211532711982727 BPR_loss 0.4213027358055115 reg_loss 0.030812596902251244
epoch: 6 s: 1280000 batch_loss 0.45861366391181946 BPR_loss 0.4277012050151825 reg_loss 0.03091246820986271
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 109.28394293785095 | 908.3909244537354 | 299.0418701171875 | [0.04554024 0.06663281 0.08166049] | [0.02097743 0.02541585 0.02816149] | [0.00254956 0.00188543 0.00154977] | [0.05044361 0.07413195 0.09111687] |
|   6   | 109.28394293785095 | 736.9454634189606 | 299.0418701171875 | [0.06142076 0.08792837 0.10769376] | [0.02740765 0.03299232 0.03661187] | [0.00349962 0.00252564 0.0020723 ] | [0.06895248 0.09893798 0.12136014] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.4280964732170105 BPR_loss 0.3970862627029419 reg_loss 0.03101019561290741
epoch: 7 s: 256000 batch_loss 0.43560782074928284 BPR_loss 0.40401691198349 reg_loss 0.031590916216373444
epoch: 7 s: 512000 batch_loss 0.44716164469718933 BPR_loss 0.41591876745224 reg_loss 0.031242871657013893
epoch: 7 s: 768000 batch_loss 0.4364520311355591 BPR_loss 0.4051015377044678 reg_loss 0.03135049343109131
epoch: 7 s: 1024000 batch_loss 0.44728884100914 BPR_loss 0.41631656885147095 reg_loss 0.030972272157669067
epoch: 7 s: 1280000 batch_loss 0.46347901225090027 BPR_loss 0.43291163444519043 reg_loss 0.030567390844225883
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 108.14402318000793 | 877.4113857746124 | 296.1907043457031 | [0.04472723 0.06601489 0.08112691] | [0.02084851 0.02533171 0.02809596] | [0.0025094  0.00186827 0.00153979] | [0.04966227 0.07348205 0.09046698] |
|   7   | 108.14402318000793 | 735.6057507991791 | 296.1907043457031 | [0.06092523 0.08752465 0.10731683] | [0.02743173 0.03304663 0.03666843] | [0.00346811 0.00251718 0.00206692] | [0.06823554 0.09851254 0.12095046] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.4308513104915619 BPR_loss 0.3997815251350403 reg_loss 0.03106979839503765
epoch: 8 s: 256000 batch_loss 0.4400429427623749 BPR_loss 0.4085855185985565 reg_loss 0.031457431614398956
epoch: 8 s: 512000 batch_loss 0.44340914487838745 BPR_loss 0.4122667908668518 reg_loss 0.031142348423600197
epoch: 8 s: 768000 batch_loss 0.4413039982318878 BPR_loss 0.41005417704582214 reg_loss 0.031249815598130226
epoch: 8 s: 1024000 batch_loss 0.46464791893959045 BPR_loss 0.43368279933929443 reg_loss 0.03096511960029602
epoch: 8 s: 1280000 batch_loss 0.44804009795188904 BPR_loss 0.41686058044433594 reg_loss 0.031179506331682205
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 106.54538083076477 | 842.8603653907776 | 293.9393005371094 | [0.04426957 0.06526618 0.08035984] | [0.02044871 0.02487365 0.02763263] | [0.00248056 0.00185056 0.00152762] | [0.04915112 0.07289058 0.0898828 ] |
|   8   | 106.54538083076477 | 792.6846797466278 | 293.9393005371094 | [0.0604363  0.08646091 0.10589862] | [0.02697118 0.03245846 0.03601458] | [0.00343935 0.00248606 0.00204053] | [0.06768404 0.09730713 0.11935901] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.43450450897216797 BPR_loss 0.40344810485839844 reg_loss 0.03105640411376953
epoch: 9 s: 256000 batch_loss 0.42993152141571045 BPR_loss 0.3983243405818939 reg_loss 0.03160717710852623
epoch: 9 s: 512000 batch_loss 0.43229180574417114 BPR_loss 0.40094050765037537 reg_loss 0.03135131299495697
epoch: 9 s: 768000 batch_loss 0.43666139245033264 BPR_loss 0.4052814245223999 reg_loss 0.03137996420264244
epoch: 9 s: 1024000 batch_loss 0.44007283449172974 BPR_loss 0.4088549017906189 reg_loss 0.03121793083846569
epoch: 9 s: 1280000 batch_loss 0.44722047448158264 BPR_loss 0.41619810461997986 reg_loss 0.03102237544953823
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 112.72632050514221 | 835.4406962394714 | 292.3790283203125 | [0.04494242 0.06579926 0.08053761] | [0.02072889 0.02512718 0.02781779] | [0.00252035 0.00186462 0.00153018] | [0.04990325 0.0733068  0.08991201] |
|   9   | 112.72632050514221 | 805.3089184761047 | 292.3790283203125 | [0.05997917 0.08615612 0.10540548] | [0.02701522 0.03254653 0.03607288] | [0.00341532 0.00247759 0.00203199] | [0.06726648 0.09700775 0.11885478] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.4261595606803894 BPR_loss 0.3951623737812042 reg_loss 0.030997173860669136
epoch: 10 s: 256000 batch_loss 0.4209855794906616 BPR_loss 0.389474093914032 reg_loss 0.031511496752500534
epoch: 10 s: 512000 batch_loss 0.4315059781074524 BPR_loss 0.3999944031238556 reg_loss 0.0315115749835968
epoch: 10 s: 768000 batch_loss 0.4387255311012268 BPR_loss 0.40728580951690674 reg_loss 0.03143973648548126
epoch: 10 s: 1024000 batch_loss 0.4433726966381073 BPR_loss 0.41218167543411255 reg_loss 0.031191013753414154
epoch: 10 s: 1280000 batch_loss 0.44332218170166016 BPR_loss 0.4122157394886017 reg_loss 0.031106451526284218
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 115.80618667602539 | 833.4136316776276 | 290.8406066894531 | [0.04501466 0.06564366 0.08046207] | [0.0206251  0.02496684 0.02767545] | [0.00252474 0.0018575  0.00152811] | [0.04999087 0.07310234 0.08991201] |
|   10  | 115.80618667602539 | 760.8211686611176 | 290.8406066894531 | [0.05998248 0.08585489 0.10505853] | [0.02689964 0.03236742 0.03589229] | [0.00342281 0.00247365 0.00203212] | [0.06741617 0.09685018 0.11879176] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.41871050000190735 BPR_loss 0.38715705275535583 reg_loss 0.03155345469713211
epoch: 11 s: 256000 batch_loss 0.4261891543865204 BPR_loss 0.3946475088596344 reg_loss 0.031541645526885986
epoch: 11 s: 512000 batch_loss 0.4163901209831238 BPR_loss 0.3846015930175781 reg_loss 0.031788527965545654
epoch: 11 s: 768000 batch_loss 0.4360743761062622 BPR_loss 0.4044695198535919 reg_loss 0.031604867428541183
epoch: 11 s: 1024000 batch_loss 0.4359605312347412 BPR_loss 0.4044104814529419 reg_loss 0.03155006095767021
epoch: 11 s: 1280000 batch_loss 0.4312952756881714 BPR_loss 0.39965224266052246 reg_loss 0.03164302185177803
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 120.21262097358704 | 806.228542804718 | 289.9481506347656 | [0.0445368  0.06528824 0.0803273 ] | [0.02055603 0.02492747 0.02768147] | [0.00250173 0.0018491  0.00152762] | [0.04954544 0.07278104 0.08977327] |
|   11  | 120.21262097358704 | 762.437408208847 | 289.9481506347656 | [0.05925729 0.08459697 0.104017  ] | [0.02638633 0.03172098 0.03527684] | [0.00337554 0.00242933 0.00200324] | [0.06649439 0.0951957  0.11731848] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.4258400797843933 BPR_loss 0.3943173289299011 reg_loss 0.03152274712920189
epoch: 12 s: 256000 batch_loss 0.42628151178359985 BPR_loss 0.3942645192146301 reg_loss 0.03201697766780853
epoch: 12 s: 512000 batch_loss 0.4349592328071594 BPR_loss 0.40301287174224854 reg_loss 0.031946368515491486
epoch: 12 s: 768000 batch_loss 0.4323417544364929 BPR_loss 0.40078967809677124 reg_loss 0.031552061438560486
epoch: 12 s: 1024000 batch_loss 0.451663076877594 BPR_loss 0.42010560631752014 reg_loss 0.03155747056007385
epoch: 12 s: 1280000 batch_loss 0.44007325172424316 BPR_loss 0.4085237383842468 reg_loss 0.03154952451586723
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 137.24912118911743 | 826.7425174713135 | 289.0238342285156 | [0.04402961 0.06450716 0.07992412] | [0.02014358 0.02446494 0.02727971] | [0.00246668 0.00183139 0.00152007] | [0.04888824 0.07206543 0.08936434] |
|   12  | 137.24912118911743 | 730.4732301235199 | 289.0238342285156 | [0.05923199 0.08575458 0.10420286] | [0.02668986 0.0322887  0.03566427] | [0.00337554 0.00246892 0.00200954] | [0.06659681 0.09675564 0.1175312 ] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.05923199430992632
early stopping at 12, recall@20:0.0628
