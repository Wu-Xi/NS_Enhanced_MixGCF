Namespace(K=1, Ks='[20, 40, 60]', alpha=0.1, batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='amazon', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, gnn='lightgcn', gpu_id=2, l2=0.001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=16, neg_mix_num=1, ns='mixgcf', out_dir='./weights/yelp2018/', pool='mean', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
卷积器不需要第0层embedding
拿这个最难的neg_item去和pos_item在每一个维度上进行softmax自适应权重,引入alpha超参数来控制模型倾向,在权重分母上mixup多个negative items......
start training ...
epoch: 0 s: 0 batch_loss 0.6931477785110474 BPR_loss 0.693147599697113 reg_loss 2.0114826781991724e-07
epoch: 0 s: 256000 batch_loss 0.6897684931755066 BPR_loss 0.6887589693069458 reg_loss 0.0010095302714034915
epoch: 0 s: 512000 batch_loss 0.6794993877410889 BPR_loss 0.6746011972427368 reg_loss 0.0048981765285134315
epoch: 0 s: 768000 batch_loss 0.6711813807487488 BPR_loss 0.6631917357444763 reg_loss 0.007989630103111267
epoch: 0 s: 1024000 batch_loss 0.6679900288581848 BPR_loss 0.659191370010376 reg_loss 0.008798650465905666
epoch: 0 s: 1280000 batch_loss 0.6613924503326416 BPR_loss 0.651137113571167 reg_loss 0.010255314409732819
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 71.0618987083435 | 359.06724739074707 | 450.7286682128906 | [0.02906326 0.05157042 0.06556066] | [0.01315823 0.01789647 0.02046523] | [0.00165322 0.00148582 0.00126791] | [0.03274307 0.05862938 0.07465041] |
|   0   | 71.0618987083435 | 430.5860686302185  | 450.7286682128906 | [0.04282529 0.05964324 0.0744249 ] | [0.0175843  0.02112948 0.02383782] | [0.00249393 0.00174292 0.00145384] | [0.04919324 0.06812524 0.08493004] |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.6495238542556763 BPR_loss 0.6389834880828857 reg_loss 0.010540378279983997
epoch: 1 s: 256000 batch_loss 0.6575219631195068 BPR_loss 0.6467045545578003 reg_loss 0.010817415080964565
epoch: 1 s: 512000 batch_loss 0.6539844870567322 BPR_loss 0.6415398120880127 reg_loss 0.0124446926638484
epoch: 1 s: 768000 batch_loss 0.6510085463523865 BPR_loss 0.6381239295005798 reg_loss 0.01288461685180664
epoch: 1 s: 1024000 batch_loss 0.6444135904312134 BPR_loss 0.6310567855834961 reg_loss 0.013356788083910942
epoch: 1 s: 1280000 batch_loss 0.6434491276741028 BPR_loss 0.6290096044540405 reg_loss 0.01443952601402998
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 77.30861568450928 | 378.2318768501282 | 432.9485778808594 | [0.03542507 0.05600131 0.07010588] | [0.01677547 0.02111847 0.02369419] | [0.00202015 0.00161835 0.00135249] | [0.03999416 0.06370441 0.07948446] |
|   1   | 77.30861568450928 | 423.2925841808319 | 432.9485778808594 | [0.04593105 0.06612501 0.0826866 ] | [0.01956934 0.02382055 0.02685615] | [0.00264953 0.0019192  0.00160813] | [0.05221858 0.07517648 0.09402969] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6407500505447388 BPR_loss 0.6261941194534302 reg_loss 0.014555943198502064
epoch: 2 s: 256000 batch_loss 0.6389809846878052 BPR_loss 0.6240060925483704 reg_loss 0.014974875375628471
epoch: 2 s: 512000 batch_loss 0.6378557085990906 BPR_loss 0.622791051864624 reg_loss 0.015064682811498642
epoch: 2 s: 768000 batch_loss 0.6299722194671631 BPR_loss 0.6148796677589417 reg_loss 0.015092550776898861
epoch: 2 s: 1024000 batch_loss 0.627718985080719 BPR_loss 0.6110835075378418 reg_loss 0.01663549244403839
epoch: 2 s: 1280000 batch_loss 0.6222171783447266 BPR_loss 0.6047542095184326 reg_loss 0.01746295765042305
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 77.40122604370117 | 380.7564129829407  | 421.9479064941406 | [0.03817031 0.05875863 0.07292992] | [0.01812983 0.02247237 0.02505894] | [0.0021808  0.00169356 0.00140494] | [0.0431049  0.06651575 0.08243455] |
|   2   | 77.40122604370117 | 434.94453954696655 | 421.9479064941406 | [0.04884109 0.07148641 0.08837363] | [0.02128443 0.02606193 0.02916054] | [0.00280986 0.00206397 0.00171042] | [0.05533846 0.08089626 0.10011975] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.6186774969100952 BPR_loss 0.6000689268112183 reg_loss 0.01860859990119934
epoch: 3 s: 256000 batch_loss 0.6108986139297485 BPR_loss 0.5929409265518188 reg_loss 0.01795770227909088
epoch: 3 s: 512000 batch_loss 0.6170318722724915 BPR_loss 0.5980861186981201 reg_loss 0.018945740535855293
epoch: 3 s: 768000 batch_loss 0.619954526424408 BPR_loss 0.6018052101135254 reg_loss 0.01814933679997921
epoch: 3 s: 1024000 batch_loss 0.612084686756134 BPR_loss 0.5928551554679871 reg_loss 0.019229553639888763
epoch: 3 s: 1280000 batch_loss 0.6161368489265442 BPR_loss 0.5970081686973572 reg_loss 0.019128672778606415
+-------+-------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 80.42515683174133 | 388.87978887557983 | 411.67333984375 | [0.04051555 0.06076626 0.07607808] | [0.01933015 0.02360187 0.02639363] | [0.0023148  0.00174742 0.00146081] | [0.04563146 0.06843623 0.08567673] |
|   3   | 80.42515683174133 | 437.5616030693054  | 411.67333984375 | [0.05179027 0.07518521 0.0925993 ] | [0.02250824 0.02743443 0.03062089] | [0.00296152 0.00216717 0.00178802] | [0.05835592 0.08493004 0.10462624] |
+-------+-------------------+--------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.6119918823242188 BPR_loss 0.5920121669769287 reg_loss 0.01997970975935459
epoch: 4 s: 256000 batch_loss 0.5995899438858032 BPR_loss 0.5781131982803345 reg_loss 0.021476730704307556
epoch: 4 s: 512000 batch_loss 0.5977174639701843 BPR_loss 0.5773987174034119 reg_loss 0.02031872794032097
epoch: 4 s: 768000 batch_loss 0.6019206643104553 BPR_loss 0.580086886882782 reg_loss 0.021833768114447594
epoch: 4 s: 1024000 batch_loss 0.5896631479263306 BPR_loss 0.5677003860473633 reg_loss 0.021962737664580345
epoch: 4 s: 1280000 batch_loss 0.5998954176902771 BPR_loss 0.5778640508651733 reg_loss 0.02203134447336197
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 77.92472410202026 | 390.50246238708496 | 401.66326904296875 | [0.04225025 0.06288447 0.07882516] | [0.02011987 0.02445913 0.02736385] | [0.00240352 0.001802   0.00150766] | [0.0474205  0.07057578 0.08839315] |
|   4   | 77.92472410202026 | 431.38069915771484 | 401.66326904296875 | [0.05306832 0.07783147 0.09637075] | [0.02328566 0.02849798 0.03188372] | [0.00303519 0.00224202 0.0018563 ] | [0.05978192 0.08788447 0.10858912] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.592270016670227 BPR_loss 0.57001793384552 reg_loss 0.022252090275287628
epoch: 5 s: 256000 batch_loss 0.5859497785568237 BPR_loss 0.5617392659187317 reg_loss 0.0242104884237051
epoch: 5 s: 512000 batch_loss 0.5884496569633484 BPR_loss 0.5639427900314331 reg_loss 0.024506879970431328
epoch: 5 s: 768000 batch_loss 0.585300624370575 BPR_loss 0.5614218711853027 reg_loss 0.02387876994907856
epoch: 5 s: 1024000 batch_loss 0.577154815196991 BPR_loss 0.5530481338500977 reg_loss 0.024106672033667564
epoch: 5 s: 1280000 batch_loss 0.5740334391593933 BPR_loss 0.5502668619155884 reg_loss 0.023766571655869484
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 80.45173287391663 | 387.61918330192566 | 391.7826232910156 | [0.04360922 0.06488719 0.08072174] | [0.02045518 0.02492193 0.02781001] | [0.00247289 0.00185512 0.00154259] | [0.04881522 0.07275914 0.09041586] |
|   5   | 80.45173287391663 | 416.8469350337982  | 391.7826232910156 | [0.05461232 0.08009658 0.09945442] | [0.02407888 0.02944909 0.03298748] | [0.00311555 0.00230643 0.00191762] | [0.06131823 0.09030316 0.11204778] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.5679596066474915 BPR_loss 0.5422253608703613 reg_loss 0.02573425881564617
epoch: 6 s: 256000 batch_loss 0.5774024724960327 BPR_loss 0.5520663261413574 reg_loss 0.025336138904094696
epoch: 6 s: 512000 batch_loss 0.5646814107894897 BPR_loss 0.5379139184951782 reg_loss 0.026767510920763016
epoch: 6 s: 768000 batch_loss 0.5827735662460327 BPR_loss 0.5568851828575134 reg_loss 0.025888361036777496
epoch: 6 s: 1024000 batch_loss 0.5765312314033508 BPR_loss 0.5505279302597046 reg_loss 0.026003319770097733
epoch: 6 s: 1280000 batch_loss 0.5569744110107422 BPR_loss 0.5294873714447021 reg_loss 0.027487020939588547
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 81.96016597747803 | 391.29237699508667 | 382.33526611328125 | [0.04409595 0.0655208  0.08200381] | [0.0205381  0.0250499  0.02804786] | [0.00249735 0.00187046 0.00156304] | [0.04926065 0.07337252 0.09160612] |
|   6   | 81.96016597747803 | 416.06171011924744 | 382.33526611328125 |  [0.0558615 0.0816956 0.1012399]   | [0.02481814 0.03027388 0.03384538] | [0.00318251 0.00235429 0.00195189] | [0.06257091 0.09212309 0.113978  ] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.5523854494094849 BPR_loss 0.5247754454612732 reg_loss 0.027609987184405327
epoch: 7 s: 256000 batch_loss 0.5602338314056396 BPR_loss 0.5326457023620605 reg_loss 0.027588143944740295
epoch: 7 s: 512000 batch_loss 0.5713123679161072 BPR_loss 0.5445023775100708 reg_loss 0.026809992268681526
epoch: 7 s: 768000 batch_loss 0.5617444515228271 BPR_loss 0.5339527130126953 reg_loss 0.027791744098067284
epoch: 7 s: 1024000 batch_loss 0.5508630275726318 BPR_loss 0.522315263748169 reg_loss 0.028547754511237144
epoch: 7 s: 1280000 batch_loss 0.5613153576850891 BPR_loss 0.5329737663269043 reg_loss 0.02834157831966877
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 82.70762586593628 | 393.35883378982544 | 372.5600891113281 |  [0.0447865 0.0667057 0.0831118]   | [0.02083355 0.02543894 0.02842793] | [0.00253094 0.00189821 0.00158093] | [0.04996897 0.07450436 0.09279638] |
|   7   | 82.70762586593628 | 410.93791151046753 | 372.5600891113281 | [0.05750007 0.08333644 0.10331848] | [0.0255855  0.03103817 0.0346894 ] | [0.00327351 0.002399   0.00199024] | [0.06430417 0.09382485 0.11614459] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.5562584400177002 BPR_loss 0.5266008377075195 reg_loss 0.029657594859600067
epoch: 8 s: 256000 batch_loss 0.5532550811767578 BPR_loss 0.5233407020568848 reg_loss 0.029914403334259987
epoch: 8 s: 512000 batch_loss 0.5534250140190125 BPR_loss 0.524726152420044 reg_loss 0.0286988727748394
epoch: 8 s: 768000 batch_loss 0.5484195351600647 BPR_loss 0.5180140733718872 reg_loss 0.030405458062887192
epoch: 8 s: 1024000 batch_loss 0.5562430620193481 BPR_loss 0.5258288383483887 reg_loss 0.030414193868637085
epoch: 8 s: 1280000 batch_loss 0.531152069568634 BPR_loss 0.49957847595214844 reg_loss 0.031573567539453506
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 80.98574662208557 | 399.64157485961914 | 362.648681640625 | [0.0451453  0.06790026 0.08409124] | [0.02087995 0.02565979 0.02860783] | [0.00254409 0.00192906 0.00159711] | [0.05029026 0.07572383 0.09373106] |
|   8   | 80.98574662208557 | 414.1003725528717  | 362.648681640625 | [0.05808057 0.0845666  0.10452065] | [0.02572203 0.03130869 0.03495938] | [0.0033003  0.00242933 0.00201308] | [0.0648084  0.09496723 0.11753908] |
+-------+-------------------+--------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.5493724346160889 BPR_loss 0.5188004970550537 reg_loss 0.030571922659873962
epoch: 9 s: 256000 batch_loss 0.5366021394729614 BPR_loss 0.5040566325187683 reg_loss 0.03254548832774162
epoch: 9 s: 512000 batch_loss 0.5294652581214905 BPR_loss 0.49795669317245483 reg_loss 0.03150855004787445
epoch: 9 s: 768000 batch_loss 0.5249618291854858 BPR_loss 0.49274659156799316 reg_loss 0.032215263694524765
epoch: 9 s: 1024000 batch_loss 0.5189149975776672 BPR_loss 0.48644644021987915 reg_loss 0.03246857598423958
epoch: 9 s: 1280000 batch_loss 0.5327560901641846 BPR_loss 0.499497652053833 reg_loss 0.033258408308029175
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 80.39737915992737 |  406.733686208725 | 352.54876708984375 | [0.04556206 0.06832664 0.08441655] | [0.02110357 0.02588932 0.02882325] | [0.00256453 0.0019391  0.00160271] | [0.05070649 0.07608164 0.09405966] |
|   9   | 80.39737915992737 | 399.6103856563568 | 352.54876708984375 | [0.05902617 0.08595445 0.10585174] | [0.02630066 0.03197213 0.03561324] | [0.00335387 0.00246695 0.00203672] | [0.06584835 0.09644838 0.11891781] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.527292788028717 BPR_loss 0.49426525831222534 reg_loss 0.033027537167072296
epoch: 10 s: 256000 batch_loss 0.5122004151344299 BPR_loss 0.4789043962955475 reg_loss 0.033296000212430954
epoch: 10 s: 512000 batch_loss 0.5107437372207642 BPR_loss 0.47613954544067383 reg_loss 0.03460417315363884
epoch: 10 s: 768000 batch_loss 0.5047211647033691 BPR_loss 0.4701165556907654 reg_loss 0.03460457921028137
epoch: 10 s: 1024000 batch_loss 0.5196323990821838 BPR_loss 0.48532021045684814 reg_loss 0.034312210977077484
epoch: 10 s: 1280000 batch_loss 0.5092523694038391 BPR_loss 0.47428447008132935 reg_loss 0.034967873245477676
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 78.68444061279297 | 428.7792990207672 | 342.1177062988281 | [0.04614708 0.06830713 0.08495684] | [0.02125078 0.02591546 0.02895053] | [0.00259374 0.00193709 0.00161135] | [0.05131987 0.07603783 0.094527  ] |
|   10  | 78.68444061279297 | 398.4108421802521 | 342.1177062988281 | [0.05945615 0.08697511 0.10663319] | [0.02665677 0.0324468  0.0360464 ] | [0.00338144 0.00249295 0.00205024] | [0.06636046 0.09745683 0.1197293 ] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.500289797782898 BPR_loss 0.4639313817024231 reg_loss 0.03635839745402336
epoch: 11 s: 256000 batch_loss 0.4971875548362732 BPR_loss 0.4608098864555359 reg_loss 0.0363776795566082
epoch: 11 s: 512000 batch_loss 0.49152812361717224 BPR_loss 0.454885333776474 reg_loss 0.036642782390117645
epoch: 11 s: 768000 batch_loss 0.503920316696167 BPR_loss 0.46689438819885254 reg_loss 0.03702595457434654
epoch: 11 s: 1024000 batch_loss 0.4918578267097473 BPR_loss 0.4541858732700348 reg_loss 0.03767195716500282
epoch: 11 s: 1280000 batch_loss 0.47932106256484985 BPR_loss 0.4410371780395508 reg_loss 0.03828388452529907
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 76.79407906532288 | 421.74255323410034 | 331.7784118652344 | [0.04644304 0.0684489  0.08514859] | [0.02140058 0.02603483 0.02908267] | [0.00260543 0.00193837 0.00161403] | [0.05157545 0.07608164 0.09471686] |
|   11  | 76.79407906532288 | 405.6349890232086  | 331.7784118652344 | [0.06000798 0.08775222 0.10772182] | [0.02697942 0.03281933 0.03647319] | [0.00340784 0.0025158  0.0020706 ] | [0.06688831 0.09837073 0.12095046] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.4970954358577728 BPR_loss 0.4591168463230133 reg_loss 0.037978578358888626
epoch: 12 s: 256000 batch_loss 0.48224690556526184 BPR_loss 0.4431929886341095 reg_loss 0.03905390948057175
epoch: 12 s: 512000 batch_loss 0.4788365364074707 BPR_loss 0.4396706223487854 reg_loss 0.0391659140586853
epoch: 12 s: 768000 batch_loss 0.4803096055984497 BPR_loss 0.4416700005531311 reg_loss 0.03863959759473801
epoch: 12 s: 1024000 batch_loss 0.47800925374031067 BPR_loss 0.43808847665786743 reg_loss 0.03992077335715294
epoch: 12 s: 1280000 batch_loss 0.4657696485519409 BPR_loss 0.4256492853164673 reg_loss 0.040120359510183334
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 77.7752296924591 | 426.52613139152527 | 321.2101745605469 | [0.0465532  0.06838858 0.08546731] | [0.02133382 0.02593325 0.02904559] | [0.00260762 0.00193308 0.00161756] | [0.05166308 0.07586987 0.09495783] |
|   12  | 77.7752296924591 | 392.08958888053894 | 321.2101745605469 | [0.06052613 0.08820643 0.10885915] | [0.02729638 0.03312202 0.03689609] | [0.00343896 0.00252958 0.00209003] | [0.06750284 0.09892222 0.1221086 ] |
+-------+------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 13 s: 0 batch_loss 0.473229318857193 BPR_loss 0.43278181552886963 reg_loss 0.040447499603033066
epoch: 13 s: 256000 batch_loss 0.468059241771698 BPR_loss 0.4284932613372803 reg_loss 0.03956598788499832
epoch: 13 s: 512000 batch_loss 0.46545305848121643 BPR_loss 0.4258853495121002 reg_loss 0.039567720144987106
epoch: 13 s: 768000 batch_loss 0.46507424116134644 BPR_loss 0.4236295819282532 reg_loss 0.04144467040896416
epoch: 13 s: 1024000 batch_loss 0.46029752492904663 BPR_loss 0.41841089725494385 reg_loss 0.041886620223522186
epoch: 13 s: 1280000 batch_loss 0.46058833599090576 BPR_loss 0.41821181774139404 reg_loss 0.04237651079893112
+-------+-------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |       Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   13  | 79.46390986442566 | 426.2921278476715 | 310.362548828125 | [0.04670395 0.06886631 0.08532315] | [0.02149479 0.02615539 0.02915669] | [0.00261382 0.00194439 0.00161464] | [0.05175801 0.07632261 0.09476797] |
|   13  | 79.46390986442566 | 401.6440737247467 | 310.362548828125 | [0.06093332 0.08859574 0.1094225 ] | [0.02746024 0.03328199 0.03708256] | [0.00345747 0.0025412  0.00210014] | [0.06793615 0.0993319  0.1226916 ] |
+-------+-------------------+-------------------+------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 14 s: 0 batch_loss 0.4462108016014099 BPR_loss 0.4034513235092163 reg_loss 0.0427594929933548
epoch: 14 s: 256000 batch_loss 0.4556204378604889 BPR_loss 0.41254156827926636 reg_loss 0.04307887703180313
epoch: 14 s: 512000 batch_loss 0.46482208371162415 BPR_loss 0.4213534891605377 reg_loss 0.04346860200166702
epoch: 14 s: 768000 batch_loss 0.44109907746315 BPR_loss 0.3976419270038605 reg_loss 0.043457139283418655
epoch: 14 s: 1024000 batch_loss 0.4388503134250641 BPR_loss 0.3951037526130676 reg_loss 0.04374656081199646
epoch: 14 s: 1280000 batch_loss 0.4437420964241028 BPR_loss 0.40041008591651917 reg_loss 0.043332021683454514
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   14  | 77.16746544837952 | 418.5484850406647  | 299.6921691894531 | [0.04677434 0.06892101 0.08545011] | [0.02155864 0.02621668 0.02923047] | [0.00261309 0.00194421 0.00161525] | [0.0517361  0.07639563 0.09487751] |
|   14  | 77.16746544837952 | 413.32015466690063 | 299.6921691894531 | [0.06107555 0.08899967 0.10961926] | [0.02759898 0.0334725  0.03723422] | [0.00346614 0.00255046 0.00210145] | [0.06812524 0.0997731  0.12281766] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 15 s: 0 batch_loss 0.4288650155067444 BPR_loss 0.3845451772212982 reg_loss 0.04431983083486557
epoch: 15 s: 256000 batch_loss 0.4238027334213257 BPR_loss 0.3785490393638611 reg_loss 0.045253679156303406
epoch: 15 s: 512000 batch_loss 0.44179293513298035 BPR_loss 0.39847704768180847 reg_loss 0.04331587627530098
epoch: 15 s: 768000 batch_loss 0.43598058819770813 BPR_loss 0.39020639657974243 reg_loss 0.045774199068546295
epoch: 15 s: 1024000 batch_loss 0.4212183654308319 BPR_loss 0.3737810254096985 reg_loss 0.04743734747171402
epoch: 15 s: 1280000 batch_loss 0.4278016686439514 BPR_loss 0.3821423351764679 reg_loss 0.04565931856632233
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 80.11454892158508 | 413.22244334220886 | 289.30889892578125 | [0.04687686 0.06924465 0.08515091] | [0.0215685  0.02626589 0.02916543] | [0.00261966 0.0019537  0.00160953] | [0.05189675 0.07684837 0.0945124 ] |
|   15  | 80.11454892158508 | 411.4337227344513  | 289.30889892578125 | [0.06140616 0.0892626  0.11036583] | [0.0277799  0.03363478 0.03749289] | [0.00348583 0.00255657 0.00211839] | [0.06852704 0.10000158 0.1237552 ] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 16 s: 0 batch_loss 0.41504642367362976 BPR_loss 0.3689047694206238 reg_loss 0.04614165425300598
epoch: 16 s: 256000 batch_loss 0.42339619994163513 BPR_loss 0.3766736686229706 reg_loss 0.04672253876924515
epoch: 16 s: 512000 batch_loss 0.4146527349948883 BPR_loss 0.366887629032135 reg_loss 0.0477650985121727
epoch: 16 s: 768000 batch_loss 0.40885215997695923 BPR_loss 0.36094850301742554 reg_loss 0.04790365695953369
epoch: 16 s: 1024000 batch_loss 0.41867777705192566 BPR_loss 0.37106865644454956 reg_loss 0.0476091168820858
epoch: 16 s: 1280000 batch_loss 0.4151765704154968 BPR_loss 0.36765623092651367 reg_loss 0.04752034321427345
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   16  | 78.42903780937195 |  408.543306350708 | 279.2710876464844 | [0.04684493 0.06874971 0.08497904] | [0.02155526 0.0261595  0.02911663] | [0.0026182  0.0019391  0.00160429] | [0.05183833 0.07626419 0.09430793] |
|   16  | 78.42903780937195 | 411.9867866039276 | 279.2710876464844 | [0.06154679 0.08970994 0.11067603] | [0.027921   0.03384656 0.0376806 ] | [0.00349096 0.00256898 0.00212496] | [0.06865309 0.10040338 0.12412549] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 17 s: 0 batch_loss 0.40185996890068054 BPR_loss 0.3534606397151947 reg_loss 0.04839932918548584
epoch: 17 s: 256000 batch_loss 0.40317583084106445 BPR_loss 0.3537769615650177 reg_loss 0.049398865550756454
epoch: 17 s: 512000 batch_loss 0.397553414106369 BPR_loss 0.34875109791755676 reg_loss 0.04880230873823166
epoch: 17 s: 768000 batch_loss 0.3964964747428894 BPR_loss 0.34671589732170105 reg_loss 0.04978056624531746
epoch: 17 s: 1024000 batch_loss 0.4084353744983673 BPR_loss 0.3595049977302551 reg_loss 0.04893038049340248
epoch: 17 s: 1280000 batch_loss 0.39767444133758545 BPR_loss 0.34745103120803833 reg_loss 0.05022341385483742
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   17  | 78.30840635299683 | 406.94216680526733 | 269.6640319824219 | [0.04695132 0.06865975 0.08471117] | [0.02166279 0.0262196  0.02914493] | [0.0026204  0.00193435 0.00159821] | [0.05189675 0.07606703 0.09394282] |
|   17  | 78.30840635299683 | 411.2493944168091  | 269.6640319824219 | [0.06168956 0.0897186  0.11102347] | [0.02798867 0.03388547 0.03778206] | [0.00350553 0.00256839 0.00213271] | [0.06891308 0.10044277 0.1245588 ] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 18 s: 0 batch_loss 0.4153481125831604 BPR_loss 0.3648011088371277 reg_loss 0.05054701119661331
epoch: 18 s: 256000 batch_loss 0.38521844148635864 BPR_loss 0.33507341146469116 reg_loss 0.05014502629637718
epoch: 18 s: 512000 batch_loss 0.39692968130111694 BPR_loss 0.3455217480659485 reg_loss 0.051407936960458755
epoch: 18 s: 768000 batch_loss 0.39410871267318726 BPR_loss 0.3433119058609009 reg_loss 0.05079681798815727
epoch: 18 s: 1024000 batch_loss 0.38112783432006836 BPR_loss 0.32880377769470215 reg_loss 0.05232406407594681
epoch: 18 s: 1280000 batch_loss 0.3842879831790924 BPR_loss 0.33226296305656433 reg_loss 0.05202502757310867
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   18  | 77.03103470802307 |  416.010671377182  | 260.5587158203125 | [0.04670155 0.0684466  0.0842874 ] | [0.02157351 0.02614493 0.0290296 ] | [0.00260397 0.00192906 0.00159005] | [0.05159005 0.07592099 0.09351199] |
|   18  | 77.03103470802307 | 419.29760551452637 | 260.5587158203125 | [0.06141338 0.08963209 0.11063098] | [0.02790876 0.03384715 0.03768863] | [0.00348662 0.0025672  0.00212391] | [0.06855067 0.10036399 0.12410185] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 19 s: 0 batch_loss 0.38802874088287354 BPR_loss 0.33658844232559204 reg_loss 0.05144031345844269
epoch: 19 s: 256000 batch_loss 0.38236692547798157 BPR_loss 0.3286511301994324 reg_loss 0.05371579900383949
epoch: 19 s: 512000 batch_loss 0.3739202320575714 BPR_loss 0.32078036665916443 reg_loss 0.05313987657427788
epoch: 19 s: 768000 batch_loss 0.3783661127090454 BPR_loss 0.32459548115730286 reg_loss 0.05377064645290375
epoch: 19 s: 1024000 batch_loss 0.3813994526863098 BPR_loss 0.32686376571655273 reg_loss 0.054535672068595886
epoch: 19 s: 1280000 batch_loss 0.3719368278980255 BPR_loss 0.3178239166736603 reg_loss 0.054112907499074936
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   19  | 78.61309099197388 | 408.70481729507446 | 252.04922485351562 | [0.04630373 0.06803781 0.08350653] | [0.02140513 0.02597765 0.02879709] | [0.00258096 0.00191592 0.00157484] | [0.05116653 0.07538793 0.09266494] |
|   19  | 78.61309099197388 | 409.73162055015564 | 252.04922485351562 | [0.06123367 0.08947573 0.11062581] | [0.02785804 0.03381137 0.03767965] | [0.00347283 0.00256366 0.00212404] | [0.06830644 0.10023793 0.1240861 ] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 20 s: 0 batch_loss 0.3701748251914978 BPR_loss 0.3172059655189514 reg_loss 0.05296885967254639
epoch: 20 s: 256000 batch_loss 0.35762882232666016 BPR_loss 0.3036764860153198 reg_loss 0.053952332586050034
epoch: 20 s: 512000 batch_loss 0.366872638463974 BPR_loss 0.31197288632392883 reg_loss 0.05489974468946457
epoch: 20 s: 768000 batch_loss 0.36770570278167725 BPR_loss 0.31320899724960327 reg_loss 0.054496705532073975
epoch: 20 s: 1024000 batch_loss 0.37183740735054016 BPR_loss 0.3164960741996765 reg_loss 0.055341340601444244
epoch: 20 s: 1280000 batch_loss 0.37100306153297424 BPR_loss 0.3155103325843811 reg_loss 0.055492717772722244
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch | training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 76.8587954044342 | 424.9445552825928 | 243.65322875976562 | [0.04633541 0.06745841 0.08313167] | [0.02133919 0.02578098 0.02863883] | [0.00258096 0.00189912 0.00156766] | [0.05113002 0.07473073 0.09223411] |
|   20  | 76.8587954044342 | 405.4240071773529 | 243.65322875976562 | [0.06136665 0.08971833 0.11059671] | [0.02798485 0.03395663 0.03777636] | [0.00348071 0.00256799 0.00212273] | [0.06848765 0.10040338 0.12407822] |
+-------+------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 21 s: 0 batch_loss 0.3635496497154236 BPR_loss 0.3080085515975952 reg_loss 0.055541086941957474
epoch: 21 s: 256000 batch_loss 0.34916651248931885 BPR_loss 0.2932421565055847 reg_loss 0.05592436343431473
epoch: 21 s: 512000 batch_loss 0.36413973569869995 BPR_loss 0.3082452118396759 reg_loss 0.05589453503489494
epoch: 21 s: 768000 batch_loss 0.34941551089286804 BPR_loss 0.29210561513900757 reg_loss 0.057309892028570175
epoch: 21 s: 1024000 batch_loss 0.3569493293762207 BPR_loss 0.299785852432251 reg_loss 0.05716348811984062
epoch: 21 s: 1280000 batch_loss 0.3495584726333618 BPR_loss 0.2929694652557373 reg_loss 0.05658901855349541
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   21  | 78.44600200653076 | 416.8482778072357 | 236.2713623046875 | [0.04624669 0.06740211 0.08295189] | [0.02135091 0.02579589 0.02863366] | [0.00257549 0.00189711 0.00156523] | [0.05104239 0.07466501 0.09210997] |
|   21  | 78.44600200653076 | 406.6136362552643 | 236.2713623046875 | [0.0611881  0.0894451  0.11033076] | [0.02778722 0.03373566 0.03755002] | [0.00346732 0.00255992 0.00211537] | [0.06824341 0.10008036 0.12366854] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 22 s: 0 batch_loss 0.3485795855522156 BPR_loss 0.28983765840530396 reg_loss 0.058741938322782516
epoch: 22 s: 256000 batch_loss 0.3358258605003357 BPR_loss 0.2796579897403717 reg_loss 0.05616786703467369
epoch: 22 s: 512000 batch_loss 0.34788426756858826 BPR_loss 0.2904950976371765 reg_loss 0.05738917738199234
epoch: 22 s: 768000 batch_loss 0.34751781821250916 BPR_loss 0.2895774245262146 reg_loss 0.05794038251042366
epoch: 22 s: 1024000 batch_loss 0.3337092101573944 BPR_loss 0.2762906551361084 reg_loss 0.057418566197156906
epoch: 22 s: 1280000 batch_loss 0.3357904255390167 BPR_loss 0.2768876850605011 reg_loss 0.05890273675322533
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   22  | 79.00836682319641 | 431.62480425834656 | 229.0496063232422 | [0.04585598 0.06683068 0.08241366] | [0.02119814 0.02560631 0.02844483] | [0.00255395 0.00188105 0.00155379] | [0.05063347 0.07411004 0.09148928] |
|   22  | 79.00836682319641 | 392.72337317466736 | 229.0496063232422 | [0.06103635 0.08922786 0.11004317] | [0.02780544 0.03373977 0.03754243] | [0.00345984 0.00255263 0.00211078] | [0.06809372 0.09983613 0.12332976] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 23 s: 0 batch_loss 0.3279866874217987 BPR_loss 0.26868918538093567 reg_loss 0.059297509491443634
epoch: 23 s: 256000 batch_loss 0.33217406272888184 BPR_loss 0.273795485496521 reg_loss 0.05837856978178024
epoch: 23 s: 512000 batch_loss 0.3266353905200958 BPR_loss 0.2672858238220215 reg_loss 0.05934956669807434
epoch: 23 s: 768000 batch_loss 0.3292471468448639 BPR_loss 0.2693139612674713 reg_loss 0.05993318185210228
epoch: 23 s: 1024000 batch_loss 0.3317517936229706 BPR_loss 0.27190738916397095 reg_loss 0.059844400733709335
epoch: 23 s: 1280000 batch_loss 0.3255249857902527 BPR_loss 0.26532429456710815 reg_loss 0.06020069867372513
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   23  | 78.41981339454651 | 424.4774560928345  | 222.32388305664062 | [0.04568031 0.06650064 0.08181964] | [0.02110791 0.02547996 0.0282748 ] | [0.00254518 0.00187009 0.00154308] | [0.05045821 0.07368652 0.09084669] |
|   23  | 78.41981339454651 | 392.75902128219604 | 222.32388305664062 | [0.06110084 0.08861864 0.10964046] | [0.02781786 0.03361857 0.03746235] | [0.00346062 0.00253648 0.00210421] | [0.0681016  0.09919797 0.12293584] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 24 s: 0 batch_loss 0.3212320804595947 BPR_loss 0.26155683398246765 reg_loss 0.05967525765299797
epoch: 24 s: 256000 batch_loss 0.32971328496932983 BPR_loss 0.26989537477493286 reg_loss 0.05981789529323578
epoch: 24 s: 512000 batch_loss 0.32053837180137634 BPR_loss 0.25962814688682556 reg_loss 0.06091023236513138
epoch: 24 s: 768000 batch_loss 0.3146182596683502 BPR_loss 0.25308388471603394 reg_loss 0.06153438240289688
epoch: 24 s: 1024000 batch_loss 0.32089006900787354 BPR_loss 0.2586475610733032 reg_loss 0.06224249303340912
epoch: 24 s: 1280000 batch_loss 0.33345791697502136 BPR_loss 0.27094191312789917 reg_loss 0.06251600384712219
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   24  | 78.91504693031311 | 429.43524384498596 | 216.2288818359375 | [0.04528253 0.06588244 0.08124934] | [0.02093201 0.0252579  0.02806685] | [0.00252145 0.00185093 0.00153212] | [0.05000548 0.0729636  0.0902187 ] |
|   24  | 78.91504693031311 | 374.98701310157776 | 216.2288818359375 | [0.0607071  0.08839922 0.10929833] | [0.02776313 0.03359962 0.03741612] | [0.00344487 0.00253057 0.00209607] | [0.06778646 0.09896949 0.12249464] |
+-------+-------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 25 s: 0 batch_loss 0.31579044461250305 BPR_loss 0.2538537383079529 reg_loss 0.06193670257925987
epoch: 25 s: 256000 batch_loss 0.32865235209465027 BPR_loss 0.26574623584747314 reg_loss 0.06290612369775772
epoch: 25 s: 512000 batch_loss 0.3180215358734131 BPR_loss 0.25608962774276733 reg_loss 0.061931904405355453
epoch: 25 s: 768000 batch_loss 0.3255569338798523 BPR_loss 0.2620081305503845 reg_loss 0.06354881823062897
epoch: 25 s: 1024000 batch_loss 0.3175406754016876 BPR_loss 0.25498971343040466 reg_loss 0.06255095452070236
epoch: 25 s: 1280000 batch_loss 0.31318989396095276 BPR_loss 0.24981996417045593 reg_loss 0.06336992979049683
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 79.27922129631042 | 422.3426105976105 | 210.98721313476562 | [0.04549487 0.06570537 0.08114183] | [0.02103275 0.02527708 0.02809687] | [0.00253496 0.00184636 0.0015303 ] | [0.05025375 0.07281025 0.09012377] |
|   25  | 79.27922129631042 | 366.2034730911255 | 210.98721313476562 | [0.06030498 0.08811925 0.10849528] | [0.0276237  0.03349084 0.03721631] | [0.0034169  0.00252072 0.00208058] | [0.06724285 0.09859133 0.1215571 ] |
+-------+-------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 26 s: 0 batch_loss 0.31559568643569946 BPR_loss 0.2524113059043884 reg_loss 0.06318436563014984
epoch: 26 s: 256000 batch_loss 0.3090619444847107 BPR_loss 0.24481624364852905 reg_loss 0.06424570828676224
epoch: 26 s: 512000 batch_loss 0.31214311718940735 BPR_loss 0.24800072610378265 reg_loss 0.0641423836350441
epoch: 26 s: 768000 batch_loss 0.30692604184150696 BPR_loss 0.24298560619354248 reg_loss 0.06394043564796448
epoch: 26 s: 1024000 batch_loss 0.3130401372909546 BPR_loss 0.2485433667898178 reg_loss 0.06449677050113678
epoch: 26 s: 1280000 batch_loss 0.30214574933052063 BPR_loss 0.238088458776474 reg_loss 0.06405729800462723
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |  tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   26  | 77.81815886497498 | 414.923579454422 | 205.4244384765625 | [0.04520112 0.06548441 0.08076239] | [0.02087091 0.02512813 0.02792138] | [0.00251743 0.00183906 0.00152348] | [0.04990325 0.07254737 0.08970755] |
|   26  | 77.81815886497498 | 357.620569229126 | 205.4244384765625 | [0.06043321 0.08787984 0.10819038] | [0.02768148 0.03346663 0.03718228] | [0.00342635 0.00251461 0.00207545] | [0.06743981 0.09834709 0.12128923] |
+-------+-------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 27 s: 0 batch_loss 0.296853244304657 BPR_loss 0.2336474359035492 reg_loss 0.06320580840110779
epoch: 27 s: 256000 batch_loss 0.3122633695602417 BPR_loss 0.24844315648078918 reg_loss 0.06382022798061371
epoch: 27 s: 512000 batch_loss 0.30514290928840637 BPR_loss 0.23982056975364685 reg_loss 0.06532233208417892
epoch: 27 s: 768000 batch_loss 0.3045603334903717 BPR_loss 0.2406470775604248 reg_loss 0.0639132484793663
epoch: 27 s: 1024000 batch_loss 0.2980005145072937 BPR_loss 0.2326231449842453 reg_loss 0.0653773620724678
epoch: 27 s: 1280000 batch_loss 0.3035045862197876 BPR_loss 0.2390584647655487 reg_loss 0.0644461065530777
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   27  | 78.52341437339783 | 412.3709650039673  | 200.69480895996094 | [0.04509002 0.06526282 0.08047417] | [0.02081754 0.0250502  0.0278282 ] | [0.00251451 0.00183285 0.00151655] | [0.04985943 0.0723064  0.08936434] |
|   27  | 78.52341437339783 | 350.42276787757874 | 200.69480895996094 | [0.06052957 0.08739577 0.10785115] | [0.02766305 0.03332281 0.03706572] | [0.00343187 0.00249984 0.0020706 ] | [0.06755799 0.09775621 0.12092682] |
+-------+-------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.06052957104218014
early stopping at 27, recall@20:0.0617
