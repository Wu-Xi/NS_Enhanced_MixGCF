Namespace(K=1, Ks='[20, 40, 60]', batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, eps=0.01, gnn='lightgcn', gpu_id=3, l2=0.0001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='final', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
这是两个item维度层面上的权重自适应......
start training ...
epoch: 0 s: 0 batch_loss 0.6931477189064026 BPR_loss 0.6931471824645996 reg_loss 5.096079007671506e-07
epoch: 0 s: 256000 batch_loss 0.693147599697113 BPR_loss 0.6931471824645996 reg_loss 4.100248247596028e-07
epoch: 0 s: 512000 batch_loss 0.6931475400924683 BPR_loss 0.6931471824645996 reg_loss 3.476428105386731e-07
epoch: 0 s: 768000 batch_loss 0.6931474208831787 BPR_loss 0.6931471228599548 reg_loss 3.0685001206620655e-07
epoch: 0 s: 1024000 batch_loss 0.6931468844413757 BPR_loss 0.6931465864181519 reg_loss 3.0432110520450806e-07
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 218.32608842849731 | 49.98738408088684 | 418.6601257324219 | [0.02779975 0.04654518 0.06232396] | [0.02241319 0.029517   0.03504555] | [0.01234685 0.01044035 0.00941329] | [0.1779083  0.26158899 0.31918656] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.6931320428848267 BPR_loss 0.6931310892105103 reg_loss 9.684165434009628e-07
epoch: 1 s: 256000 batch_loss 0.6926425695419312 BPR_loss 0.692623496055603 reg_loss 1.9072964278166182e-05
epoch: 1 s: 512000 batch_loss 0.6906093955039978 BPR_loss 0.6904911994934082 reg_loss 0.00011818630446214229
epoch: 1 s: 768000 batch_loss 0.6821491718292236 BPR_loss 0.6817708015441895 reg_loss 0.0003783900465350598
epoch: 1 s: 1024000 batch_loss 0.6687354445457458 BPR_loss 0.6679009199142456 reg_loss 0.0008345373789779842
using time 219.4302s, training loss at epoch 1: 412.6886
epoch: 2 s: 0 batch_loss 0.6565149426460266 BPR_loss 0.6551803350448608 reg_loss 0.0013345920015126467
epoch: 2 s: 256000 batch_loss 0.639763593673706 BPR_loss 0.6377289295196533 reg_loss 0.0020346748642623425
epoch: 2 s: 512000 batch_loss 0.6163538694381714 BPR_loss 0.6134858727455139 reg_loss 0.0028679720126092434
epoch: 2 s: 768000 batch_loss 0.5940907001495361 BPR_loss 0.5902644395828247 reg_loss 0.0038262801244854927
epoch: 2 s: 1024000 batch_loss 0.5656612515449524 BPR_loss 0.5607976913452148 reg_loss 0.004863574635237455
using time 214.7163s, training loss at epoch 2: 365.6127
epoch: 3 s: 0 batch_loss 0.5492554306983948 BPR_loss 0.5434893369674683 reg_loss 0.005766088608652353
epoch: 3 s: 256000 batch_loss 0.5349419116973877 BPR_loss 0.5280256271362305 reg_loss 0.006916309241205454
epoch: 3 s: 512000 batch_loss 0.5072528719902039 BPR_loss 0.4992098808288574 reg_loss 0.008042979054152966
epoch: 3 s: 768000 batch_loss 0.4928399324417114 BPR_loss 0.4835616648197174 reg_loss 0.009278264828026295
epoch: 3 s: 1024000 batch_loss 0.47711917757987976 BPR_loss 0.46669071912765503 reg_loss 0.010428463108837605
using time 213.3320s, training loss at epoch 3: 303.3997
epoch: 4 s: 0 batch_loss 0.45250827074050903 BPR_loss 0.44101381301879883 reg_loss 0.011494460515677929
epoch: 4 s: 256000 batch_loss 0.43823644518852234 BPR_loss 0.42551523447036743 reg_loss 0.012721196748316288
epoch: 4 s: 512000 batch_loss 0.4262329936027527 BPR_loss 0.4123799502849579 reg_loss 0.013853042386472225
epoch: 4 s: 768000 batch_loss 0.39664432406425476 BPR_loss 0.3814930319786072 reg_loss 0.015151284635066986
epoch: 4 s: 1024000 batch_loss 0.40102827548980713 BPR_loss 0.38467463850975037 reg_loss 0.016353638842701912
using time 216.3501s, training loss at epoch 4: 252.1200
epoch: 5 s: 0 batch_loss 0.386152982711792 BPR_loss 0.3688315749168396 reg_loss 0.017321420833468437
epoch: 5 s: 256000 batch_loss 0.3638364374637604 BPR_loss 0.3452795147895813 reg_loss 0.018556931987404823
epoch: 5 s: 512000 batch_loss 0.35973161458969116 BPR_loss 0.34001854062080383 reg_loss 0.01971307024359703
epoch: 5 s: 768000 batch_loss 0.34342169761657715 BPR_loss 0.3225438594818115 reg_loss 0.02087784744799137
epoch: 5 s: 1024000 batch_loss 0.3350418508052826 BPR_loss 0.3129216730594635 reg_loss 0.022120170295238495
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 209.4200165271759 | 43.19126534461975 | 213.6573486328125 | [0.03578266 0.06103801 0.08192939] | [0.02842369 0.03808014 0.04544526] | [0.01622774 0.01396836 0.01260157] | [0.23983201 0.35843754 0.43760263] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.3261384665966034 BPR_loss 0.303167462348938 reg_loss 0.02297101356089115
epoch: 6 s: 256000 batch_loss 0.31819358468055725 BPR_loss 0.29410627484321594 reg_loss 0.024087300524115562
epoch: 6 s: 512000 batch_loss 0.30374449491500854 BPR_loss 0.27850574254989624 reg_loss 0.0252387598156929
epoch: 6 s: 768000 batch_loss 0.3036699593067169 BPR_loss 0.27743375301361084 reg_loss 0.02623620629310608
epoch: 6 s: 1024000 batch_loss 0.29346010088920593 BPR_loss 0.2660471796989441 reg_loss 0.027412932366132736
using time 212.5139s, training loss at epoch 6: 184.3499
epoch: 7 s: 0 batch_loss 0.28230756521224976 BPR_loss 0.25400400161743164 reg_loss 0.02830355241894722
epoch: 7 s: 256000 batch_loss 0.268629789352417 BPR_loss 0.23928001523017883 reg_loss 0.029349785298109055
epoch: 7 s: 512000 batch_loss 0.26384639739990234 BPR_loss 0.23344364762306213 reg_loss 0.030402742326259613
epoch: 7 s: 768000 batch_loss 0.26489153504371643 BPR_loss 0.23348596692085266 reg_loss 0.03140556067228317
epoch: 7 s: 1024000 batch_loss 0.2563171088695526 BPR_loss 0.22391477227210999 reg_loss 0.03240234777331352
using time 207.1358s, training loss at epoch 7: 162.5697
epoch: 8 s: 0 batch_loss 0.2581068277359009 BPR_loss 0.22485753893852234 reg_loss 0.03324928507208824
epoch: 8 s: 256000 batch_loss 0.24577003717422485 BPR_loss 0.2117096483707428 reg_loss 0.03406038135290146
epoch: 8 s: 512000 batch_loss 0.23747502267360687 BPR_loss 0.20249086618423462 reg_loss 0.03498416021466255
epoch: 8 s: 768000 batch_loss 0.2342483401298523 BPR_loss 0.19836723804473877 reg_loss 0.03588109835982323
epoch: 8 s: 1024000 batch_loss 0.22841882705688477 BPR_loss 0.19152697920799255 reg_loss 0.03689185529947281
using time 209.6852s, training loss at epoch 8: 145.8813
epoch: 9 s: 0 batch_loss 0.22878454625606537 BPR_loss 0.19130846858024597 reg_loss 0.037476081401109695
epoch: 9 s: 256000 batch_loss 0.2305721789598465 BPR_loss 0.19229236245155334 reg_loss 0.03827982023358345
epoch: 9 s: 512000 batch_loss 0.2130797803401947 BPR_loss 0.1739262044429779 reg_loss 0.0391535684466362
epoch: 9 s: 768000 batch_loss 0.21826280653476715 BPR_loss 0.17820173501968384 reg_loss 0.04006107151508331
epoch: 9 s: 1024000 batch_loss 0.21245437860488892 BPR_loss 0.17179131507873535 reg_loss 0.04066307097673416
using time 210.2402s, training loss at epoch 9: 132.9707
epoch: 10 s: 0 batch_loss 0.20912876725196838 BPR_loss 0.16774044930934906 reg_loss 0.041388317942619324
epoch: 10 s: 256000 batch_loss 0.2117851823568344 BPR_loss 0.1696585714817047 reg_loss 0.04212661460042
epoch: 10 s: 512000 batch_loss 0.21049551665782928 BPR_loss 0.16772925853729248 reg_loss 0.042766254395246506
epoch: 10 s: 768000 batch_loss 0.20796170830726624 BPR_loss 0.16445815563201904 reg_loss 0.04350355267524719
epoch: 10 s: 1024000 batch_loss 0.20208263397216797 BPR_loss 0.15779604017734528 reg_loss 0.04428659379482269
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 206.85744714736938 | 49.66609334945679 | 122.65611267089844 | [0.0272027  0.04755818 0.06566084] | [0.02067815 0.02854995 0.03486944] | [0.01143899 0.01012536 0.00939013] | [0.1779083  0.27984085 0.35565871] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.1955224573612213 BPR_loss 0.15073281526565552 reg_loss 0.044789645820856094
epoch: 11 s: 256000 batch_loss 0.19525982439517975 BPR_loss 0.14989854395389557 reg_loss 0.04536128416657448
epoch: 11 s: 512000 batch_loss 0.19218045473098755 BPR_loss 0.1460282802581787 reg_loss 0.04615217074751854
epoch: 11 s: 768000 batch_loss 0.19186249375343323 BPR_loss 0.14523503184318542 reg_loss 0.046627454459667206
epoch: 11 s: 1024000 batch_loss 0.18490377068519592 BPR_loss 0.13766083121299744 reg_loss 0.04724293574690819
using time 210.7154s, training loss at epoch 11: 114.5086
epoch: 12 s: 0 batch_loss 0.19313772022724152 BPR_loss 0.14533114433288574 reg_loss 0.047806572169065475
epoch: 12 s: 256000 batch_loss 0.18367771804332733 BPR_loss 0.13530394434928894 reg_loss 0.04837377741932869
epoch: 12 s: 512000 batch_loss 0.1779177188873291 BPR_loss 0.1290530115365982 reg_loss 0.04886471480131149
epoch: 12 s: 768000 batch_loss 0.18291263282299042 BPR_loss 0.13339778780937195 reg_loss 0.04951484501361847
epoch: 12 s: 1024000 batch_loss 0.16837836802005768 BPR_loss 0.11864710599184036 reg_loss 0.049731262028217316
using time 209.8504s, training loss at epoch 12: 107.9077
epoch: 13 s: 0 batch_loss 0.1682073175907135 BPR_loss 0.11801005899906158 reg_loss 0.050197258591651917
epoch: 13 s: 256000 batch_loss 0.17074885964393616 BPR_loss 0.1198359876871109 reg_loss 0.050912875682115555
epoch: 13 s: 512000 batch_loss 0.1713164746761322 BPR_loss 0.1200973242521286 reg_loss 0.0512191504240036
epoch: 13 s: 768000 batch_loss 0.16873911023139954 BPR_loss 0.11708806455135345 reg_loss 0.05165104195475578
epoch: 13 s: 1024000 batch_loss 0.16671988368034363 BPR_loss 0.11439132690429688 reg_loss 0.052328549325466156
using time 210.4314s, training loss at epoch 13: 102.4360
epoch: 14 s: 0 batch_loss 0.16322356462478638 BPR_loss 0.11081746220588684 reg_loss 0.052406102418899536
epoch: 14 s: 256000 batch_loss 0.1654859036207199 BPR_loss 0.11258023977279663 reg_loss 0.05290566757321358
epoch: 14 s: 512000 batch_loss 0.15875853598117828 BPR_loss 0.10558655858039856 reg_loss 0.053171977400779724
epoch: 14 s: 768000 batch_loss 0.15741406381130219 BPR_loss 0.1037496030330658 reg_loss 0.05366446450352669
epoch: 14 s: 1024000 batch_loss 0.15559151768684387 BPR_loss 0.10151293873786926 reg_loss 0.05407858267426491
using time 211.7935s, training loss at epoch 14: 97.8057
epoch: 15 s: 0 batch_loss 0.15744376182556152 BPR_loss 0.10309571027755737 reg_loss 0.05434805154800415
epoch: 15 s: 256000 batch_loss 0.15821868181228638 BPR_loss 0.10363108664751053 reg_loss 0.05458759516477585
epoch: 15 s: 512000 batch_loss 0.1545882672071457 BPR_loss 0.09949272871017456 reg_loss 0.05509554222226143
epoch: 15 s: 768000 batch_loss 0.15250399708747864 BPR_loss 0.09720473736524582 reg_loss 0.05529925972223282
epoch: 15 s: 1024000 batch_loss 0.15225672721862793 BPR_loss 0.09661474823951721 reg_loss 0.05564197897911072
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   15  | 207.95160126686096 | 48.02207565307617 | 94.040771484375 | [0.01960452 0.03541339 0.04947882] | [0.01449923 0.02064991 0.02554087] | [0.00772546 0.00710654 0.00672024] | [0.12337375 0.20468612 0.26676772] |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 16 s: 0 batch_loss 0.1529688835144043 BPR_loss 0.09671232104301453 reg_loss 0.05625656619668007
epoch: 16 s: 256000 batch_loss 0.1515362709760666 BPR_loss 0.09533047676086426 reg_loss 0.05620579794049263
epoch: 16 s: 512000 batch_loss 0.15075835585594177 BPR_loss 0.09413313865661621 reg_loss 0.05662521719932556
epoch: 16 s: 768000 batch_loss 0.15333189070224762 BPR_loss 0.0965036004781723 reg_loss 0.056828293949365616
epoch: 16 s: 1024000 batch_loss 0.14363862574100494 BPR_loss 0.08674177527427673 reg_loss 0.05689685419201851
using time 212.1205s, training loss at epoch 16: 90.6145
epoch: 17 s: 0 batch_loss 0.1523217409849167 BPR_loss 0.09521690011024475 reg_loss 0.057104844599962234
epoch: 17 s: 256000 batch_loss 0.144889697432518 BPR_loss 0.08743613958358765 reg_loss 0.05745356157422066
epoch: 17 s: 512000 batch_loss 0.146036297082901 BPR_loss 0.08816944062709808 reg_loss 0.05786685645580292
epoch: 17 s: 768000 batch_loss 0.14484605193138123 BPR_loss 0.08709289133548737 reg_loss 0.05775316059589386
epoch: 17 s: 1024000 batch_loss 0.14413796365261078 BPR_loss 0.0859290137887001 reg_loss 0.05820894613862038
using time 211.0598s, training loss at epoch 17: 87.8399
epoch: 18 s: 0 batch_loss 0.14268037676811218 BPR_loss 0.08439791947603226 reg_loss 0.058282457292079926
epoch: 18 s: 256000 batch_loss 0.1413876712322235 BPR_loss 0.08284001052379608 reg_loss 0.058547668159008026
epoch: 18 s: 512000 batch_loss 0.14329546689987183 BPR_loss 0.08477751910686493 reg_loss 0.0585179440677166
epoch: 18 s: 768000 batch_loss 0.14325401186943054 BPR_loss 0.08392969518899918 reg_loss 0.059324320405721664
epoch: 18 s: 1024000 batch_loss 0.1428808867931366 BPR_loss 0.08379152417182922 reg_loss 0.05908936634659767
using time 208.2051s, training loss at epoch 18: 85.2154
epoch: 19 s: 0 batch_loss 0.1379891186952591 BPR_loss 0.07872419059276581 reg_loss 0.059264928102493286
epoch: 19 s: 256000 batch_loss 0.13859832286834717 BPR_loss 0.07908093184232712 reg_loss 0.05951739475131035
epoch: 19 s: 512000 batch_loss 0.13600848615169525 BPR_loss 0.07614477723836899 reg_loss 0.05986371263861656
epoch: 19 s: 768000 batch_loss 0.1336604207754135 BPR_loss 0.07397057116031647 reg_loss 0.059689853340387344
epoch: 19 s: 1024000 batch_loss 0.13681353628635406 BPR_loss 0.0771099105477333 reg_loss 0.05970362573862076
using time 214.1598s, training loss at epoch 19: 82.9312
epoch: 20 s: 0 batch_loss 0.13620951771736145 BPR_loss 0.07589767128229141 reg_loss 0.060311850160360336
epoch: 20 s: 256000 batch_loss 0.1359974443912506 BPR_loss 0.07575125992298126 reg_loss 0.06024617701768875
epoch: 20 s: 512000 batch_loss 0.1310424953699112 BPR_loss 0.07097388058900833 reg_loss 0.06006861478090286
epoch: 20 s: 768000 batch_loss 0.13020960986614227 BPR_loss 0.07018005847930908 reg_loss 0.06002955138683319
epoch: 20 s: 1024000 batch_loss 0.13007280230522156 BPR_loss 0.06977764517068863 reg_loss 0.06029515340924263
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   20  | 209.68208241462708 | 46.626065731048584 | 80.92911529541016 | [0.01381447 0.02400681 0.03330773] | [0.01010736 0.01404519 0.0172391 ] | [0.005084   0.00450534 0.0042414 ] | [0.08042819 0.13123658 0.17418214] |
+-------+--------------------+--------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 21 s: 0 batch_loss 0.12689819931983948 BPR_loss 0.06637848913669586 reg_loss 0.06051970645785332
epoch: 21 s: 256000 batch_loss 0.13063545525074005 BPR_loss 0.06997427344322205 reg_loss 0.060661181807518005
epoch: 21 s: 512000 batch_loss 0.13003088533878326 BPR_loss 0.06931231915950775 reg_loss 0.06071856617927551
epoch: 21 s: 768000 batch_loss 0.13043224811553955 BPR_loss 0.06956814229488373 reg_loss 0.060864102095365524
epoch: 21 s: 1024000 batch_loss 0.130977600812912 BPR_loss 0.07000458240509033 reg_loss 0.06097301468253136
using time 208.9628s, training loss at epoch 21: 79.0983
epoch: 22 s: 0 batch_loss 0.12784644961357117 BPR_loss 0.0666787326335907 reg_loss 0.061167724430561066
epoch: 22 s: 256000 batch_loss 0.12736690044403076 BPR_loss 0.06629922986030579 reg_loss 0.06106766313314438
epoch: 22 s: 512000 batch_loss 0.129451185464859 BPR_loss 0.06824426352977753 reg_loss 0.061206918209791183
epoch: 22 s: 768000 batch_loss 0.13010026514530182 BPR_loss 0.06881009787321091 reg_loss 0.06129017099738121
epoch: 22 s: 1024000 batch_loss 0.13134893774986267 BPR_loss 0.06961379945278168 reg_loss 0.06173514202237129
using time 207.9663s, training loss at epoch 22: 77.5005
epoch: 23 s: 0 batch_loss 0.12679582834243774 BPR_loss 0.0653894767165184 reg_loss 0.061406347900629044
epoch: 23 s: 256000 batch_loss 0.1259622871875763 BPR_loss 0.0640954077243805 reg_loss 0.0618668757379055
epoch: 23 s: 512000 batch_loss 0.12381603568792343 BPR_loss 0.06197936087846756 reg_loss 0.06183667480945587
epoch: 23 s: 768000 batch_loss 0.12814971804618835 BPR_loss 0.06642812490463257 reg_loss 0.061721593141555786
epoch: 23 s: 1024000 batch_loss 0.12584954500198364 BPR_loss 0.06447824835777283 reg_loss 0.06137129291892052
using time 210.9489s, training loss at epoch 23: 75.9540
epoch: 24 s: 0 batch_loss 0.1233697161078453 BPR_loss 0.061732400208711624 reg_loss 0.06163731589913368
epoch: 24 s: 256000 batch_loss 0.12403402477502823 BPR_loss 0.0621681809425354 reg_loss 0.06186584383249283
epoch: 24 s: 512000 batch_loss 0.12041755020618439 BPR_loss 0.058031804859638214 reg_loss 0.062385741621255875
epoch: 24 s: 768000 batch_loss 0.12248044461011887 BPR_loss 0.06068943068385124 reg_loss 0.061791013926267624
epoch: 24 s: 1024000 batch_loss 0.12222596257925034 BPR_loss 0.06006801128387451 reg_loss 0.062157951295375824
using time 211.5495s, training loss at epoch 24: 74.6004
epoch: 25 s: 0 batch_loss 0.12395431101322174 BPR_loss 0.062327150255441666 reg_loss 0.061627160757780075
epoch: 25 s: 256000 batch_loss 0.12149198353290558 BPR_loss 0.05946073681116104 reg_loss 0.06203124299645424
epoch: 25 s: 512000 batch_loss 0.1260949969291687 BPR_loss 0.06384117156267166 reg_loss 0.06225381791591644
epoch: 25 s: 768000 batch_loss 0.12022377550601959 BPR_loss 0.05830540508031845 reg_loss 0.06191837042570114
epoch: 25 s: 1024000 batch_loss 0.12147196382284164 BPR_loss 0.05927882716059685 reg_loss 0.0621931366622448
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   25  | 208.09641456604004 | 46.78570556640625 | 73.29487609863281 | [0.01147336 0.02018591 0.02792726] | [0.00815156 0.01151239 0.01415503] | [0.00411141 0.00369458 0.00346775] | [0.06495516 0.1079323  0.14519389] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 26 s: 0 batch_loss 0.1200454980134964 BPR_loss 0.057908959686756134 reg_loss 0.062136534601449966
epoch: 26 s: 256000 batch_loss 0.1179247573018074 BPR_loss 0.05587073042988777 reg_loss 0.06205402687191963
epoch: 26 s: 512000 batch_loss 0.11878985166549683 BPR_loss 0.057052284479141235 reg_loss 0.06173757091164589
epoch: 26 s: 768000 batch_loss 0.11785178631544113 BPR_loss 0.05562116205692291 reg_loss 0.06223062425851822
epoch: 26 s: 1024000 batch_loss 0.11879223585128784 BPR_loss 0.05666234344244003 reg_loss 0.06212989240884781
using time 208.0826s, training loss at epoch 26: 72.1165
epoch: 27 s: 0 batch_loss 0.11797360330820084 BPR_loss 0.055939681828022 reg_loss 0.06203392148017883
epoch: 27 s: 256000 batch_loss 0.11952473223209381 BPR_loss 0.05719719082117081 reg_loss 0.062327537685632706
epoch: 27 s: 512000 batch_loss 0.11681599915027618 BPR_loss 0.05468596890568733 reg_loss 0.06213002651929855
epoch: 27 s: 768000 batch_loss 0.11654674261808395 BPR_loss 0.05430016666650772 reg_loss 0.06224657595157623
epoch: 27 s: 1024000 batch_loss 0.11622238904237747 BPR_loss 0.05385772883892059 reg_loss 0.06236466020345688
using time 215.6196s, training loss at epoch 27: 71.0292
epoch: 28 s: 0 batch_loss 0.11686152219772339 BPR_loss 0.05491314083337784 reg_loss 0.06194838136434555
epoch: 28 s: 256000 batch_loss 0.1131754219532013 BPR_loss 0.051108427345752716 reg_loss 0.062066998332738876
epoch: 28 s: 512000 batch_loss 0.11528057605028152 BPR_loss 0.053465381264686584 reg_loss 0.06181519478559494
epoch: 28 s: 768000 batch_loss 0.11426568776369095 BPR_loss 0.05183514207601547 reg_loss 0.062430545687675476
epoch: 28 s: 1024000 batch_loss 0.11321090161800385 BPR_loss 0.05067703500390053 reg_loss 0.06253387033939362
using time 208.3375s, training loss at epoch 28: 69.9956
epoch: 29 s: 0 batch_loss 0.1167215034365654 BPR_loss 0.054831184446811676 reg_loss 0.06189031898975372
epoch: 29 s: 256000 batch_loss 0.11261196434497833 BPR_loss 0.05019728094339371 reg_loss 0.062414683401584625
epoch: 29 s: 512000 batch_loss 0.11604062467813492 BPR_loss 0.05340460687875748 reg_loss 0.06263601779937744
epoch: 29 s: 768000 batch_loss 0.1139458417892456 BPR_loss 0.05173983424901962 reg_loss 0.062206003814935684
epoch: 29 s: 1024000 batch_loss 0.11462321132421494 BPR_loss 0.052339307963848114 reg_loss 0.06228390336036682
using time 212.6411s, training loss at epoch 29: 69.0979
epoch: 30 s: 0 batch_loss 0.11402806639671326 BPR_loss 0.051695629954338074 reg_loss 0.062332432717084885
epoch: 30 s: 256000 batch_loss 0.11310161650180817 BPR_loss 0.051030319184064865 reg_loss 0.0620713010430336
epoch: 30 s: 512000 batch_loss 0.11605749279260635 BPR_loss 0.05354931950569153 reg_loss 0.06250817328691483
epoch: 30 s: 768000 batch_loss 0.11256532371044159 BPR_loss 0.050333041697740555 reg_loss 0.06223228573799133
epoch: 30 s: 1024000 batch_loss 0.11265933513641357 BPR_loss 0.05059494078159332 reg_loss 0.06206439062952995
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |       Loss      |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   30  | 211.98575043678284 | 48.61909294128418 | 68.246337890625 | [0.00983759 0.01755914 0.02356494] | [0.00667863 0.0096366  0.01166876] | [0.00345617 0.00313724 0.0028483 ] | [0.05399773 0.08942781 0.11459517] |
+-------+--------------------+-------------------+-----------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 31 s: 0 batch_loss 0.11024263501167297 BPR_loss 0.04808349162340164 reg_loss 0.06215913966298103
epoch: 31 s: 256000 batch_loss 0.11198738217353821 BPR_loss 0.049685560166835785 reg_loss 0.06230182200670242
epoch: 31 s: 512000 batch_loss 0.11017921566963196 BPR_loss 0.04816813766956329 reg_loss 0.06201108172535896
epoch: 31 s: 768000 batch_loss 0.11020761728286743 BPR_loss 0.0480390265583992 reg_loss 0.06216859072446823
epoch: 31 s: 1024000 batch_loss 0.11031849682331085 BPR_loss 0.04869123548269272 reg_loss 0.061627257615327835
using time 208.2494s, training loss at epoch 31: 67.3064
epoch: 32 s: 0 batch_loss 0.1103285551071167 BPR_loss 0.048483893275260925 reg_loss 0.06184466555714607
epoch: 32 s: 256000 batch_loss 0.11215592920780182 BPR_loss 0.05022208392620087 reg_loss 0.06193384900689125
epoch: 32 s: 512000 batch_loss 0.10927936434745789 BPR_loss 0.04747579246759415 reg_loss 0.06180357560515404
epoch: 32 s: 768000 batch_loss 0.1100904792547226 BPR_loss 0.04822174459695816 reg_loss 0.061868734657764435
epoch: 32 s: 1024000 batch_loss 0.11358653008937836 BPR_loss 0.051347244530916214 reg_loss 0.062239281833171844
using time 214.8361s, training loss at epoch 32: 66.5237
epoch: 33 s: 0 batch_loss 0.11229272186756134 BPR_loss 0.050060395151376724 reg_loss 0.06223232299089432
epoch: 33 s: 256000 batch_loss 0.1078389585018158 BPR_loss 0.045979537069797516 reg_loss 0.06185942143201828
epoch: 33 s: 512000 batch_loss 0.10978660732507706 BPR_loss 0.04755643755197525 reg_loss 0.06223016977310181
epoch: 33 s: 768000 batch_loss 0.1066334992647171 BPR_loss 0.04451408237218857 reg_loss 0.06211942061781883
epoch: 33 s: 1024000 batch_loss 0.10986196994781494 BPR_loss 0.04781672731041908 reg_loss 0.06204523891210556
using time 211.4048s, training loss at epoch 33: 65.7639
epoch: 34 s: 0 batch_loss 0.10998678207397461 BPR_loss 0.04821373149752617 reg_loss 0.06177304685115814
epoch: 34 s: 256000 batch_loss 0.1048303097486496 BPR_loss 0.04355030134320259 reg_loss 0.061280008405447006
epoch: 34 s: 512000 batch_loss 0.1048988401889801 BPR_loss 0.0430748388171196 reg_loss 0.061823997646570206
epoch: 34 s: 768000 batch_loss 0.10505956411361694 BPR_loss 0.04339329153299332 reg_loss 0.061666276305913925
epoch: 34 s: 1024000 batch_loss 0.10489032417535782 BPR_loss 0.0428784117102623 reg_loss 0.06201191246509552
using time 209.4539s, training loss at epoch 34: 65.0807
epoch: 35 s: 0 batch_loss 0.10921536386013031 BPR_loss 0.04736783355474472 reg_loss 0.06184753403067589
epoch: 35 s: 256000 batch_loss 0.10534100234508514 BPR_loss 0.04383442550897598 reg_loss 0.06150657683610916
epoch: 35 s: 512000 batch_loss 0.10490906983613968 BPR_loss 0.04318135604262352 reg_loss 0.06172771379351616
epoch: 35 s: 768000 batch_loss 0.10948536545038223 BPR_loss 0.04770233482122421 reg_loss 0.06178303062915802
epoch: 35 s: 1024000 batch_loss 0.10655545443296432 BPR_loss 0.045170459896326065 reg_loss 0.06138499453663826
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   35  | 210.30697441101074 | 48.53161096572876 | 64.40921020507812 | [0.00780007 0.01433662 0.02021053] | [0.00529143 0.0077864  0.00976939] | [0.00265568 0.00249226 0.00238358] | [0.04130352 0.0718075  0.09899583] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 36 s: 0 batch_loss 0.1055329293012619 BPR_loss 0.04454955458641052 reg_loss 0.06098337098956108
epoch: 36 s: 256000 batch_loss 0.10578019171953201 BPR_loss 0.04444510489702225 reg_loss 0.061335086822509766
epoch: 36 s: 512000 batch_loss 0.10578550398349762 BPR_loss 0.04448426887392998 reg_loss 0.061301231384277344
epoch: 36 s: 768000 batch_loss 0.10696062445640564 BPR_loss 0.0454954132437706 reg_loss 0.06146521493792534
epoch: 36 s: 1024000 batch_loss 0.10713375359773636 BPR_loss 0.04523509368300438 reg_loss 0.06189865991473198
using time 208.1206s, training loss at epoch 36: 63.7158
epoch: 37 s: 0 batch_loss 0.10213784128427505 BPR_loss 0.04102427512407303 reg_loss 0.061113566160202026
epoch: 37 s: 256000 batch_loss 0.10422514379024506 BPR_loss 0.04276708513498306 reg_loss 0.061458054929971695
epoch: 37 s: 512000 batch_loss 0.10214079171419144 BPR_loss 0.04045909270644188 reg_loss 0.06168169900774956
epoch: 37 s: 768000 batch_loss 0.10504689812660217 BPR_loss 0.04407402127981186 reg_loss 0.060972873121500015
epoch: 37 s: 1024000 batch_loss 0.10726348310709 BPR_loss 0.04564505070447922 reg_loss 0.06161843240261078
using time 212.4041s, training loss at epoch 37: 63.1449
epoch: 38 s: 0 batch_loss 0.10530920326709747 BPR_loss 0.04387309029698372 reg_loss 0.061436112970113754
epoch: 38 s: 256000 batch_loss 0.10554252564907074 BPR_loss 0.04484425485134125 reg_loss 0.06069827079772949
epoch: 38 s: 512000 batch_loss 0.10106433928012848 BPR_loss 0.04031677171587944 reg_loss 0.06074756756424904
epoch: 38 s: 768000 batch_loss 0.10358648002147675 BPR_loss 0.0422847643494606 reg_loss 0.061301711946725845
epoch: 38 s: 1024000 batch_loss 0.1056579127907753 BPR_loss 0.04465271532535553 reg_loss 0.06100519746541977
using time 214.0702s, training loss at epoch 38: 62.5638
epoch: 39 s: 0 batch_loss 0.10439047962427139 BPR_loss 0.04313177615404129 reg_loss 0.0612587034702301
epoch: 39 s: 256000 batch_loss 0.10006499290466309 BPR_loss 0.03896705061197281 reg_loss 0.061097946017980576
epoch: 39 s: 512000 batch_loss 0.10596388578414917 BPR_loss 0.04534988850355148 reg_loss 0.060614001005887985
epoch: 39 s: 768000 batch_loss 0.10013651847839355 BPR_loss 0.03932467848062515 reg_loss 0.0608118399977684
epoch: 39 s: 1024000 batch_loss 0.10246007144451141 BPR_loss 0.04137856513261795 reg_loss 0.06108150631189346
using time 206.3252s, training loss at epoch 39: 62.0244
epoch: 40 s: 0 batch_loss 0.10214011371135712 BPR_loss 0.0411515012383461 reg_loss 0.060988616198301315
epoch: 40 s: 256000 batch_loss 0.099810391664505 BPR_loss 0.03953111916780472 reg_loss 0.06027927249670029
epoch: 40 s: 512000 batch_loss 0.1036241427063942 BPR_loss 0.04276895523071289 reg_loss 0.060855187475681305
epoch: 40 s: 768000 batch_loss 0.10140623152256012 BPR_loss 0.0409640371799469 reg_loss 0.06044219061732292
epoch: 40 s: 1024000 batch_loss 0.10291239619255066 BPR_loss 0.042750053107738495 reg_loss 0.060162339359521866
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   40  | 210.13714504241943 | 44.25695180892944 | 61.52766799926758 | [0.00734344 0.01366322 0.01882097] | [0.00499563 0.00741305 0.00915535] | [0.00250884 0.00237306 0.00222359] | [0.03966149 0.06855501 0.09271189] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 41 s: 0 batch_loss 0.0994875580072403 BPR_loss 0.03926032781600952 reg_loss 0.06022723391652107
epoch: 41 s: 256000 batch_loss 0.10140634328126907 BPR_loss 0.04082720726728439 reg_loss 0.06057913601398468
epoch: 41 s: 512000 batch_loss 0.10116062313318253 BPR_loss 0.03995557129383087 reg_loss 0.061205051839351654
epoch: 41 s: 768000 batch_loss 0.10110576450824738 BPR_loss 0.040631555020809174 reg_loss 0.0604742057621479
epoch: 41 s: 1024000 batch_loss 0.09895065426826477 BPR_loss 0.03825804591178894 reg_loss 0.06069261208176613
using time 209.8947s, training loss at epoch 41: 60.9984
epoch: 42 s: 0 batch_loss 0.10078656673431396 BPR_loss 0.03991701081395149 reg_loss 0.06086955592036247
epoch: 42 s: 256000 batch_loss 0.09722574800252914 BPR_loss 0.03699083626270294 reg_loss 0.0602349117398262
epoch: 42 s: 512000 batch_loss 0.10054832696914673 BPR_loss 0.03989176079630852 reg_loss 0.06065656617283821
epoch: 42 s: 768000 batch_loss 0.09883858263492584 BPR_loss 0.03864995390176773 reg_loss 0.06018863245844841
epoch: 42 s: 1024000 batch_loss 0.0997404009103775 BPR_loss 0.03961705416440964 reg_loss 0.06012335047125816
using time 211.4436s, training loss at epoch 42: 60.5294
epoch: 43 s: 0 batch_loss 0.10060674697160721 BPR_loss 0.040127988904714584 reg_loss 0.060478758066892624
epoch: 43 s: 256000 batch_loss 0.1014975905418396 BPR_loss 0.04136554151773453 reg_loss 0.06013205274939537
epoch: 43 s: 512000 batch_loss 0.09860385954380035 BPR_loss 0.03892095014452934 reg_loss 0.05968291312456131
epoch: 43 s: 768000 batch_loss 0.09948952496051788 BPR_loss 0.039056435227394104 reg_loss 0.06043308600783348
epoch: 43 s: 1024000 batch_loss 0.10158642381429672 BPR_loss 0.04182761162519455 reg_loss 0.05975881218910217
using time 212.9272s, training loss at epoch 43: 60.1014
epoch: 44 s: 0 batch_loss 0.10029739141464233 BPR_loss 0.03997227922081947 reg_loss 0.06032510846853256
epoch: 44 s: 256000 batch_loss 0.09818706661462784 BPR_loss 0.03816238418221474 reg_loss 0.0600246824324131
epoch: 44 s: 512000 batch_loss 0.09861727803945541 BPR_loss 0.03841060400009155 reg_loss 0.06020667403936386
epoch: 44 s: 768000 batch_loss 0.10061532258987427 BPR_loss 0.04062563180923462 reg_loss 0.05998969450592995
epoch: 44 s: 1024000 batch_loss 0.10207192599773407 BPR_loss 0.041940852999687195 reg_loss 0.06013107672333717
using time 208.6834s, training loss at epoch 44: 59.6504
epoch: 45 s: 0 batch_loss 0.09800602495670319 BPR_loss 0.0378548800945282 reg_loss 0.06015114486217499
epoch: 45 s: 256000 batch_loss 0.09747454524040222 BPR_loss 0.03752667084336281 reg_loss 0.05994787439703941
epoch: 45 s: 512000 batch_loss 0.09919571131467819 BPR_loss 0.039053477346897125 reg_loss 0.06014223396778107
epoch: 45 s: 768000 batch_loss 0.09779810905456543 BPR_loss 0.03811291605234146 reg_loss 0.05968519672751427
epoch: 45 s: 1024000 batch_loss 0.09539581835269928 BPR_loss 0.03569108247756958 reg_loss 0.0597047358751297
+-------+-------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |  tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   45  | 214.2541003227234 | 49.1472749710083 | 59.257476806640625 | [0.0061474  0.01104201 0.01518269] | [0.00404969 0.00591066 0.00730621] | [0.00206518 0.00188834 0.00176729] | [0.03220917 0.05358722 0.07158646] |
+-------+-------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 46 s: 0 batch_loss 0.09477883577346802 BPR_loss 0.035119786858558655 reg_loss 0.059659045189619064
epoch: 46 s: 256000 batch_loss 0.09864900261163712 BPR_loss 0.038787320256233215 reg_loss 0.0598616823554039
epoch: 46 s: 512000 batch_loss 0.09637961536645889 BPR_loss 0.03660869970917702 reg_loss 0.059770915657281876
epoch: 46 s: 768000 batch_loss 0.09394277632236481 BPR_loss 0.034663647413253784 reg_loss 0.059279125183820724
epoch: 46 s: 1024000 batch_loss 0.09574760496616364 BPR_loss 0.03660210222005844 reg_loss 0.059145499020814896
using time 210.7397s, training loss at epoch 46: 58.8623
epoch: 47 s: 0 batch_loss 0.09640412032604218 BPR_loss 0.03674070164561272 reg_loss 0.05966341495513916
epoch: 47 s: 256000 batch_loss 0.09735928475856781 BPR_loss 0.037646904587745667 reg_loss 0.059712376445531845
epoch: 47 s: 512000 batch_loss 0.09731058031320572 BPR_loss 0.037366557866334915 reg_loss 0.059944022446870804
epoch: 47 s: 768000 batch_loss 0.09889364242553711 BPR_loss 0.04007123410701752 reg_loss 0.05882241204380989
epoch: 47 s: 1024000 batch_loss 0.09608198702335358 BPR_loss 0.03622419387102127 reg_loss 0.059857793152332306
using time 207.4887s, training loss at epoch 47: 58.4360
epoch: 48 s: 0 batch_loss 0.09479355812072754 BPR_loss 0.03498203307390213 reg_loss 0.05981152132153511
epoch: 48 s: 256000 batch_loss 0.09626250714063644 BPR_loss 0.03658924996852875 reg_loss 0.0596732571721077
epoch: 48 s: 512000 batch_loss 0.09661959111690521 BPR_loss 0.0373164638876915 reg_loss 0.059303123503923416
epoch: 48 s: 768000 batch_loss 0.09660205990076065 BPR_loss 0.03715575486421585 reg_loss 0.0594463050365448
epoch: 48 s: 1024000 batch_loss 0.09464505314826965 BPR_loss 0.03512590005993843 reg_loss 0.05951915308833122
using time 211.1510s, training loss at epoch 48: 58.0599
epoch: 49 s: 0 batch_loss 0.09497692435979843 BPR_loss 0.035430751740932465 reg_loss 0.05954617261886597
epoch: 49 s: 256000 batch_loss 0.09514550864696503 BPR_loss 0.03617074340581894 reg_loss 0.05897476524114609
epoch: 49 s: 512000 batch_loss 0.09585098922252655 BPR_loss 0.03661750257015228 reg_loss 0.05923348665237427
epoch: 49 s: 768000 batch_loss 0.0950724184513092 BPR_loss 0.03555494546890259 reg_loss 0.059517472982406616
epoch: 49 s: 1024000 batch_loss 0.09795285761356354 BPR_loss 0.03869302198290825 reg_loss 0.05925983190536499
using time 202.4077s, training loss at epoch 49: 57.7751
epoch: 50 s: 0 batch_loss 0.09576702117919922 BPR_loss 0.03692092001438141 reg_loss 0.05884610489010811
epoch: 50 s: 256000 batch_loss 0.09112916886806488 BPR_loss 0.032497309148311615 reg_loss 0.058631859719753265
epoch: 50 s: 512000 batch_loss 0.09719277918338776 BPR_loss 0.03809778392314911 reg_loss 0.05909499526023865
epoch: 50 s: 768000 batch_loss 0.09451954066753387 BPR_loss 0.03555847704410553 reg_loss 0.058961059898138046
epoch: 50 s: 1024000 batch_loss 0.09237056970596313 BPR_loss 0.03352495655417442 reg_loss 0.05884560942649841
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   50  | 202.1767225265503 | 44.34681487083435 | 57.34397888183594 | [0.00559946 0.01036782 0.01445312] | [0.00380876 0.00561561 0.00697936] | [0.0018615  0.00174624 0.00165204] | [0.02895668 0.04888215 0.06643931] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 51 s: 0 batch_loss 0.09454578161239624 BPR_loss 0.03541795164346695 reg_loss 0.05912782624363899
epoch: 51 s: 256000 batch_loss 0.09616589546203613 BPR_loss 0.03710738569498062 reg_loss 0.05905851349234581
epoch: 51 s: 512000 batch_loss 0.09230498969554901 BPR_loss 0.03306884318590164 reg_loss 0.05923614278435707
epoch: 51 s: 768000 batch_loss 0.09424106776714325 BPR_loss 0.03537936508655548 reg_loss 0.05886169895529747
epoch: 51 s: 1024000 batch_loss 0.09353592991828918 BPR_loss 0.03463331609964371 reg_loss 0.05890261009335518
using time 204.4967s, training loss at epoch 51: 57.0361
epoch: 52 s: 0 batch_loss 0.09190638363361359 BPR_loss 0.032857369631528854 reg_loss 0.059049010276794434
epoch: 52 s: 256000 batch_loss 0.09352982044219971 BPR_loss 0.0344398096203804 reg_loss 0.059090014547109604
epoch: 52 s: 512000 batch_loss 0.09373059868812561 BPR_loss 0.03456486016511917 reg_loss 0.05916573852300644
epoch: 52 s: 768000 batch_loss 0.09312400966882706 BPR_loss 0.0344792976975441 reg_loss 0.05864471197128296
epoch: 52 s: 1024000 batch_loss 0.093805231153965 BPR_loss 0.03532420098781586 reg_loss 0.05848103016614914
using time 202.3058s, training loss at epoch 52: 56.7090
epoch: 53 s: 0 batch_loss 0.09394403547048569 BPR_loss 0.03534022718667984 reg_loss 0.05860380828380585
epoch: 53 s: 256000 batch_loss 0.09346932172775269 BPR_loss 0.03546682745218277 reg_loss 0.05800249055027962
epoch: 53 s: 512000 batch_loss 0.09414029121398926 BPR_loss 0.03544681891798973 reg_loss 0.05869347229599953
epoch: 53 s: 768000 batch_loss 0.0945170670747757 BPR_loss 0.035700179636478424 reg_loss 0.05881688743829727
epoch: 53 s: 1024000 batch_loss 0.09270545840263367 BPR_loss 0.03458874672651291 reg_loss 0.058116715401411057
using time 202.4770s, training loss at epoch 53: 56.4196
epoch: 54 s: 0 batch_loss 0.09336765855550766 BPR_loss 0.03483721613883972 reg_loss 0.05853044241666794
epoch: 54 s: 256000 batch_loss 0.0937427282333374 BPR_loss 0.0355808287858963 reg_loss 0.0581618957221508
epoch: 54 s: 512000 batch_loss 0.0920606255531311 BPR_loss 0.03361709415912628 reg_loss 0.05844352766871452
epoch: 54 s: 768000 batch_loss 0.09492386132478714 BPR_loss 0.03671661764383316 reg_loss 0.05820724368095398
epoch: 54 s: 1024000 batch_loss 0.09298157691955566 BPR_loss 0.034433163702487946 reg_loss 0.05854841694235802
using time 202.6452s, training loss at epoch 54: 56.1420
epoch: 55 s: 0 batch_loss 0.09197342395782471 BPR_loss 0.03389568626880646 reg_loss 0.05807773396372795
epoch: 55 s: 256000 batch_loss 0.09295986592769623 BPR_loss 0.03483626991510391 reg_loss 0.058123596012592316
epoch: 55 s: 512000 batch_loss 0.09120562672615051 BPR_loss 0.03292373567819595 reg_loss 0.05828189104795456
epoch: 55 s: 768000 batch_loss 0.09355109930038452 BPR_loss 0.03555501997470856 reg_loss 0.057996079325675964
epoch: 55 s: 1024000 batch_loss 0.09149808436632156 BPR_loss 0.033270612359046936 reg_loss 0.05822747200727463
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   55  | 202.22567081451416 | 44.00636839866638 | 55.88460922241211 | [0.00751988 0.01382137 0.01900772] | [0.00519775 0.00761152 0.00936412] | [0.00258621 0.00243779 0.00227306] | [0.04048251 0.06880763 0.09204876] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.007519882899278386
early stopping at 55, recall@20:0.0358
