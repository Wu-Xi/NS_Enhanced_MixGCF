Namespace(K=1, Ks='[20, 40, 60]', batch_size=2048, batch_test_flag=True, context_hops=3, cuda=True, data_path='data/', dataset='yelp2018', dim=64, edge_dropout=False, edge_dropout_rate=0.1, epoch=1000, eps=0.01, gnn='lightgcn', gpu_id=3, l2=0.0001, lr=0.001, mess_dropout=False, mess_dropout_rate=0.1, n_negs=64, ns='mixgcf', out_dir='./weights/yelp2018/', pool='final', save=False, test_batch_size=2048, test_flag='part')
reading train and test user-item set ...
building the adj mat ...
loading over ...
这是两个item维度层面上的权重自适应......
start training ...
epoch: 0 s: 0 batch_loss 0.6931477189064026 BPR_loss 0.6931471824645996 reg_loss 5.096079007671506e-07
epoch: 0 s: 256000 batch_loss 0.693147599697113 BPR_loss 0.6931471824645996 reg_loss 4.100248247596028e-07
epoch: 0 s: 512000 batch_loss 0.6931475400924683 BPR_loss 0.6931471824645996 reg_loss 3.476428105386731e-07
epoch: 0 s: 768000 batch_loss 0.6931474208831787 BPR_loss 0.6931471228599548 reg_loss 3.0685001206620655e-07
epoch: 0 s: 1024000 batch_loss 0.6931468844413757 BPR_loss 0.6931465864181519 reg_loss 3.0432110520450806e-07
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   0   | 224.01428771018982 | 45.44003391265869 | 418.6601257324219 | [0.02779975 0.04654518 0.06232396] | [0.02241319 0.029517   0.03504555] | [0.01234685 0.01044035 0.00941329] | [0.1779083  0.26158899 0.31918656] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 1 s: 0 batch_loss 0.6931320428848267 BPR_loss 0.6931310892105103 reg_loss 9.684165434009628e-07
epoch: 1 s: 256000 batch_loss 0.6926425695419312 BPR_loss 0.692623496055603 reg_loss 1.9072964278166182e-05
epoch: 1 s: 512000 batch_loss 0.6906093955039978 BPR_loss 0.6904911994934082 reg_loss 0.00011818630446214229
epoch: 1 s: 768000 batch_loss 0.6821491718292236 BPR_loss 0.6817708015441895 reg_loss 0.0003783900465350598
epoch: 1 s: 1024000 batch_loss 0.6687354445457458 BPR_loss 0.6679009199142456 reg_loss 0.0008345373789779842
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   1   | 227.87642288208008 | 43.1347541809082 | 412.6885986328125 | [0.0334168  0.05702024 0.07685093] | [0.02692576 0.03593242 0.0429281 ] | [0.0152141  0.01312445 0.01190634] | [0.22303271 0.33731211 0.41524567] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 2 s: 0 batch_loss 0.6565149426460266 BPR_loss 0.6551803350448608 reg_loss 0.0013345920015126467
epoch: 2 s: 256000 batch_loss 0.639763593673706 BPR_loss 0.6377289295196533 reg_loss 0.0020346748642623425
epoch: 2 s: 512000 batch_loss 0.6163538694381714 BPR_loss 0.6134858727455139 reg_loss 0.0028679720126092434
epoch: 2 s: 768000 batch_loss 0.5940907001495361 BPR_loss 0.5902644395828247 reg_loss 0.0038262801244854927
epoch: 2 s: 1024000 batch_loss 0.5656612515449524 BPR_loss 0.5607976913452148 reg_loss 0.004863574635237455
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   2   | 220.9770050048828 | 50.18074345588684 | 365.6127014160156 | [0.03590685 0.06015821 0.08107801] | [0.02907638 0.03826922 0.04563638] | [0.01649773 0.01393047 0.01262999] | [0.24257926 0.35786914 0.43902362] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 3 s: 0 batch_loss 0.5492554306983948 BPR_loss 0.5434893369674683 reg_loss 0.005766088608652353
epoch: 3 s: 256000 batch_loss 0.5349419116973877 BPR_loss 0.5280256271362305 reg_loss 0.006916309241205454
epoch: 3 s: 512000 batch_loss 0.5072528719902039 BPR_loss 0.4992098808288574 reg_loss 0.008042979054152966
epoch: 3 s: 768000 batch_loss 0.4928399324417114 BPR_loss 0.4835616648197174 reg_loss 0.009278264828026295
epoch: 3 s: 1024000 batch_loss 0.47711917757987976 BPR_loss 0.46669071912765503 reg_loss 0.010428463108837605
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   3   | 225.5353443622589 | 50.78001308441162 | 303.3997497558594 | [0.03671475 0.06184463 0.0832208 ] | [0.02922468 0.0388217  0.046363  ] | [0.01676929 0.0143244  0.01295998] | [0.24848427 0.36708981 0.44717065] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 4 s: 0 batch_loss 0.45250827074050903 BPR_loss 0.44101381301879883 reg_loss 0.011494460515677929
epoch: 4 s: 256000 batch_loss 0.43823644518852234 BPR_loss 0.42551523447036743 reg_loss 0.012721196748316288
epoch: 4 s: 512000 batch_loss 0.4262329936027527 BPR_loss 0.4123799502849579 reg_loss 0.013853042386472225
epoch: 4 s: 768000 batch_loss 0.39664432406425476 BPR_loss 0.3814930319786072 reg_loss 0.015151284635066986
epoch: 4 s: 1024000 batch_loss 0.40102827548980713 BPR_loss 0.38467463850975037 reg_loss 0.016353638842701912
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   4   | 217.86082577705383 | 50.38751554489136 | 252.1200408935547 | [0.0366376  0.06225067 0.08376173] | [0.02930691 0.03905765 0.04663895] | [0.01678666 0.01437571 0.01300261] | [0.24513705 0.36497411 0.44530757] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 5 s: 0 batch_loss 0.386152982711792 BPR_loss 0.3688315749168396 reg_loss 0.017321420833468437
epoch: 5 s: 256000 batch_loss 0.3638364374637604 BPR_loss 0.3452795147895813 reg_loss 0.018556931987404823
epoch: 5 s: 512000 batch_loss 0.35973161458969116 BPR_loss 0.34001854062080383 reg_loss 0.01971307024359703
epoch: 5 s: 768000 batch_loss 0.34342169761657715 BPR_loss 0.3225438594818115 reg_loss 0.02087784744799137
epoch: 5 s: 1024000 batch_loss 0.3350418508052826 BPR_loss 0.3129216730594635 reg_loss 0.022120170295238495
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   5   | 226.82873249053955 | 48.1849524974823 | 213.6573486328125 | [0.03578266 0.06103801 0.08192939] | [0.02842369 0.03808014 0.04544526] | [0.01622774 0.01396836 0.01260157] | [0.23983201 0.35843754 0.43760263] |
+-------+--------------------+------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 6 s: 0 batch_loss 0.3261384665966034 BPR_loss 0.303167462348938 reg_loss 0.02297101356089115
epoch: 6 s: 256000 batch_loss 0.31819358468055725 BPR_loss 0.29410627484321594 reg_loss 0.024087300524115562
epoch: 6 s: 512000 batch_loss 0.30374449491500854 BPR_loss 0.27850574254989624 reg_loss 0.0252387598156929
epoch: 6 s: 768000 batch_loss 0.3036699593067169 BPR_loss 0.27743375301361084 reg_loss 0.02623620629310608
epoch: 6 s: 1024000 batch_loss 0.29346010088920593 BPR_loss 0.2660471796989441 reg_loss 0.027412932366132736
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   6   | 221.27590823173523 | 48.029605865478516 | 184.34991455078125 | [0.03556551 0.06063399 0.08128106] | [0.02793902 0.03757528 0.04481387] | [0.01598459 0.01379468 0.01238527] | [0.23866364 0.3546798  0.43362385] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 7 s: 0 batch_loss 0.28230756521224976 BPR_loss 0.25400400161743164 reg_loss 0.02830355241894722
epoch: 7 s: 256000 batch_loss 0.268629789352417 BPR_loss 0.23928001523017883 reg_loss 0.029349785298109055
epoch: 7 s: 512000 batch_loss 0.26384639739990234 BPR_loss 0.23344364762306213 reg_loss 0.030402742326259613
epoch: 7 s: 768000 batch_loss 0.26489153504371643 BPR_loss 0.23348596692085266 reg_loss 0.03140556067228317
epoch: 7 s: 1024000 batch_loss 0.2563171088695526 BPR_loss 0.22391477227210999 reg_loss 0.03240234777331352
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s) |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   7   | 223.6694939136505 | 49.89890170097351 | 162.5696563720703 | [0.03454183 0.05914135 0.07962545] | [0.02717731 0.03661822 0.04381075] | [0.01546198 0.01336286 0.01206791] | [0.23061134 0.3452381  0.42307692] |
+-------+-------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 8 s: 0 batch_loss 0.2581068277359009 BPR_loss 0.22485753893852234 reg_loss 0.03324928507208824
epoch: 8 s: 256000 batch_loss 0.24577003717422485 BPR_loss 0.2117096483707428 reg_loss 0.03406038135290146
epoch: 8 s: 512000 batch_loss 0.23747502267360687 BPR_loss 0.20249086618423462 reg_loss 0.03498416021466255
epoch: 8 s: 768000 batch_loss 0.2342483401298523 BPR_loss 0.19836723804473877 reg_loss 0.03588109835982323
epoch: 8 s: 1024000 batch_loss 0.22841882705688477 BPR_loss 0.19152697920799255 reg_loss 0.03689185529947281
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss       |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   8   | 222.53726315498352 | 42.28973340988159 | 145.8812713623047 | [0.03306116 0.05644243 0.07621467] | [0.02576679 0.03476739 0.04171298] | [0.01445939 0.01245895 0.01131637] | [0.22085386 0.33011242 0.40918277] |
+-------+--------------------+-------------------+-------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 9 s: 0 batch_loss 0.22878454625606537 BPR_loss 0.19130846858024597 reg_loss 0.037476081401109695
epoch: 9 s: 256000 batch_loss 0.2305721789598465 BPR_loss 0.19229236245155334 reg_loss 0.03827982023358345
epoch: 9 s: 512000 batch_loss 0.2130797803401947 BPR_loss 0.1739262044429779 reg_loss 0.0391535684466362
epoch: 9 s: 768000 batch_loss 0.21826280653476715 BPR_loss 0.17820173501968384 reg_loss 0.04006107151508331
epoch: 9 s: 1024000 batch_loss 0.21245437860488892 BPR_loss 0.17179131507873535 reg_loss 0.04066307097673416
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   9   | 225.91783809661865 | 49.18335318565369 | 132.97073364257812 | [0.02947133 0.05108917 0.06975994] | [0.02259123 0.0309831  0.03752708] | [0.01257421 0.01106006 0.01014063] | [0.19436024 0.30134521 0.37700518] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 10 s: 0 batch_loss 0.20912876725196838 BPR_loss 0.16774044930934906 reg_loss 0.041388317942619324
epoch: 10 s: 256000 batch_loss 0.2117851823568344 BPR_loss 0.1696585714817047 reg_loss 0.04212661460042
epoch: 10 s: 512000 batch_loss 0.21049551665782928 BPR_loss 0.16772925853729248 reg_loss 0.042766254395246506
epoch: 10 s: 768000 batch_loss 0.20796170830726624 BPR_loss 0.16445815563201904 reg_loss 0.04350355267524719
epoch: 10 s: 1024000 batch_loss 0.20208263397216797 BPR_loss 0.15779604017734528 reg_loss 0.04428659379482269
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |  tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   10  | 227.51316261291504 | 46.9161741733551 | 122.65611267089844 | [0.0272027  0.04755818 0.06566084] | [0.02067815 0.02854995 0.03486944] | [0.01143899 0.01012536 0.00939013] | [0.1779083  0.27984085 0.35565871] |
+-------+--------------------+------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 11 s: 0 batch_loss 0.1955224573612213 BPR_loss 0.15073281526565552 reg_loss 0.044789645820856094
epoch: 11 s: 256000 batch_loss 0.19525982439517975 BPR_loss 0.14989854395389557 reg_loss 0.04536128416657448
epoch: 11 s: 512000 batch_loss 0.19218045473098755 BPR_loss 0.1460282802581787 reg_loss 0.04615217074751854
epoch: 11 s: 768000 batch_loss 0.19186249375343323 BPR_loss 0.14523503184318542 reg_loss 0.046627454459667206
epoch: 11 s: 1024000 batch_loss 0.18490377068519592 BPR_loss 0.13766083121299744 reg_loss 0.04724293574690819
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   11  | 221.79293584823608 | 48.791356325149536 | 114.50859069824219 | [0.02455584 0.04328761 0.05991349] | [0.01837668 0.02566935 0.03147047] | [0.01003063 0.00899331 0.00838702] | [0.15776178 0.24952634 0.32044967] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 12 s: 0 batch_loss 0.19313772022724152 BPR_loss 0.14533114433288574 reg_loss 0.047806572169065475
epoch: 12 s: 256000 batch_loss 0.18367771804332733 BPR_loss 0.13530394434928894 reg_loss 0.04837377741932869
epoch: 12 s: 512000 batch_loss 0.1779177188873291 BPR_loss 0.1290530115365982 reg_loss 0.04886471480131149
epoch: 12 s: 768000 batch_loss 0.18291263282299042 BPR_loss 0.13339778780937195 reg_loss 0.04951484501361847
epoch: 12 s: 1024000 batch_loss 0.16837836802005768 BPR_loss 0.11864710599184036 reg_loss 0.049731262028217316
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)   |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   12  | 227.34731793403625 | 52.765565633773804 | 107.90772247314453 | [0.02359571 0.04164921 0.05778374] | [0.01761907 0.02466546 0.03029477] | [0.00958381 0.00863964 0.0080765 ] | [0.1510989  0.24324239 0.3117974 ] |
+-------+--------------------+--------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
epoch: 13 s: 0 batch_loss 0.1682073175907135 BPR_loss 0.11801005899906158 reg_loss 0.050197258591651917
epoch: 13 s: 256000 batch_loss 0.17074885964393616 BPR_loss 0.1198359876871109 reg_loss 0.050912875682115555
epoch: 13 s: 512000 batch_loss 0.1713164746761322 BPR_loss 0.1200973242521286 reg_loss 0.0512191504240036
epoch: 13 s: 768000 batch_loss 0.16873911023139954 BPR_loss 0.11708806455135345 reg_loss 0.05165104195475578
epoch: 13 s: 1024000 batch_loss 0.16671988368034363 BPR_loss 0.11439132690429688 reg_loss 0.052328549325466156
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
| Epoch |  training time(s)  |   tesing time(s)  |        Loss        |               recall               |                ndcg                |             precision              |             hit_ratio              |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
|   13  | 219.49859166145325 | 54.17506718635559 | 102.43597412109375 | [0.02077317 0.03770007 0.05263484] | [0.01541465 0.02202023 0.02722785] | [0.00824649 0.00765836 0.00723391] | [0.13193129 0.21974864 0.28590375] |
+-------+--------------------+-------------------+--------------------+------------------------------------+------------------------------------+------------------------------------+------------------------------------+
Early stopping is trigger at step: 10 log:0.02077317065170049
early stopping at 13, recall@20:0.0367
